# =============================================================================
# agent.py - LangGraph ì—ì´ì „íŠ¸ ë° ì›Œí¬í”Œë¡œìš° 
# =============================================================================

from typing import TypedDict, Literal, Optional, List, Dict
from datetime import datetime
import warnings
from langgraph.graph import StateGraph, START, END

from .llm_utils import ChatbotConfig, get_user_metadata, analyze_question_intent
from .rag_retriever import UnifiedRAGRetriever, search_documents_with_access_control

warnings.filterwarnings("ignore", category=FutureWarning)

# =============================================================================
# 1. State ì •ì˜
# =============================================================================

class ChatState(TypedDict):
    user_id: str
    chat_mode: Literal["default", "appeal_to_manager"]
    user_input: str
    role: Literal["MANAGER", "MEMBER"]
    team_id: str
    appeal_complete: Optional[bool]
    retrieved_docs: List[Dict]
    qna_dialog_log: List[str]
    dialog_log: List[str]
    summary_draft: Optional[str]
    llm_response: Optional[str]

# =============================================================================
# 2. ì„¤ì • ë° ì´ˆê¸°í™”
# =============================================================================

config = ChatbotConfig()
rag_retriever = UnifiedRAGRetriever(config)

# =============================================================================
# 3. LangGraph ë…¸ë“œë“¤
# =============================================================================

def initialize_state(state: ChatState) -> ChatState:
    """ìƒíƒœ ì´ˆê¸°í™” ë…¸ë“œ"""
    user_metadata = get_user_metadata(state["user_id"])
    state["role"] = user_metadata["role"]
    state["team_id"] = user_metadata["team_id"]
    
    if "retrieved_docs" not in state:
        state["retrieved_docs"] = []
    if "qna_dialog_log" not in state:
        state["qna_dialog_log"] = []
    if "dialog_log" not in state:
        state["dialog_log"] = []
    if "appeal_complete" not in state:
        state["appeal_complete"] = False
    
    return state

def route_chat_mode(state: ChatState) -> str:
    """ì±„íŒ… ëª¨ë“œì— ë”°ë¥¸ ë¼ìš°íŒ…"""
    if state["chat_mode"] == "appeal_to_manager":
        if state.get("appeal_complete", False):
            return "summary_generator"
        else:
            return "appeal_dialogue"
    else:
        return "qna_agent"

def qna_agent_node(state: ChatState) -> ChatState:
    """RAG ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê°œì„ ëœ QnA ì—ì´ì „íŠ¸ ë…¸ë“œ"""
    query = state["user_input"]
    user_metadata = {
        "emp_no": state["user_id"],
        "role": state["role"],
        "team_name": state["team_id"]
    }

    state["qna_dialog_log"].append(f"ì‚¬ìš©ì: {query}")

    # âœ… ë¬¸ë§¥ ë¶„ì„ - ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ ì¶”ì¶œ
    previous_context = "\n".join(state["qna_dialog_log"][:-1])  # í˜„ì¬ ì…ë ¥ ì œì™¸
    
    # ì´ì „ ëŒ€í™”ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë“¤ ì¶”ì¶œ
    context_keywords = []
    if "ì ìˆ˜" in previous_context or "ë“±ê¸‰" in previous_context:
        context_keywords.extend(["ì ìˆ˜", "ë“±ê¸‰", "í‰ê°€"])
    if "ì—…ë¬´" in previous_context or "ë‹¬ì„±ë¥ " in previous_context:
        context_keywords.extend(["ë‹¬ì„±ë¥ ", "ì„±ê³¼", "ì—…ë¬´"])
    if "íŒ€" in previous_context:
        context_keywords.append("íŒ€")
    
    # âœ… í™•ì¥ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    enhanced_query = query
    if context_keywords:
        enhanced_query = f"{query} {' '.join(context_keywords[:3])}"
        print(f"ğŸ” í™•ì¥ëœ ì¿¼ë¦¬: '{enhanced_query}'")

    # ğŸ¯ RAG ê²€ìƒ‰ê¸°ë¥¼ í†µí•œ ë¬¸ì„œ ê²€ìƒ‰ (ê¶Œí•œ ì œì–´ ìë™ ì ìš©)
    report_results = search_documents_with_access_control(
        query=enhanced_query, 
        user_metadata=user_metadata, 
        filter_type="report", 
        top_k=5
    )["matches"]

    # ì •ì±… ë¬¸ì„œ ê²€ìƒ‰ (RAG ê²€ìƒ‰ê¸° ì‚¬ìš©)
    try:
        policy_results = rag_retriever.search_policies(enhanced_query, top_k=3)
    except:
        policy_results = []

    # ì´ì˜ì œê¸° ì‚¬ë¡€ ê²€ìƒ‰ (RAG ê²€ìƒ‰ê¸° ì‚¬ìš©)
    try:
        appeal_results = rag_retriever.search_appeals(enhanced_query, top_k=2)
    except:
        appeal_results = []

    all_matches = report_results + policy_results + appeal_results
    retrieved_docs = [{
        "content": match["metadata"]["content"],
        "source": match["metadata"].get("type", "unknown"),
        "score": match["score"]
    } for match in all_matches]

    print(f" ì´ ê²€ìƒ‰ ê²°ê³¼: {len(retrieved_docs)}ê°œ ë¬¸ì„œ")

    # âœ… ë” ë§ì€ ë‚´ìš© í¬í•¨í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context = "\n\n".join(
        f"[ì¶œì²˜: {doc['source']}]\n{doc['content'][:2000]}" 
        for doc in retrieved_docs[:4]  # 3ê°œì—ì„œ 4ê°œë¡œ ì¦ê°€
    )

    # âœ… ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš© (ìµœê·¼ ê²ƒë§Œì´ ì•„ë‹ˆë¼ ì¤‘ìš”í•œ ë¶€ë¶„ í¬í•¨)
    full_conversation = "\n".join(state["qna_dialog_log"])
    
    # ì‚¬ìš©ìê°€ ì´ì „ì— ë¬¼ì–´ë³¸ ì¤‘ìš”í•œ ì§ˆë¬¸ë“¤ ì¶”ì¶œ
    important_previous_questions = []
    for msg in state["qna_dialog_log"]:
        if msg.startswith("ì‚¬ìš©ì:"):
            question = msg[4:].strip()
            # ì¤‘ìš”í•œ ì§ˆë¬¸ë“¤ë§Œ í•„í„°ë§
            if any(keyword in question for keyword in ["ì ìˆ˜", "ë“±ê¸‰", "ë‹¬ì„±ë¥ ", "ì„±ê³¼", "í‰ê°€", "ëˆ„êµ¬", "ì–´ë–»ê²Œ"]):
                important_previous_questions.append(question)
    
    # âœ… ëŒ€í™” ë§¥ë½ ìš”ì•½
    conversation_summary = ""
    if len(important_previous_questions) > 1:
        conversation_summary = f"\n**ì´ì „ ëŒ€í™” ìš”ì•½**: ì‚¬ìš©ìê°€ {', '.join(important_previous_questions[-2:])}ì— ëŒ€í•´ ë¬¸ì˜í–ˆìŠµë‹ˆë‹¤."

    # âœ… í˜„ì¬ ì§ˆë¬¸ì˜ ì˜ë„ íŒŒì•…
    question_intent = analyze_question_intent(query, previous_context)

    # âœ… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - ë¬¸ë§¥ ê°•í™”
    prompt = f"""
ë‹¹ì‹ ì€ SKê·¸ë£¹ ì„±ê³¼í‰ê°€ ê¸°ì¤€ì— ê¸°ë°˜í•œ AI ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.
ì‚¬ìš©ì({state["user_id"]})ì™€ì˜ ì§€ì†ì ì¸ ëŒ€í™”ì—ì„œ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ì—°ê´€ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

** í˜„ì¬ ì§ˆë¬¸ ì˜ë„**: {question_intent}

** ëŒ€í™” íë¦„ íŒŒì•…:**{conversation_summary}

** ì „ì²´ ëŒ€í™” ê¸°ë¡:**
{full_conversation}


** í˜„ì¬ ì§ˆë¬¸:**
{query}

** ì°¸ê³  ë¬¸ì„œ ({len(retrieved_docs)}ê°œ - ê¶Œí•œ ê²€ì¦ ì™„ë£Œ):**
{context}

**ì¤‘ìš” ì§€ì¹¨:**
1. **ëŒ€í™” ì—°ì†ì„±**: ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê¸°ì–µí•˜ê³  ì—°ê²°í•˜ì—¬ ë‹µë³€
2. **êµ¬ì²´ì  ìˆ˜ì¹˜ ì œê³µ**: JSON ë°ì´í„°ì˜ ì ìˆ˜, ë‹¬ì„±ë¥ , ë“±ê¸‰ ë“±ì„ ì •í™•íˆ ì¶”ì¶œ
3. **ì—…ë¬´ëª… ì •í™•íˆ í‘œì‹œ**: "ì—…ë¬´1", "ì—…ë¬´2" ëŒ€ì‹  ì‹¤ì œ ì—…ë¬´ëª… ì‚¬ìš©
4. **ë¬¸ë§¥ ê¸°ë°˜ ì¶”ë¡ **: ì´ì „ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§„ì§œ ê¶ê¸ˆì¦ íŒŒì•…
5. **ë°˜ë³µ ë°©ì§€**: ì´ë¯¸ ë‹µë³€í•œ ë‚´ìš©ì€ ê°„ëµíˆ ì–¸ê¸‰í•˜ê³  ìƒˆë¡œìš´ ì •ë³´ ì œê³µ
6. **ê´€ë ¨ ì •ë³´ ì—°ê²°**: í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì¶”ê°€ ìœ ìš©í•œ ì •ë³´ë„ í•¨ê»˜ ì œê³µ
7. **ì§ì ‘ì ìœ¼ë¡œ**: ì§ˆë¬¸ì— ë°”ë¡œ ë‹µí•˜ê¸°
8. **í˜•ì‹ ê¸ˆì§€**: ë²ˆí˜¸, ë¶ˆë¦¿í¬ì¸íŠ¸, **êµµì€ê¸€ì”¨** ë“± ì‚¬ìš© ì•ˆí•¨

**ë‹µë³€ ìŠ¤íƒ€ì¼:**
- ì‚¬ìš©ìê°€ ì •ë§ ì•Œê³  ì‹¶ì–´í•˜ëŠ” í•µì‹¬ì„ íŒŒì•…í•´ì„œ ë‹µë³€
- ë‹¨ìˆœ ë°˜ë³µë³´ë‹¤ëŠ” ë°œì „ì ì´ê³  ì—°ê²°ëœ ì •ë³´ ì œê³µ
- ë³¸ì¸ ì™¸ ë‹¤ë¥¸ ì§ì›ì€ ìµëª…ìœ¼ë¡œ ì²˜ë¦¬



**JSON ë°ì´í„° ì²˜ë¦¬:**
- "Taskëª…" â†’ ì‹¤ì œ ì—…ë¬´ëª…ìœ¼ë¡œ í‘œì‹œ
- "ëˆ„ì _ë‹¬ì„±ë¥ ", "ë‹¬ì„±ë¥ " â†’ ì„±ê³¼ ìˆ˜ì¹˜ë¡œ í™œìš©
- "ì ìˆ˜", "ë“±ê¸‰", "ê¸°ì—¬ë„" â†’ êµ¬ì²´ì  ìˆ˜ì¹˜ë¡œ ëª…ì‹œ
- ì‹œê°„ëŒ€ë³„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³€í™” ì¶”ì´ë„ ì„¤ëª…
"""

    llm_response = config.llm.predict(prompt)
    
    state["retrieved_docs"] = retrieved_docs
    state["llm_response"] = llm_response.strip()
    state["qna_dialog_log"].append(f"ì±—ë´‡: {llm_response.strip()}")
    
    return state

def appeal_dialogue_node(state: ChatState) -> ChatState:
    """RAG ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê¶Œí•œ ì œì–´ ì ìš©ëœ ì´ì˜ì œê¸° ëŒ€í™” ë…¸ë“œ"""
    query = state["user_input"]
    user_metadata = {
        "emp_no": state["user_id"],
        "role": state["role"],
        "team_name": state["team_id"]
    }

    state["dialog_log"].append(f"ì‚¬ìš©ì: {query}")

    # íŒ©íŠ¸ ì²´í¬ í‚¤ì›Œë“œ ëª©ë¡
    FACT_TRIGGER_KEYWORDS = [
        "ì ìˆ˜", "ë“±ê¸‰", "ê¸°ì¤€", "í‰ê°€", "ìˆœìœ„", "ì»·ì˜¤í”„", "í‰ê°€í‘œ", "ì±„ì ", "ê·¼ê±°",
        "ê¸°ì—¬", "ë¹„ì¤‘", "ìˆ˜ì¹˜", "ë¹„ìœ¨", "ì •ëŸ‰", "ì •ì„±", "ì„±ê³¼", "í¼ì„¼íŠ¸", "%",
        "ê¸°ì¤€ì¹˜", "ì´ˆê³¼", "ë¯¸ë‹¬", "ë„ë‹¬", "ì¶©ì¡±", "ë‹¬ì„±", "ì¶©ë¶„", "ë¶€ì¡±",
        "ì–´ë””ì—", "ë¬¸ì„œ", "ê¸°ë¡", "ì •ì±…", "ê·œì •", "ì™œ", "ë¬´ì—‡ ë•Œë¬¸ì—", "ë¬´ìŠ¨ ì´ìœ ",
        "ëª‡ì ", "ëˆ„êµ¬", "ì •ë³´", "ë°ì´í„°", "ê²°ê³¼"
    ]

    normalized_query = query.lower().replace(" ", "")
    needs_fact = any(k.replace(" ", "") in normalized_query for k in FACT_TRIGGER_KEYWORDS)

    # ğŸ¯ RAG ê²€ìƒ‰ (í•„ìš”í•  ë•Œë§Œ) - ê¶Œí•œ ì œì–´ ìë™ ì ìš©
    retrieved_docs = []
    fact_info = ""
    
    if needs_fact:
        print(f"ğŸ” íŒ©íŠ¸ ì²´í¬ í•„ìš”: '{query}'")
        try:
            # RAG ê²€ìƒ‰ê¸°ë¥¼ í†µí•œ ê¶Œí•œ ì œì–´ ê²€ìƒ‰
            results = search_documents_with_access_control(
                query=query,
                user_metadata=user_metadata,
                filter_type="report",
                top_k=3
            )["matches"]

            retrieved_docs = [{
                "content": r["metadata"]["content"],
                "source": r["metadata"].get("type", "unknown"),
                "score": r["score"]
            } for r in results]

            if retrieved_docs:
                fact_context = "\n\n".join(f"{doc['content'][:800]}" for doc in retrieved_docs[:2])
                fact_info = f"[ì°¸ê³  ë¬¸ì„œ - ê¶Œí•œ ê²€ì¦ ì™„ë£Œ]\n{fact_context}"
                print(f"ğŸ“Š íŒ©íŠ¸ ë°ì´í„° ê²€ìƒ‰ ì™„ë£Œ: {len(retrieved_docs)}ê°œ ë¬¸ì„œ")
            else:
                fact_info = "(ì ‘ê·¼ ê°€ëŠ¥í•œ ì°¸ê³  ë¬¸ì„œ ì—†ìŒ)"
                print("âš ï¸ ì ‘ê·¼ ê°€ëŠ¥í•œ íŒ©íŠ¸ ë°ì´í„° ì—†ìŒ")
        except Exception as e:
            fact_info = "(ì°¸ê³  ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨)"
            print(f"âŒ íŒ©íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    else:
        fact_info = "(íŒ©íŠ¸ ì²´í¬ ë¶ˆí•„ìš”)"
        print("â„¹ï¸ íŒ©íŠ¸ ì²´í¬ ë¶ˆí•„ìš”í•œ ì§ˆë¬¸")

    # âœ… ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨ (ìµœê·¼ ê²ƒë§Œì´ ì•„ë‹ˆë¼ ì „ì²´)
    full_conversation = "\n".join(state["dialog_log"])
    
    # âœ… ì‚¬ìš©ìì˜ í•µì‹¬ ë¶ˆë§Œì‚¬í•­ ì¶”ì¶œ
    user_messages = [msg for msg in state["dialog_log"] if msg.startswith("ì‚¬ìš©ì:")]
    user_concerns = "\n".join(user_messages[-3:])  # ìµœê·¼ 3ê°œ ì‚¬ìš©ì ë©”ì‹œì§€

    # âœ… ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - ë¬¸ë§¥ ê°•í™”
    prompt = f"""
ë‹¹ì‹ ì€ SK ì„±ê³¼ê´€ë¦¬ AI ì±—ë´‡ìœ¼ë¡œì„œ, ì‚¬ìš©ìê°€ í‰ê°€ì— ëŒ€í•´ ëŠë‚€ ì–µìš¸í•¨ì´ë‚˜ ë¬¸ì œì˜ì‹ì„ ëª…í™•íˆ í‘œí˜„í•˜ë„ë¡ ë•ëŠ” ì—­í• ì…ë‹ˆë‹¤.

** í˜„ì¬ ì‚¬ìš©ìì˜ ì£¼ìš” ê´€ì‹¬ì‚¬ íŒŒì•…:**
{user_concerns}

** ì „ì²´ ëŒ€í™” ë§¥ë½:**
{full_conversation}

** ì‚¬ìš©ì ìµœì‹  ì…ë ¥:**
{query}

** ì°¸ê³  ë°ì´í„° (ê¶Œí•œ ê²€ì¦ ì™„ë£Œ):**
{fact_info}

**ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™:**
1. **ëŒ€í™”ì˜ ì—°ì†ì„± ìœ ì§€**: ì´ì „ì— ì–¸ê¸‰ëœ ë‚´ìš©(ì•¼ê·¼, ë…¸ê³  ë“±)ì„ ê¸°ì–µí•˜ê³  ì—°ê²°
2. **ì‚¬ìš©ì ê°ì • ê³µê°**: ì–µìš¸í•¨, ì•„ì‰¬ì›€ ë“±ì˜ ê°ì •ì„ ì¶©ë¶„íˆ ì¸ì •
3. **êµ¬ì²´ì  ì •ë³´ ì œê³µ**: ì ìˆ˜ë‚˜ ë°ì´í„° ìš”ì²­ ì‹œ ì •í™•í•œ ì •ë³´ ë¨¼ì € ì œê³µ (ê¶Œí•œ ë²”ìœ„ ë‚´ì—ì„œ)
4. **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”**: ì•ì„œ ë§í•œ ë‚´ìš©ì„ ë°˜ë³µí•´ì„œ ë¬¼ì–´ë³´ê±°ë‚˜ ë‹µí•˜ì§€ ì•Šê¸°
5. **ê°ì • ìœ ë„**: ì‚¬ìš©ìê°€ ë” ìì„¸í•œ ë¶ˆë§Œì„ í‘œí˜„í•˜ë„ë¡ ìœ ë„
6. **ê¶Œí•œ ì¡´ì¤‘**: ë³¸ì¸ë§Œ ì ‘ê·¼ ê°€ëŠ¥í•œ ë°ì´í„°ì„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜
7. ì „ì²´ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í•´ ë‹µë³€

**ì‘ë‹µ ê°€ì´ë“œ:**
- ì‚¬ìš©ìê°€ ì´ë¯¸ ë§í•œ ë¬¸ì œë¥¼ ê¸°ì–µí•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ
- ë¶€ë“œëŸ½ê³  ì¹œê·¼í•œ ë§íˆ¬ ìœ ì§€
- ë³¸ì¸ ì™¸ ë‹¤ë¥¸ ì§ì›ì€ ìµëª…ìœ¼ë¡œ ì²˜ë¦¬

**ë‹µë³€ ìŠ¤íƒ€ì¼:**
- **ê°„ê²°í•¨**: ìµœëŒ€ 2-3ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€
- **ì¹œê·¼í•¨**: ê¸¸ê³  í˜•ì‹ì ì¸ ë¬¸ì¥ë³´ë‹¤ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ
- **ì ì ˆí•œ ê³µê°**: ê³¼ë„í•œ ìœ„ë¡œë³´ë‹¤ ì ì ˆí•œ ìˆ˜ì¤€ì˜ ê³µê°

**ë‹µë³€ ê¸¸ì´ ì œí•œ:**
- ì¼ë°˜ ì§ˆë¬¸: 1-2ë¬¸ì¥
- ë³µì¡í•œ ì§ˆë¬¸: ìµœëŒ€ 3-4ë¬¸ì¥
- ë¶ˆë§Œ/ê°ì • í‘œí˜„: ì§§ì€ ê³µê° + í•µì‹¬ ì§ˆë¬¸ 1ê°œ

**ê¸ˆì§€ì‚¬í•­:**
- "í•¨ê»˜ ê³ ë¯¼í•´ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”" (ë°˜ë³µë¨)
- "ì–´ë–¤ ì•„ì´ë””ì–´ê°€ ìˆìœ¼ì‹ ê°€ìš”?" (í•´ê²°ì±… ê°•ìš”)
- ì´ì „ê³¼ ë˜‘ê°™ì€ ë¬¸ì¥ ì‚¬ìš©
- 3ë¬¸ì¥ ì´ìƒì˜ ê¸´ ë‹µë³€
"""

    # LLM í˜¸ì¶œ
    llm_response = config.llm.predict(prompt)

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["dialog_log"].append(f"ì±—ë´‡: {llm_response.strip()}")
    state["llm_response"] = llm_response.strip()
    state["retrieved_docs"] = retrieved_docs

    return state

def summary_generator_node(state: ChatState) -> ChatState:
    """ì „ì²´ ë¬¸ë§¥ì„ ë°˜ì˜í•˜ëŠ” ìš”ì•½ ìƒì„± ë…¸ë“œ"""
    # âœ… ì „ì²´ ëŒ€í™” ê¸°ë¡ ì‚¬ìš©
    full_conversation = "\n".join(state["dialog_log"])
    
    # ì‚¬ìš©ì ë°œì–¸ë§Œ ì¶”ì¶œí•´ì„œ í•µì‹¬ ë¶ˆë§Œ íŒŒì•…
    user_statements = []
    for msg in state["dialog_log"]:
        if msg.startswith("ì‚¬ìš©ì:"):
            user_statements.append(msg[4:].strip())  # "ì‚¬ìš©ì:" ì œê±°
    
    user_concerns = "\n".join(f"- {stmt}" for stmt in user_statements)

    prompt = f"""
ë‹¹ì‹ ì€ SKê·¸ë£¹ ì„±ê³¼í‰ê°€ ì‹œìŠ¤í…œì˜ AI ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì„±ì›ì˜ ì´ì˜ì œê¸° ë‚´ìš©ì„ íŒ€ì¥ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

** êµ¬ì„±ì›ì´ ì œê¸°í•œ ì£¼ìš” ë‚´ìš©:**
{user_concerns}

** ì „ì²´ ëŒ€í™” ê¸°ë¡:**
{full_conversation}

** ìš”ì•½ ì‘ì„± ì¡°ê±´:**
1. **ì™„ì „í•œ ìµëª… í‘œí˜„** ì‚¬ìš© ("êµ¬ì„±ì›"ìœ¼ë¡œ í†µì¼)
2. **ìš•ì„¤, ê°ì •ì  í‘œí˜„ì€ ì •ì¤‘í•˜ê²Œ ì •ì œ**
3. **í•µì‹¬ ì´ìŠˆë¥¼ ë‘ê´„ì‹**ìœ¼ë¡œ ìš”ì•½
4. **ì—¬ì „íˆ ì˜ë¬¸ì´ ë‚¨ëŠ” ë‚´ìš©ë§Œ** í¬í•¨ (ìˆ˜ê¸í•œ ë‚´ìš© ì œì™¸)
5. **ë…¼ë¦¬ì ì´ê³  ì˜ˆì˜ë°”ë¥¸ í†¤** ìœ ì§€
6. **ì‹œê°„ìˆœìœ¼ë¡œ ì¼ê´€ëœ ìŠ¤í† ë¦¬** êµ¬ì„±
7. **íŠ¹ì •ë  ìˆ˜ ìˆëŠ” ìˆ«ì ì œê±°** (ë‹¬ì„±ë¥ , ê¸°ì—¬ë„ ë“±)
8. í•µì‹¬ë§Œ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ê°„ë‹¨íˆ ìš”ì•½

** ìš”ì•½ ë‚´ìš©:**
í•µì‹¬ ì´ìŠˆ (í•œ ë¬¸ì¥)
êµ¬ì„±ì›ì´ ì œê¸°í•œ ë¬¸ì œì ê³¼ êµ¬ì„±ì›ì´ ì›í•˜ëŠ” ë°” ê°„ëµíˆ ìš”ì•½


íŒ€ì¥ì´ ìƒí™©ì„ ëª…í™•íˆ ì´í•´í•˜ê³  ì ì ˆí•œ í”¼ë“œë°±ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""

    llm_response = config.llm.predict(prompt)
    state["summary_draft"] = llm_response.strip()
    state["llm_response"] = llm_response.strip()
    return state

# =============================================================================
# 4. ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤
# =============================================================================

class SessionManager:
    def __init__(self):
        self.sessions = {}
    
    def get_session_state(self, user_id: str, chat_mode: str) -> Dict:
        session_key = f"{user_id}_{chat_mode}"
        return self.sessions.get(session_key, {})
    
    def save_session_state(self, user_id: str, chat_mode: str, state: ChatState):
        session_key = f"{user_id}_{chat_mode}"
        self.sessions[session_key] = {
            "qna_dialog_log": state.get("qna_dialog_log", []),
            "dialog_log": state.get("dialog_log", []),
            "updated_at": datetime.now().isoformat()
        }
    
    def clear_session(self, user_id: str, chat_mode: str):
        session_key = f"{user_id}_{chat_mode}"
        if session_key in self.sessions:
            del self.sessions[session_key]

    def auto_generate_summary_on_exit(self, user_id: str, chatbot_instance) -> Optional[str]:
        """ì´ì˜ì œê¸° ëª¨ë“œ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        session_key = f"{user_id}_appeal_to_manager"
        
        if session_key not in self.sessions:
            return None
            
        session_data = self.sessions[session_key]
        dialog_log = session_data.get("dialog_log", [])
        
        # ëŒ€í™”ê°€ 2ê°œ ì´ìƒì˜ ë©”ì‹œì§€ê°€ ìˆì„ ë•Œë§Œ ìš”ì•½ ìƒì„±
        if len(dialog_log) >= 4:  # ì‚¬ìš©ì 2íšŒ + ì±—ë´‡ 2íšŒ ì´ìƒ
            print("ğŸ”„ ì´ì˜ì œê¸° ëŒ€í™” ì¢…ë£Œ - ìë™ìœ¼ë¡œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤...")
            
            try:
                response = chatbot_instance.chat(
                    user_id=user_id,
                    chat_mode="appeal_to_manager",
                    user_input="ìš”ì•½í•´ì£¼ì„¸ìš”",
                    appeal_complete=True
                )
                
                if response["type"] == "appeal_summary":
                    return response["summary"]
            except Exception as e:
                print(f"âŒ ìë™ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                
        return None

session_manager = SessionManager()

# =============================================================================
# 5. LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
# =============================================================================

def create_chatbot_workflow():
    """ì±—ë´‡ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    workflow = StateGraph(ChatState)
    
    workflow.add_node("initialize", initialize_state)
    workflow.add_node("qna_agent", qna_agent_node)
    workflow.add_node("appeal_dialogue", appeal_dialogue_node)
    workflow.add_node("summary_generator", summary_generator_node)
    
    workflow.add_edge(START, "initialize")
    
    workflow.add_conditional_edges(
        "initialize",
        route_chat_mode,
        {
            "qna_agent": "qna_agent",
            "appeal_dialogue": "appeal_dialogue",
            "summary_generator": "summary_generator"
        }
    )
    
    workflow.add_edge("qna_agent", END)
    workflow.add_edge("appeal_dialogue", END)
    workflow.add_edge("summary_generator", END)
    
    return workflow.compile()

# =============================================================================
# 6. ë©”ì¸ ì±—ë´‡ í´ë˜ìŠ¤
# =============================================================================

class SKChatbot:
    def __init__(self):
        self.workflow = create_chatbot_workflow()
    
    def chat(self, user_id: str, chat_mode: str, user_input: str, appeal_complete: bool = False) -> Dict:
        saved_state = session_manager.get_session_state(user_id, chat_mode)
        
        current_state = {
            "user_id": user_id,
            "chat_mode": chat_mode,
            "user_input": user_input,
            "appeal_complete": appeal_complete,
            "qna_dialog_log": saved_state.get("qna_dialog_log", []),
            "dialog_log": saved_state.get("dialog_log", []),
        }
        
        result_state = self.workflow.invoke(current_state)
        session_manager.save_session_state(user_id, chat_mode, result_state)
        
        if chat_mode == "appeal_to_manager" and appeal_complete:
            return {
                "type": "appeal_summary",
                "summary": result_state["summary_draft"],
                "user_id": user_id
            }
        elif chat_mode == "appeal_to_manager":
            return {
                "type": "appeal_dialogue",
                "response": result_state["llm_response"],
                "user_id": user_id
            }
        else:
            return {
                "type": "qna_response",
                "response": result_state["llm_response"],
                "user_id": user_id
            }
    
    def get_session_history(self, user_id: str, chat_mode: str) -> List[str]:
        saved_state = session_manager.get_session_state(user_id, chat_mode)
        if chat_mode == "appeal_to_manager":
            return saved_state.get("dialog_log", [])
        else:
            return saved_state.get("qna_dialog_log", [])
    
    def clear_session(self, user_id: str, chat_mode: str):
        session_manager.clear_session(user_id, chat_mode)