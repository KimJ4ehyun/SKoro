{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 모듈 6: 4P BARS 평가 시스템 (완전 수정 버전)\n",
    "# ================================================================\n",
    "\n",
    "from typing import Annotated, List, Literal, TypedDict, Dict, Optional\n",
    "from langchain_core.messages import HumanMessage\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Row\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import OperationalError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 환경변수 확인 ===\n",
      "DB_TYPE: mariadb\n",
      "DB_USERNAME: root\n",
      "DB_PASSWORD: Skala25a!23$\n",
      "DB_HOST: a1961fab471c6487aa7b3f049f61cdf7-770154099.ap-northeast-2.elb.amazonaws.com\n",
      "DB_PORT: 3306\n",
      "DB_NAME: sk-team-10\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv(\"C:/Users/Administrator/Desktop/skala10/SKoro-AI/.env\", override=True)\n",
    "\n",
    "print(\"=== 환경변수 확인 ===\")\n",
    "print(f\"DB_TYPE: {os.getenv('DB_TYPE')}\")\n",
    "print(f\"DB_USERNAME: {os.getenv('DB_USERNAME')}\")\n",
    "print(f\"DB_PASSWORD: {os.getenv('DB_PASSWORD')}\")\n",
    "print(f\"DB_HOST: {os.getenv('DB_HOST')}\")\n",
    "print(f\"DB_PORT: {os.getenv('DB_PORT')}\")\n",
    "print(f\"DB_NAME: {os.getenv('DB_NAME')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated DATABASE_URL: mysql+pymysql://root:***@a1961fab471c6487aa7b3f049f61cdf7-770154099.ap-northeast-2.elb.amazonaws.com:3306/sk-team-10\n",
      "✅ Database connection successful!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import OperationalError\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env에서 DB 정보 불러오기\n",
    "db_type = os.getenv(\"DB_TYPE\")  # mariadb\n",
    "db_username = os.getenv(\"DB_USERNAME\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# MariaDB/MySQL의 경우 mysql+pymysql 드라이버 사용\n",
    "if db_type.lower() in [\"mariadb\", \"mysql\"]:\n",
    "    DATABASE_URL = (\n",
    "        f\"mysql+pymysql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "    )\n",
    "else:\n",
    "    DATABASE_URL = (\n",
    "        f\"{db_type}://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Generated DATABASE_URL: mysql+pymysql://{db_username}:***@{db_host}:{db_port}/{db_name}\"\n",
    ")\n",
    "\n",
    "# DB 엔진 생성\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# 연결 테스트\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"✅ Database connection successful!\")\n",
    "except OperationalError as e:\n",
    "    print(f\"❌ Database connection failed: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_dict(row: Row) -> Dict:\n",
    "    \"\"\"SQLAlchemy Row 객체를 딕셔너리로 변환\"\"\"\n",
    "    if row is None:\n",
    "        return {}\n",
    "    return row._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Client initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# LLM 클라이언트 설정\n",
    "# ================================================================\n",
    "\n",
    "llm_client = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(f\"LLM Client initialized: {llm_client.model_name}\")\n",
    "\n",
    "\n",
    "def _extract_json_from_llm_response(text: str) -> str:\n",
    "    \"\"\"LLM 응답에서 JSON 블록 추출\"\"\"\n",
    "    match = re.search(r\"```(?:json)?\\s*(.*?)\\s*```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# DB 접근 함수들 (실제 테이블 구조 반영)\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "def fetch_employee_basic_info(emp_no: str) -> Optional[Dict]:\n",
    "    \"\"\"직원 기본 정보 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\n",
    "            \"\"\"\n",
    "            SELECT emp_no, emp_name, cl, position, team_id\n",
    "            FROM employees \n",
    "            WHERE emp_no = :emp_no\n",
    "        \"\"\"\n",
    "        )\n",
    "        result = connection.execute(query, {\"emp_no\": emp_no}).fetchone()\n",
    "        return row_to_dict(result) if result else None\n",
    "\n",
    "\n",
    "def fetch_task_data_for_passionate(\n",
    "    emp_no: str, period_id: int, report_type: str\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Passionate 평가용 Task 데이터 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        if report_type == \"annual\":\n",
    "            # 연말: 전체 분기 데이터\n",
    "            query = text(\n",
    "                \"\"\"\n",
    "                SELECT ts.task_summary, ts.task_performance, task_id, period_id\n",
    "                FROM task_summaries ts\n",
    "                WHERE ts.task_id IN (\n",
    "                    SELECT task_id FROM tasks WHERE emp_no = :emp_no\n",
    "                ) AND ts.period_id <= :period_id\n",
    "                ORDER BY ts.period_id\n",
    "            \"\"\"\n",
    "            )\n",
    "        else:\n",
    "            # 분기: 해당 분기만\n",
    "            query = text(\n",
    "                \"\"\"\n",
    "                SELECT ts.task_summary, ts.task_performance, task_id, period_id\n",
    "                FROM task_summaries ts\n",
    "                WHERE ts.task_id IN (\n",
    "                    SELECT task_id FROM tasks WHERE emp_no = :emp_no\n",
    "                ) AND ts.period_id = :period_id\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "        results = connection.execute(\n",
    "            query, {\"emp_no\": emp_no, \"period_id\": period_id}\n",
    "        ).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "\n",
    "def fetch_task_data_for_proactive(\n",
    "    emp_no: str, period_id: int, report_type: str\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Proactive 평가용 Task 데이터 조회\"\"\"\n",
    "    return fetch_task_data_for_passionate(emp_no, period_id, report_type)\n",
    "\n",
    "\n",
    "def fetch_task_data_for_professional(\n",
    "    emp_no: str, period_id: int, report_type: str\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Professional 평가용 Task 데이터 조회\"\"\"\n",
    "    return fetch_task_data_for_passionate(emp_no, period_id, report_type)\n",
    "\n",
    "\n",
    "def fetch_peer_talk_data(emp_no: str, period_id: int) -> Dict:\n",
    "    \"\"\"Peer Talk 데이터 조회 (실제 테이블 구조 반영)\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        # feedback_reports에서 ai_peer_talk_summary 조회\n",
    "        query = text(\n",
    "            \"\"\"\n",
    "            SELECT fr.ai_peer_talk_summary\n",
    "            FROM feedback_reports fr\n",
    "            JOIN team_evaluations te ON fr.team_evaluation_id = te.team_evaluation_id\n",
    "            WHERE fr.emp_no = :emp_no AND te.period_id <= :period_id\n",
    "            ORDER BY te.period_id DESC\n",
    "            LIMIT 1\n",
    "        \"\"\"\n",
    "        )\n",
    "        result = connection.execute(\n",
    "            query, {\"emp_no\": emp_no, \"period_id\": period_id}\n",
    "        ).fetchone()\n",
    "\n",
    "        if result and result.ai_peer_talk_summary:\n",
    "            return {\"peer_talk_summary\": result.ai_peer_talk_summary}\n",
    "\n",
    "        return {\"peer_talk_summary\": \"동료평가 데이터 없음\"}\n",
    "\n",
    "\n",
    "def fetch_collaboration_matrix_data(emp_no: str, team_id: int, period_id: int) -> Dict:\n",
    "    \"\"\"협업 매트릭스에서 개인 데이터 추출\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\n",
    "            \"\"\"\n",
    "            SELECT ai_collaboration_matrix\n",
    "            FROM team_evaluations\n",
    "            WHERE team_id = :team_id AND period_id <= :period_id\n",
    "            AND ai_collaboration_matrix IS NOT NULL\n",
    "            ORDER BY period_id DESC\n",
    "            LIMIT 1\n",
    "        \"\"\"\n",
    "        )\n",
    "        result = connection.execute(\n",
    "            query, {\"team_id\": team_id, \"period_id\": period_id}\n",
    "        ).fetchone()\n",
    "\n",
    "        if result and result.ai_collaboration_matrix:\n",
    "            try:\n",
    "                matrix_data = json.loads(result.ai_collaboration_matrix)\n",
    "                collaboration_matrix = matrix_data.get(\"collaboration_matrix\", [])\n",
    "\n",
    "                # 해당 직원의 데이터 찾기\n",
    "                for member in collaboration_matrix:\n",
    "                    if member.get(\"emp_no\") == emp_no:\n",
    "                        return member\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "\n",
    "        return {}\n",
    "    \n",
    "\n",
    "# ================================================================\n",
    "# 1. DB에서 평가 기준 가져오는 함수 (간단 버전)\n",
    "# ================================================================\n",
    "\n",
    "def fetch_evaluation_criteria_from_db(prompt_type: str = \"4p_evaluation\") -> str:\n",
    "    \"\"\"DB prompts 테이블에서 평가 기준 가져오기 - 실패시 에러\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT prompt \n",
    "            FROM prompts \n",
    "            LIMIT 1\n",
    "        \"\"\")\n",
    "        \n",
    "        result = connection.execute(query, {\"prompt_type\": prompt_type}).fetchone()\n",
    "        \n",
    "        if result:\n",
    "            return result.prompt\n",
    "        else:\n",
    "            raise ValueError(f\"DB에서 {prompt_type} 평가 기준을 찾을 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 개선된 State 정의\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "class Module6AgentState(TypedDict, total=False):\n",
    "    \"\"\"모듈 6 (4P BARS 평가) 상태 - 병렬 처리 완전 지원\"\"\"\n",
    "\n",
    "    # ✅ 병렬 누적 필드\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    \n",
    "    # ✅ 읽기 전용 기본 정보 (초기 설정 후 변경 안함)\n",
    "    report_type: Literal[\"quarterly\", \"annual\"]\n",
    "    team_id: int\n",
    "    period_id: int\n",
    "    emp_no: str\n",
    "    feedback_report_id: Optional[int]\n",
    "    final_evaluation_report_id: Optional[int]\n",
    "    raw_evaluation_criteria: str\n",
    "    \n",
    "    # ✅ 병렬 업데이트 가능한 딕셔너리 필드들\n",
    "    evaluation_criteria: Annotated[Dict[str, str], lambda x, y: {**x, **y}]\n",
    "    evaluation_results: Annotated[Dict[str, Dict], lambda x, y: {**x, **y}]\n",
    "    integrated_data: Annotated[Dict[str, any], lambda x, y: {**x, **y}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 1. 글로벌 캐시 저장소\n",
    "# ================================================================\n",
    "\n",
    "# 메모리 캐시 (애플리케이션 실행 중 유지)\n",
    "EVALUATION_CRITERIA_CACHE = {\n",
    "    \"raw_text\": None,\n",
    "    \"raw_text_hash\": None,\n",
    "    \"parsed_criteria\": None,\n",
    "    \"last_updated\": None\n",
    "}\n",
    "\n",
    "def get_text_hash(text: str) -> str:\n",
    "    \"\"\"텍스트의 해시값 계산\"\"\"\n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_criteria_with_llm(raw_text: str) -> Dict[str, str]:\n",
    "    \"\"\"독립적인 LLM 파싱 함수 - 문자열 입력\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "당신은 성과 평가 기준을 분석하는 평가 전문가입니다.\n",
    "사용자는 Passionate, Proactive, Professional, People 네 가지 항목의 평가 기준을 하나의 텍스트에 모두 작성했습니다.\n",
    "다만 항목 구분이 명확하지 않을 수 있으므로 문맥을 통해 항목별로 내용을 분리해야 합니다.\n",
    "\n",
    "당신의 작업 결과는 반드시 아래와 같은 JSON 형식이어야 합니다:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"passionate\": \"passionate 평가 기준 텍스트...\",\n",
    "  \"proactive\": \"proactive 평가 기준 텍스트...\",\n",
    "  \"professional\": \"professional 평가 기준 텍스트...\",\n",
    "  \"people\": \"people 평가 기준 텍스트...\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "다음은 DB에서 가져온 전체 평가 기준 텍스트입니다:\n",
    "\n",
    "{raw_text}\n",
    "\n",
    "이 텍스트를 분석하여 4개의 평가 항목으로 나눠주세요.\n",
    "반드시 JSON 형식으로 응답해주세요.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt), \n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm_client\n",
    "    \n",
    "    try:\n",
    "        response = chain.invoke({})\n",
    "        content = response.content\n",
    "        match = re.search(r\"```json\\s*(.*?)```\", content, re.DOTALL)\n",
    "        extracted = match.group(1).strip() if match else content.strip()\n",
    "        parsed = json.loads(extracted)\n",
    "\n",
    "        expected_keys = {\"passionate\", \"proactive\", \"professional\", \"people\"}\n",
    "        if not expected_keys.issubset(parsed.keys()):\n",
    "            raise ValueError(\"4개의 평가 기준 키 중 일부가 누락됨\")\n",
    "\n",
    "        return parsed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 파싱 실패: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def parse_criteria_agent(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"State 기반 파싱 에이전트 - LangGraph용\"\"\"\n",
    "    raw_text = state.get(\"raw_evaluation_criteria\", \"\")\n",
    "    \n",
    "    try:\n",
    "        parsed_criteria = parse_criteria_with_llm(raw_text)  # ✅ 독립 함수 호출\n",
    "        \n",
    "        return {\n",
    "            \"evaluation_criteria\": parsed_criteria,\n",
    "            \"messages\": [\"✅ 평가 기준 LLM 파싱 완료\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"evaluation_criteria\": {},\n",
    "            \"messages\": [f\"❌ 평가 기준 파싱 실패: {str(e)}\"]\n",
    "        }\n",
    "\n",
    "\n",
    "def load_and_cache_evaluation_criteria() -> Dict[str, str]:\n",
    "    \"\"\"수정된 캐시 기반 평가 기준 로더\"\"\"\n",
    "    \n",
    "    # 1. DB에서 현재 평가 기준 텍스트 가져오기\n",
    "    try:\n",
    "        current_raw_text = fetch_evaluation_criteria_from_db()\n",
    "        current_hash = get_text_hash(current_raw_text)\n",
    "        \n",
    "        print(f\"🔍 DB 평가 기준 해시: {current_hash[:8]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ DB 조회 실패: {e}\")\n",
    "        raise e\n",
    "    \n",
    "    # 2. 캐시된 데이터와 비교\n",
    "    cached_hash = EVALUATION_CRITERIA_CACHE.get(\"raw_text_hash\")\n",
    "    cached_parsed = EVALUATION_CRITERIA_CACHE.get(\"parsed_criteria\")\n",
    "    \n",
    "    if cached_hash == current_hash and cached_parsed:\n",
    "        print(\"✅ 캐시된 평가 기준 사용 (DB 텍스트 변경 없음)\")\n",
    "        return cached_parsed\n",
    "    \n",
    "    # 3. 캐시 미스 또는 텍스트 변경 - 새로 파싱\n",
    "    print(\"🔄 평가 기준 새로 파싱 중...\")\n",
    "    \n",
    "    try:\n",
    "        # ✅ 수정: 독립 함수 호출\n",
    "        parsed_criteria = parse_criteria_with_llm(current_raw_text)\n",
    "        \n",
    "        # 4. 캐시 업데이트\n",
    "        EVALUATION_CRITERIA_CACHE.update({\n",
    "            \"raw_text\": current_raw_text,\n",
    "            \"raw_text_hash\": current_hash,\n",
    "            \"parsed_criteria\": parsed_criteria,\n",
    "            \"last_updated\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        print(\"✅ 평가 기준 파싱 완료 및 캐시 업데이트\")\n",
    "        return parsed_criteria\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 평가 기준 파싱 실패: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_evaluation_criteria_agent(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"평가 기준 초기화 - 캐시 활용하여 raw와 parsed 모두 설정\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 캐시 기반으로 평가 기준 로드\n",
    "        parsed_criteria = load_and_cache_evaluation_criteria()\n",
    "        \n",
    "        # 캐시에서 raw_text도 가져오기\n",
    "        raw_text = EVALUATION_CRITERIA_CACHE.get(\"raw_text\", \"\")\n",
    "        \n",
    "        return {\n",
    "            \"raw_evaluation_criteria\": raw_text,  # DB 원본 텍스트\n",
    "            \"evaluation_criteria\": parsed_criteria,  # 파싱된 4P 딕셔너리\n",
    "            \"messages\": [\"✅ 평가 기준 초기화 완료 (캐시 활용)\"]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 평가 기준 초기화 실패: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# LLM 호출 함수들 (동적 수정)\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "def call_llm_for_passionate_evaluation(\n",
    "    task_data: List[Dict], basic_info: Dict, evaluation_criteria: Dict[str, str]\n",
    ") -> Dict:\n",
    "    \"\"\"Passionate (열정적 몰입) LLM 평가\"\"\"\n",
    "\n",
    "    emp_name = basic_info.get(\"emp_name\", \"\")\n",
    "    task_details = \"\"\n",
    "\n",
    "    for task in task_data:\n",
    "        task_details += f\"- 업무 요약: {task.get('task_summary', '')}\\n\"\n",
    "        if task.get(\"task_performance\"):\n",
    "            task_details += f\"  성과: {task.get('task_performance')}\\n\"\n",
    "        task_details += \"\\n\"\n",
    "\n",
    "    if not task_details.strip():\n",
    "        task_details = \"분석할 업무 데이터가 없습니다.\"\n",
    "\n",
    "    # 평가기준을 동적으로 삽입\n",
    "    bars_text = evaluation_criteria.get(\"passionate\", \"\").strip()\n",
    "    if not bars_text:\n",
    "        bars_text = \"평가 기준 없음. 기본 점수로 평가 진행\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    당신은 SK AX 4P 평가 전문가입니다.\n",
    "    Passionate (열정적 몰입) 기준으로 직원을 평가하세요.\n",
    "\n",
    "    평가 기준:\n",
    "    {bars_text}\n",
    "\n",
    "    Passionate 정의: \"이 가치는 규범을 넘어서 헌신과 열정을 가지고 일을 수행하는 것을 강조합니다. 직원들은 에너지와 헌신으로 업무에 임하며, 탁월한 결과를 추구해야 합니다.\"\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <직원 정보>\n",
    "    이름: {emp_name}\n",
    "    </직원 정보>\n",
    "\n",
    "    <업무 데이터>\n",
    "    {task_details}\n",
    "    </업무 데이터>\n",
    "\n",
    "    위 데이터를 바탕으로 Passionate 관점에서 평가하세요.\n",
    "\n",
    "\n",
    "    응답은 반드시 다음 JSON 형식으로 작성하세요:\n",
    "    ```json\n",
    "    {{\n",
    "        \"score\": [1-5점 사이의 숫자],\n",
    "        \"evidence\": [\"구체적 근거1\", \"구체적 근거2\", \"구체적 근거3\"],\n",
    "        \"reasoning\": \"평가 근거 설명\",\n",
    "        \"bars_level\": \"해당 활동이 부합한 평가 기준의 레이블 (예: '탁월한 열정', '성실한 수행' 등)\",\n",
    "        \"improvement_points\": [\"개선점1\", \"개선점2\"]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [SystemMessage(content=system_prompt), HumanMessage(content=human_prompt)]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response = chain.invoke({})\n",
    "        json_output = _extract_json_from_llm_response(response.content)\n",
    "        result = json.loads(json_output)\n",
    "\n",
    "        # 유효성 검증\n",
    "        if not isinstance(result.get(\"score\"), (int, float)) or not (\n",
    "            1 <= result[\"score\"] <= 5\n",
    "        ):\n",
    "            result[\"score\"] = 3.0\n",
    "        if not isinstance(result.get(\"evidence\"), list):\n",
    "            result[\"evidence\"] = [\"평가 근거 생성 실패\"]\n",
    "        if not result.get(\"reasoning\"):\n",
    "            result[\"reasoning\"] = \"기본 평가\"\n",
    "        if not result.get(\"bars_level\"):\n",
    "            result[\"bars_level\"] = \"기본 열정\"\n",
    "        if not isinstance(result.get(\"improvement_points\"), list):\n",
    "            result[\"improvement_points\"] = [\"지속적 개선 필요\"]\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Passionate 평가 LLM 오류: {e}\")\n",
    "        return {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"AI 평가 실패\"],\n",
    "            \"reasoning\": f\"평가 중 오류 발생: {str(e)[:100]}\",\n",
    "            \"bars_level\": \"기본 열정\",\n",
    "            \"improvement_points\": [\"평가 재시도 필요\"],\n",
    "        }\n",
    "\n",
    "\n",
    "def call_llm_for_proactive_evaluation(\n",
    "    task_data: List[Dict], basic_info: Dict, evaluation_criteria: Dict[str, str]\n",
    ") -> Dict:\n",
    "    \"\"\"Proactive (능동적 주도) LLM 평가\"\"\"\n",
    "\n",
    "    emp_name = basic_info.get(\"emp_name\", \"\")\n",
    "    task_details = \"\"\n",
    "\n",
    "    for task in task_data:\n",
    "        task_details += f\"- 업무 요약: {task.get('task_summary', '')}\\n\"\n",
    "        if task.get(\"task_performance\"):\n",
    "            task_details += f\"  성과: {task.get('task_performance')}\\n\"\n",
    "        task_details += \"\\n\"\n",
    "\n",
    "    if not task_details.strip():\n",
    "        task_details = \"분석할 업무 데이터가 없습니다.\"\n",
    "\n",
    "    # 평가기준을 동적으로 삽입\n",
    "    bars_text = evaluation_criteria.get(\"proactive\", \"\").strip()\n",
    "    if not bars_text:\n",
    "        bars_text = \"평가 기준 없음. 기본 점수로 평가 진행\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    당신은 SK AX 4P 평가 전문가입니다.\n",
    "    Proactive (능동적 주도) 기준으로 직원을 평가하세요.\n",
    "\n",
    "    평가 기준:\n",
    "    {bars_text}\n",
    "\n",
    "    Proactive 정의: \"주도적인 태도를 취하고 미래를 대비하는 자세를 장려합니다. 직원들은 도전 과제를 예측하고, 기회를 찾으며, 긍정적인 결과를 이끌어내기 위해 능동적으로 행동해야 합니다.\"\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <직원 정보>\n",
    "    이름: {emp_name}\n",
    "    </직원 정보>\n",
    "\n",
    "    <업무 데이터>\n",
    "    {task_details}\n",
    "    </업무 데이터>\n",
    "\n",
    "    위 데이터를 바탕으로 Proactive 관점에서 평가하세요.\n",
    "\n",
    "\n",
    "    응답은 반드시 다음 JSON 형식으로 작성하세요:\n",
    "    ```json\n",
    "    {{\n",
    "        \"score\": [1-5점 사이의 숫자],\n",
    "        \"evidence\": [\"구체적 근거1\", \"구체적 근거2\", \"구체적 근거3\"],\n",
    "        \"reasoning\": \"평가 근거 설명\",\n",
    "        \"bars_level\": \"해당 활동이 부합한 평가 기준의 레이블 (예: '탁월한 열정', '성실한 수행' 등)\",\n",
    "        \"improvement_points\": [\"개선점1\", \"개선점2\"]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [SystemMessage(content=system_prompt), HumanMessage(content=human_prompt)]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response = chain.invoke({})\n",
    "        json_output = _extract_json_from_llm_response(response.content)\n",
    "        result = json.loads(json_output)\n",
    "\n",
    "        if not isinstance(result.get(\"score\"), (int, float)) or not (\n",
    "            1 <= result[\"score\"] <= 5\n",
    "        ):\n",
    "            result[\"score\"] = 3.0\n",
    "        if not isinstance(result.get(\"evidence\"), list):\n",
    "            result[\"evidence\"] = [\"평가 근거 생성 실패\"]\n",
    "        if not result.get(\"reasoning\"):\n",
    "            result[\"reasoning\"] = \"기본 평가\"\n",
    "        if not result.get(\"bars_level\"):\n",
    "            result[\"bars_level\"] = \"기본 주도성\"\n",
    "        if not isinstance(result.get(\"improvement_points\"), list):\n",
    "            result[\"improvement_points\"] = [\"지속적 개선 필요\"]\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Proactive 평가 LLM 오류: {e}\")\n",
    "        return {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"AI 평가 실패\"],\n",
    "            \"reasoning\": f\"평가 중 오류 발생: {str(e)[:100]}\",\n",
    "            \"bars_level\": \"기본 주도성\",\n",
    "            \"improvement_points\": [\"평가 재시도 필요\"],\n",
    "        }\n",
    "\n",
    "\n",
    "def call_llm_for_professional_evaluation(\n",
    "    task_data: List[Dict], basic_info: Dict, evaluation_criteria: Dict[str, str]\n",
    ") -> Dict:\n",
    "    \"\"\"Professional (전문성) LLM 평가\"\"\"\n",
    "\n",
    "    emp_name = basic_info.get(\"emp_name\", \"\")\n",
    "    position = basic_info.get(\"position\", \"\")\n",
    "    task_details = \"\"\n",
    "\n",
    "    for task in task_data:\n",
    "        task_details += f\"- 업무 요약: {task.get('task_summary', '')}\\n\"\n",
    "        if task.get(\"task_performance\"):\n",
    "            task_details += f\"  성과: {task.get('task_performance')}\\n\"\n",
    "        task_details += \"\\n\"\n",
    "\n",
    "    if not task_details.strip():\n",
    "        task_details = \"분석할 업무 데이터가 없습니다.\"\n",
    "\n",
    "    bars_text = evaluation_criteria.get(\"professional\", \"\").strip()\n",
    "    if not bars_text:\n",
    "        bars_text = \"평가 기준 없음. 기본 점수로 평가 진행\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    당신은 SK AX 4P 평가 전문가입니다.\n",
    "    Professional (전문성) 기준으로 직원을 평가하세요.\n",
    "\n",
    "    평가 기준:\n",
    "    {bars_text}\n",
    "\n",
    "    Professional 정의: \"모든 업무에서 전문성을 유지하는 중요성을 강조합니다. 직원들은 높은 윤리적 기준과 직무 능력을 바탕으로 일을 수행하고 회사의 가치를 대표해야 합니다.\"\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <직원 정보>\n",
    "    이름: {emp_name}\n",
    "    직책: {position}\n",
    "    </직원 정보>\n",
    "\n",
    "    <업무 데이터>\n",
    "    {task_details}\n",
    "    </업무 데이터>\n",
    "\n",
    "    위 데이터를 바탕으로 Professional 관점에서 평가하세요.\n",
    "\n",
    "\n",
    "    응답은 반드시 다음 JSON 형식으로 작성하세요:\n",
    "    ```json\n",
    "    {{\n",
    "        \"score\": [1-5점 사이의 숫자],\n",
    "        \"evidence\": [\"구체적 근거1\", \"구체적 근거2\", \"구체적 근거3\"],\n",
    "        \"reasoning\": \"평가 근거 설명\",\n",
    "        \"bars_level\": \"해당 활동이 부합한 평가 기준의 레이블 (예: '탁월한 열정', '성실한 수행' 등)\",\n",
    "        \"improvement_points\": [\"개선점1\", \"개선점2\"]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [SystemMessage(content=system_prompt), HumanMessage(content=human_prompt)]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response = chain.invoke({})\n",
    "        json_output = _extract_json_from_llm_response(response.content)\n",
    "        result = json.loads(json_output)\n",
    "\n",
    "        if not isinstance(result.get(\"score\"), (int, float)) or not (\n",
    "            1 <= result[\"score\"] <= 5\n",
    "        ):\n",
    "            result[\"score\"] = 3.0\n",
    "        if not isinstance(result.get(\"evidence\"), list):\n",
    "            result[\"evidence\"] = [\"평가 근거 생성 실패\"]\n",
    "        if not result.get(\"reasoning\"):\n",
    "            result[\"reasoning\"] = \"기본 평가\"\n",
    "        if not result.get(\"bars_level\"):\n",
    "            result[\"bars_level\"] = \"기본 전문성\"\n",
    "        if not isinstance(result.get(\"improvement_points\"), list):\n",
    "            result[\"improvement_points\"] = [\"지속적 개선 필요\"]\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Professional 평가 LLM 오류: {e}\")\n",
    "        return {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"AI 평가 실패\"],\n",
    "            \"reasoning\": f\"평가 중 오류 발생: {str(e)[:100]}\",\n",
    "            \"bars_level\": \"기본 전문성\",\n",
    "            \"improvement_points\": [\"평가 재시도 필요\"],\n",
    "        }\n",
    "\n",
    "\n",
    "def call_llm_for_people_evaluation(\n",
    "    task_data: List[Dict],\n",
    "    collaboration_data: Dict,\n",
    "    peer_talk_data: Dict,\n",
    "    basic_info: Dict,\n",
    "    evaluation_criteria: Dict[str, str],\n",
    ") -> Dict:\n",
    "    \"\"\"People (공동체) LLM 평가\"\"\"\n",
    "\n",
    "    emp_name = basic_info.get(\"emp_name\", \"\")\n",
    "\n",
    "    # 협업 데이터 정리\n",
    "    collaboration_info = \"\"\n",
    "    if collaboration_data:\n",
    "        collaboration_info = f\"\"\"\n",
    "        팀 역할: {collaboration_data.get('team_role', '')}\n",
    "        협업률: {collaboration_data.get('collaboration_rate', 0)}%\n",
    "        핵심 협업자: {', '.join(collaboration_data.get('key_collaborators', []))}\n",
    "        동료평가 요약: {collaboration_data.get('peer_talk_summary', '')}\n",
    "        전체 평가: {collaboration_data.get('overall_evaluation', '')}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        collaboration_info = \"협업 데이터 없음\"\n",
    "\n",
    "    # Peer Talk 데이터\n",
    "    peer_talk_summary = peer_talk_data.get(\"peer_talk_summary\", \"동료평가 없음\")\n",
    "\n",
    "    # Task 데이터에서 협업 관련 내용 추출\n",
    "    collaboration_tasks = \"\"\n",
    "    for task in task_data:\n",
    "        if any(\n",
    "            keyword in task.get(\"task_summary\", \"\")\n",
    "            for keyword in [\"협업\", \"함께\", \"공동\", \"팀\", \"동료\"]\n",
    "        ):\n",
    "            collaboration_tasks += f\"- {task.get('task_summary', '')}\\n\"\n",
    "\n",
    "    # 평가기준을 동적으로 삽입\n",
    "    bars_text = evaluation_criteria.get(\"people\", \"\").strip()\n",
    "    if not bars_text:\n",
    "        bars_text = \"평가 기준 없음. 기본 점수로 평가 진행\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    당신은 SK AX 4P 평가 전문가입니다.\n",
    "    People (공동체) 기준으로 직원을 평가하세요.\n",
    "\n",
    "    평가 기준:\n",
    "    {bars_text}\n",
    "\n",
    "    People 정의: \"조직 내에서 의미 있는 관계와 팀워크를 형성하는 데 중점을 둡니다. 동료, 이해관계자, 고객과의 협력, 공감, 존중을 장려합니다.\"\n",
    "    \"\"\"\n",
    "\n",
    "    human_prompt = f\"\"\"\n",
    "    <직원 정보>\n",
    "    이름: {emp_name}\n",
    "    </직원 정보>\n",
    "\n",
    "    <협업 데이터>\n",
    "    {collaboration_info}\n",
    "    </협업 데이터>\n",
    "\n",
    "    <동료평가 데이터>\n",
    "    {peer_talk_summary}\n",
    "    </동료평가 데이터>\n",
    "\n",
    "    <협업 관련 업무>\n",
    "    {collaboration_tasks if collaboration_tasks else '협업 관련 업무 데이터 없음'}\n",
    "    </협업 관련 업무>\n",
    "\n",
    "    위 데이터를 바탕으로 People 관점에서 평가하세요.\n",
    "\n",
    "    응답은 반드시 다음 JSON 형식으로 작성하세요:\n",
    "    ```json\n",
    "    {{\n",
    "        \"score\": [1-5점 사이의 숫자],\n",
    "        \"evidence\": [\"구체적 근거1\", \"구체적 근거2\", \"구체적 근거3\"],\n",
    "        \"reasoning\": \"평가 근거 설명\",\n",
    "        \"bars_level\": \"해당 활동이 부합한 평가 기준의 레이블 (예: '탁월한 열정', '성실한 수행' 등)\",\n",
    "        \"improvement_points\": [\"개선점1\", \"개선점2\"]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [SystemMessage(content=system_prompt), HumanMessage(content=human_prompt)]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response = chain.invoke({})\n",
    "        json_output = _extract_json_from_llm_response(response.content)\n",
    "        result = json.loads(json_output)\n",
    "\n",
    "        if not isinstance(result.get(\"score\"), (int, float)) or not (\n",
    "            1 <= result[\"score\"] <= 5\n",
    "        ):\n",
    "            result[\"score\"] = 3.0\n",
    "        if not isinstance(result.get(\"evidence\"), list):\n",
    "            result[\"evidence\"] = [\"평가 근거 생성 실패\"]\n",
    "        if not result.get(\"reasoning\"):\n",
    "            result[\"reasoning\"] = \"기본 평가\"\n",
    "        if not result.get(\"bars_level\"):\n",
    "            result[\"bars_level\"] = \"기본적 협력\"\n",
    "        if not isinstance(result.get(\"improvement_points\"), list):\n",
    "            result[\"improvement_points\"] = [\"지속적 개선 필요\"]\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"People 평가 LLM 오류: {e}\")\n",
    "        return {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"AI 평가 실패\"],\n",
    "            \"reasoning\": f\"평가 중 오류 발생: {str(e)[:100]}\",\n",
    "            \"bars_level\": \"기본적 협력\",\n",
    "            \"improvement_points\": [\"평가 재시도 필요\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# DB 저장 함수들 (실제 테이블 구조 반영)\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "def save_quarterly_4p_results(feedback_report_id: int, integrated_result: Dict) -> bool:\n",
    "    \"\"\"분기 4P 결과를 feedback_reports 테이블에 저장\"\"\"\n",
    "\n",
    "    # 각 P별 대표 evidence 1개씩 선택 (가장 임팩트 있는 것)\n",
    "    passionate_highlight = (\n",
    "        integrated_result[\"passionate\"][\"evidence\"][0]\n",
    "        if integrated_result[\"passionate\"][\"evidence\"]\n",
    "        else \"열정적 업무 수행\"\n",
    "    )\n",
    "    proactive_highlight = (\n",
    "        integrated_result[\"proactive\"][\"evidence\"][0]\n",
    "        if integrated_result[\"proactive\"][\"evidence\"]\n",
    "        else \"주도적 업무 진행\"\n",
    "    )\n",
    "    professional_highlight = (\n",
    "        integrated_result[\"professional\"][\"evidence\"][0]\n",
    "        if integrated_result[\"professional\"][\"evidence\"]\n",
    "        else \"전문적 업무 수행\"\n",
    "    )\n",
    "    people_highlight = (\n",
    "        integrated_result[\"people\"][\"evidence\"][0]\n",
    "        if integrated_result[\"people\"][\"evidence\"]\n",
    "        else \"협력적 업무 참여\"\n",
    "    )\n",
    "\n",
    "    # 분기용 깔끔한 5줄 개조식 텍스트\n",
    "    quarterly_text = f\"\"\"* Passionate 성과 하이라이트: {passionate_highlight}\n",
    "* Proactive 주도적 성과: {proactive_highlight}\n",
    "* Professional 전문성 발휘: {professional_highlight}  \n",
    "* People 협업 기여: {people_highlight}\n",
    "* 종합 평가: {integrated_result['comprehensive_assessment']}\"\"\".strip()\n",
    "\n",
    "    quarterly_format = {\n",
    "        \"evaluation_text\": quarterly_text,\n",
    "        \"scores\": {\n",
    "            \"passionate\": integrated_result[\"passionate\"][\"score\"],\n",
    "            \"proactive\": integrated_result[\"proactive\"][\"score\"],\n",
    "            \"professional\": integrated_result[\"professional\"][\"score\"],\n",
    "            \"people\": integrated_result[\"people\"][\"score\"],\n",
    "            \"average\": integrated_result[\"average_score\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        # ai_4p_evaluation 컬럼이 있는지 확인하고 없으면 추가\n",
    "        try:\n",
    "            query = text(\n",
    "                \"\"\"\n",
    "                UPDATE feedback_reports \n",
    "                SET ai_4p_evaluation = :ai_4p_evaluation\n",
    "                WHERE feedback_report_id = :feedback_report_id\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "            result = connection.execute(\n",
    "                query,\n",
    "                {\n",
    "                    \"feedback_report_id\": feedback_report_id,\n",
    "                    \"ai_4p_evaluation\": json.dumps(\n",
    "                        quarterly_format, ensure_ascii=False\n",
    "                    ),\n",
    "                },\n",
    "            )\n",
    "            connection.commit()\n",
    "            return result.rowcount > 0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"분기 저장 오류: {e}\")\n",
    "            # 컬럼이 없다면 추가 시도\n",
    "            try:\n",
    "                connection.execute(\n",
    "                    text(\n",
    "                        \"ALTER TABLE feedback_reports ADD COLUMN ai_4p_evaluation TEXT\"\n",
    "                    )\n",
    "                )\n",
    "                connection.commit()\n",
    "                print(\"ai_4p_evaluation 컬럼 추가됨\")\n",
    "\n",
    "                # 다시 저장 시도\n",
    "                result = connection.execute(\n",
    "                    query,\n",
    "                    {\n",
    "                        \"feedback_report_id\": feedback_report_id,\n",
    "                        \"ai_4p_evaluation\": json.dumps(\n",
    "                            quarterly_format, ensure_ascii=False\n",
    "                        ),\n",
    "                    },\n",
    "                )\n",
    "                connection.commit()\n",
    "                return result.rowcount > 0\n",
    "            except Exception as e2:\n",
    "                print(f\"컬럼 추가 실패: {e2}\")\n",
    "                return False\n",
    "\n",
    "\n",
    "def save_annual_4p_results(\n",
    "    final_evaluation_report_id: int, integrated_result: Dict\n",
    ") -> bool:\n",
    "    \"\"\"연말 4P 결과를 final_evaluation_reports 테이블에 저장\"\"\"\n",
    "\n",
    "    # 연말용 상세 포맷\n",
    "    annual_format = {\n",
    "        \"passionate\": {\n",
    "            \"score\": integrated_result[\"passionate\"][\"score\"],\n",
    "            \"level\": integrated_result[\"passionate\"][\"bars_level\"],\n",
    "            \"reasoning\": integrated_result[\"passionate\"][\"reasoning\"],\n",
    "            \"evidence\": integrated_result[\"passionate\"][\"evidence\"],\n",
    "            \"improvement_points\": integrated_result[\"passionate\"][\"improvement_points\"],\n",
    "        },\n",
    "        \"proactive\": {\n",
    "            \"score\": integrated_result[\"proactive\"][\"score\"],\n",
    "            \"level\": integrated_result[\"proactive\"][\"bars_level\"],\n",
    "            \"reasoning\": integrated_result[\"proactive\"][\"reasoning\"],\n",
    "            \"evidence\": integrated_result[\"proactive\"][\"evidence\"],\n",
    "            \"improvement_points\": integrated_result[\"proactive\"][\"improvement_points\"],\n",
    "        },\n",
    "        \"professional\": {\n",
    "            \"score\": integrated_result[\"professional\"][\"score\"],\n",
    "            \"level\": integrated_result[\"professional\"][\"bars_level\"],\n",
    "            \"reasoning\": integrated_result[\"professional\"][\"reasoning\"],\n",
    "            \"evidence\": integrated_result[\"professional\"][\"evidence\"],\n",
    "            \"improvement_points\": integrated_result[\"professional\"][\n",
    "                \"improvement_points\"\n",
    "            ],\n",
    "        },\n",
    "        \"people\": {\n",
    "            \"score\": integrated_result[\"people\"][\"score\"],\n",
    "            \"level\": integrated_result[\"people\"][\"bars_level\"],\n",
    "            \"reasoning\": integrated_result[\"people\"][\"reasoning\"],\n",
    "            \"evidence\": integrated_result[\"people\"][\"evidence\"],\n",
    "            \"improvement_points\": integrated_result[\"people\"][\"improvement_points\"],\n",
    "        },\n",
    "        \"overall\": {\n",
    "            \"average_score\": integrated_result[\"average_score\"],\n",
    "            \"overall_level\": integrated_result[\"overall_level\"],\n",
    "            \"top_strength\": integrated_result[\"top_strength\"],\n",
    "            \"improvement_area\": integrated_result[\"improvement_area\"],\n",
    "            \"balance_analysis\": integrated_result[\"balance_analysis\"],\n",
    "            \"comprehensive_assessment\": integrated_result[\"comprehensive_assessment\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            query = text(\n",
    "                \"\"\"\n",
    "                UPDATE final_evaluation_reports \n",
    "                SET ai_4p_evaluation = :ai_4p_evaluation\n",
    "                WHERE final_evaluation_report_id = :final_evaluation_report_id\n",
    "            \"\"\"\n",
    "            )\n",
    "\n",
    "            result = connection.execute(\n",
    "                query,\n",
    "                {\n",
    "                    \"final_evaluation_report_id\": final_evaluation_report_id,\n",
    "                    \"ai_4p_evaluation\": json.dumps(annual_format, ensure_ascii=False),\n",
    "                },\n",
    "            )\n",
    "            connection.commit()\n",
    "            return result.rowcount > 0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"연말 저장 오류: {e}\")\n",
    "            # 컬럼이 없다면 추가 시도\n",
    "            try:\n",
    "                connection.execute(\n",
    "                    text(\n",
    "                        \"ALTER TABLE final_evaluation_reports ADD COLUMN ai_4p_evaluation TEXT\"\n",
    "                    )\n",
    "                )\n",
    "                connection.commit()\n",
    "                print(\"final_evaluation_reports.ai_4p_evaluation 컬럼 추가됨\")\n",
    "\n",
    "                # 다시 저장 시도\n",
    "                result = connection.execute(\n",
    "                    query,\n",
    "                    {\n",
    "                        \"final_evaluation_report_id\": final_evaluation_report_id,\n",
    "                        \"ai_4p_evaluation\": json.dumps(\n",
    "                            annual_format, ensure_ascii=False\n",
    "                        ),\n",
    "                    },\n",
    "                )\n",
    "                connection.commit()\n",
    "                return result.rowcount > 0\n",
    "            except Exception as e2:\n",
    "                print(f\"컬럼 추가 실패: {e2}\")\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 서브모듈 함수들 (State 관리 수정)\n",
    "# ================================================================\n",
    "\n",
    "\n",
    "def passionate_evaluation_submodule(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"Passionate 평가 서브모듈 - 수정됨\"\"\"\n",
    "    \n",
    "    emp_no = state[\"emp_no\"]\n",
    "    period_id = state[\"period_id\"]\n",
    "    report_type = state[\"report_type\"]\n",
    "    evaluation_criteria = state.get(\"evaluation_criteria\", {})\n",
    "\n",
    "    print(f\"Passionate 평가 시작: {emp_no}\")\n",
    "\n",
    "    basic_info = fetch_employee_basic_info(emp_no)\n",
    "    task_data = fetch_task_data_for_passionate(emp_no, period_id, report_type)\n",
    "\n",
    "    if not basic_info:\n",
    "        passionate_result = {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"직원 정보 없음\"],\n",
    "            \"reasoning\": \"직원 정보를 찾을 수 없어 기본 평가\",\n",
    "            \"bars_level\": \"기본 열정\",\n",
    "            \"improvement_points\": [\"정보 확인 필요\"],\n",
    "        }\n",
    "    else:\n",
    "        passionate_result = call_llm_for_passionate_evaluation(\n",
    "            task_data, basic_info, evaluation_criteria\n",
    "        )\n",
    "\n",
    "    # ✅ 특정 키만 반환\n",
    "    return {\n",
    "        \"evaluation_results\": {\"passionate\": passionate_result},\n",
    "        \"messages\": [f\"Passionate 평가 완료: {passionate_result['score']}점 ({passionate_result['bars_level']})\"]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def proactive_evaluation_submodule(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"Proactive 평가 서브모듈 - 수정됨\"\"\"\n",
    "    \n",
    "    emp_no = state[\"emp_no\"]\n",
    "    period_id = state[\"period_id\"]\n",
    "    report_type = state[\"report_type\"]\n",
    "    evaluation_criteria = state.get(\"evaluation_criteria\", {})\n",
    "\n",
    "    print(f\"Proactive 평가 시작: {emp_no}\")\n",
    "\n",
    "    basic_info = fetch_employee_basic_info(emp_no)\n",
    "    task_data = fetch_task_data_for_proactive(emp_no, period_id, report_type)\n",
    "\n",
    "    if not basic_info:\n",
    "        proactive_result = {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"직원 정보 없음\"],\n",
    "            \"reasoning\": \"직원 정보를 찾을 수 없어 기본 평가\",\n",
    "            \"bars_level\": \"기본 주도성\",\n",
    "            \"improvement_points\": [\"정보 확인 필요\"],\n",
    "        }\n",
    "    else:\n",
    "        proactive_result = call_llm_for_proactive_evaluation(task_data, basic_info, evaluation_criteria)\n",
    "\n",
    "    # ✅ 특정 키만 반환\n",
    "    return {\n",
    "        \"evaluation_results\": {\"proactive\": proactive_result},\n",
    "        \"messages\": [f\"Proactive 평가 완료: {proactive_result['score']}점 ({proactive_result['bars_level']})\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def professional_evaluation_submodule(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"Professional 평가 서브모듈 - 수정됨\"\"\"\n",
    "    \n",
    "    emp_no = state[\"emp_no\"]\n",
    "    period_id = state[\"period_id\"]\n",
    "    report_type = state[\"report_type\"]\n",
    "    evaluation_criteria = state.get(\"evaluation_criteria\", {})\n",
    "\n",
    "    print(f\"Professional 평가 시작: {emp_no}\")\n",
    "\n",
    "    basic_info = fetch_employee_basic_info(emp_no)\n",
    "    task_data = fetch_task_data_for_professional(emp_no, period_id, report_type)\n",
    "\n",
    "    if not basic_info:\n",
    "        professional_result = {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"직원 정보 없음\"],\n",
    "            \"reasoning\": \"직원 정보를 찾을 수 없어 기본 평가\",\n",
    "            \"bars_level\": \"기본 전문성\",\n",
    "            \"improvement_points\": [\"정보 확인 필요\"],\n",
    "        }\n",
    "    else:\n",
    "        professional_result = call_llm_for_professional_evaluation(\n",
    "            task_data, basic_info, evaluation_criteria\n",
    "        )\n",
    "\n",
    "    # ✅ 특정 키만 반환\n",
    "    return {\n",
    "        \"evaluation_results\": {\"professional\": professional_result},\n",
    "        \"messages\": [f\"Professional 평가 완료: {professional_result['score']}점 ({professional_result['bars_level']})\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def people_evaluation_submodule(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"People 평가 서브모듈 - 수정됨\"\"\"\n",
    "    \n",
    "    emp_no = state[\"emp_no\"]\n",
    "    period_id = state[\"period_id\"]\n",
    "    team_id = state[\"team_id\"]\n",
    "    evaluation_criteria = state.get(\"evaluation_criteria\", {})\n",
    "\n",
    "    print(f\"People 평가 시작: {emp_no}\")\n",
    "\n",
    "    basic_info = fetch_employee_basic_info(emp_no)\n",
    "    task_data = fetch_task_data_for_professional(emp_no, period_id, state[\"report_type\"])\n",
    "    collaboration_data = fetch_collaboration_matrix_data(emp_no, team_id, period_id)\n",
    "    peer_talk_data = fetch_peer_talk_data(emp_no, period_id)\n",
    "\n",
    "    if not basic_info:\n",
    "        people_result = {\n",
    "            \"score\": 3.0,\n",
    "            \"evidence\": [\"직원 정보 없음\"],\n",
    "            \"reasoning\": \"직원 정보를 찾을 수 없어 기본 평가\",\n",
    "            \"bars_level\": \"기본적 협력\",\n",
    "            \"improvement_points\": [\"정보 확인 필요\"],\n",
    "        }\n",
    "    else:\n",
    "        people_result = call_llm_for_people_evaluation(\n",
    "            task_data, collaboration_data, peer_talk_data, basic_info, evaluation_criteria\n",
    "        )\n",
    "\n",
    "    # ✅ 특정 키만 반환\n",
    "    return {\n",
    "        \"evaluation_results\": {\"people\": people_result},\n",
    "        \"messages\": [f\"People 평가 완료: {people_result['score']}점 ({people_result['bars_level']})\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def bars_integration_submodule(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"4P 통합 평가 서브모듈 - 수정됨\"\"\"\n",
    "    \n",
    "    evaluation_results = state.get(\"evaluation_results\", {})\n",
    "    passionate = evaluation_results.get(\"passionate\", {})\n",
    "    proactive = evaluation_results.get(\"proactive\", {})\n",
    "    professional = evaluation_results.get(\"professional\", {})\n",
    "    people = evaluation_results.get(\"people\", {})\n",
    "\n",
    "    print(\"4P 통합 평가 시작\")\n",
    "\n",
    "    # 4P 평균 점수 계산\n",
    "    scores = [\n",
    "        passionate.get(\"score\", 3.0),\n",
    "        proactive.get(\"score\", 3.0),\n",
    "        professional.get(\"score\", 3.0),\n",
    "        people.get(\"score\", 3.0),\n",
    "    ]\n",
    "    average_score = sum(scores) / len(scores)\n",
    "\n",
    "    # 강점/약점 분석\n",
    "    score_dict = {\n",
    "        \"passionate\": passionate.get(\"score\", 3.0),\n",
    "        \"proactive\": proactive.get(\"score\", 3.0),\n",
    "        \"professional\": professional.get(\"score\", 3.0),\n",
    "        \"people\": people.get(\"score\", 3.0),\n",
    "    }\n",
    "\n",
    "    top_strength = max(score_dict, key=score_dict.get)\n",
    "    improvement_area = min(score_dict, key=score_dict.get)\n",
    "\n",
    "    # 4P 균형도 분석\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "    balance_gap = max_score - min_score\n",
    "\n",
    "    if balance_gap <= 0.5:\n",
    "        balance_analysis = \"4P 영역이 매우 균형있게 발달\"\n",
    "    elif balance_gap <= 1.0:\n",
    "        balance_analysis = f\"{top_strength.capitalize()} 영역이 강하며, 전반적으로 균형 잡힌 발전\"\n",
    "    else:\n",
    "        balance_analysis = f\"{top_strength.capitalize()} 영역이 특히 강하며, {improvement_area.capitalize()} 영역에서 성장 여지\"\n",
    "\n",
    "    # 종합 평가\n",
    "    if average_score >= 4.5:\n",
    "        overall_level = \"탁월\"\n",
    "    elif average_score >= 4.0:\n",
    "        overall_level = \"우수\"\n",
    "    elif average_score >= 3.5:\n",
    "        overall_level = \"양호\"\n",
    "    elif average_score >= 3.0:\n",
    "        overall_level = \"보통\"\n",
    "    else:\n",
    "        overall_level = \"개선 필요\"\n",
    "\n",
    "    integrated_result = {\n",
    "        \"scores\": score_dict,\n",
    "        \"average_score\": round(average_score, 2),\n",
    "        \"top_strength\": top_strength,\n",
    "        \"improvement_area\": improvement_area,\n",
    "        \"balance_analysis\": balance_analysis,\n",
    "        \"overall_level\": overall_level,\n",
    "        \"comprehensive_assessment\": f\"{overall_level} 수준의 4P 역량을 보유하고 있으며, {balance_analysis}\",\n",
    "        \"passionate\": passionate,\n",
    "        \"proactive\": proactive,\n",
    "        \"professional\": professional,\n",
    "        \"people\": people,\n",
    "    }\n",
    "\n",
    "    # ✅ 특정 키만 반환\n",
    "    return {\n",
    "        \"integrated_data\": {\"integrated_4p_result\": integrated_result},\n",
    "        \"messages\": [f\"4P 통합 평가 완료: 평균 {average_score:.1f}점 ({overall_level})\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def quarterly_format_and_save_submodule(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"분기 저장 서브모듈 - 수정됨\"\"\"\n",
    "    \n",
    "    feedback_report_id = state.get(\"feedback_report_id\")\n",
    "    integrated_result = state.get(\"integrated_data\", {}).get(\"integrated_4p_result\", {})\n",
    "\n",
    "    print(f\"분기 결과 저장 시작: feedback_report_id={feedback_report_id}\")\n",
    "\n",
    "    if not feedback_report_id:\n",
    "        return {\"messages\": [\"분기 저장 실패: feedback_report_id 없음\"]}\n",
    "\n",
    "    success = save_quarterly_4p_results(feedback_report_id, integrated_result)\n",
    "\n",
    "    if success:\n",
    "        message = f\"분기 4P 평가 결과 저장 완료 (ID: {feedback_report_id})\"\n",
    "    else:\n",
    "        message = \"분기 4P 평가 결과 저장 실패\"\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "def annual_format_and_save_submodule(state: Module6AgentState) -> Dict:\n",
    "    \"\"\"연말 저장 서브모듈 - 수정됨\"\"\"\n",
    "    \n",
    "    final_evaluation_report_id = state.get(\"final_evaluation_report_id\")\n",
    "    integrated_result = state.get(\"integrated_data\", {}).get(\"integrated_4p_result\", {})\n",
    "\n",
    "    print(f\"연말 결과 저장 시작: final_evaluation_report_id={final_evaluation_report_id}\")\n",
    "\n",
    "    if not final_evaluation_report_id:\n",
    "        return {\"messages\": [\"연말 저장 실패: final_evaluation_report_id 없음\"]}\n",
    "        \n",
    "    if not integrated_result:\n",
    "        return {\"messages\": [\"연말 저장 실패: integrated_4p_result가 전달되지 않음\"]}\n",
    "\n",
    "    success = save_annual_4p_results(final_evaluation_report_id, integrated_result)\n",
    "\n",
    "    if success:\n",
    "        message = f\"연말 4P 평가 결과 저장 완료 (ID: {final_evaluation_report_id})\"\n",
    "    else:\n",
    "        message = \"연말 4P 평가 결과 저장 실패\"\n",
    "\n",
    "    return {\"messages\": [message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "캐싱 이후 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_module6_graph_efficient():\n",
    "    \"\"\"효율적인 모듈 6 그래프 - 파싱 단계 없음\"\"\"\n",
    "    module6 = StateGraph(Module6AgentState)\n",
    "\n",
    "    # 노드 정의 (initialize만 있음, parse 제거)\n",
    "    module6.add_node(\"initialize_criteria\", initialize_evaluation_criteria_agent)  # 👈 캐시 기반\n",
    "    module6.add_node(\"passionate_evaluation\", passionate_evaluation_submodule)\n",
    "    module6.add_node(\"proactive_evaluation\", proactive_evaluation_submodule)\n",
    "    module6.add_node(\"professional_evaluation\", professional_evaluation_submodule)\n",
    "    module6.add_node(\"people_evaluation\", people_evaluation_submodule)\n",
    "    module6.add_node(\"bars_integration\", bars_integration_submodule)\n",
    "    module6.add_node(\"quarterly_format_and_save\", quarterly_format_and_save_submodule)\n",
    "    module6.add_node(\"annual_format_and_save\", annual_format_and_save_submodule)\n",
    "\n",
    "    # 흐름 (initialize → 바로 평가들)\n",
    "    module6.add_edge(START, \"initialize_criteria\")\n",
    "    \n",
    "    # initialize → 4개 평가 노드 직접 연결\n",
    "    module6.add_edge(\"initialize_criteria\", \"passionate_evaluation\")\n",
    "    module6.add_edge(\"initialize_criteria\", \"proactive_evaluation\") \n",
    "    module6.add_edge(\"initialize_criteria\", \"professional_evaluation\")\n",
    "    module6.add_edge(\"initialize_criteria\", \"people_evaluation\")\n",
    "\n",
    "    # 나머지는 동일\n",
    "    module6.add_edge(\"passionate_evaluation\", \"bars_integration\")\n",
    "    module6.add_edge(\"proactive_evaluation\", \"bars_integration\")\n",
    "    module6.add_edge(\"professional_evaluation\", \"bars_integration\")\n",
    "    module6.add_edge(\"people_evaluation\", \"bars_integration\")\n",
    "\n",
    "    def decide_save_path(state):\n",
    "        return (\n",
    "            \"quarterly_format_and_save\"\n",
    "            if state[\"report_type\"] == \"quarterly\"\n",
    "            else \"annual_format_and_save\"\n",
    "        )\n",
    "\n",
    "    module6.add_conditional_edges(\n",
    "        \"bars_integration\",\n",
    "        decide_save_path,\n",
    "        {\n",
    "            \"quarterly_format_and_save\": \"quarterly_format_and_save\",\n",
    "            \"annual_format_and_save\": \"annual_format_and_save\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    module6.add_edge(\"quarterly_format_and_save\", END)\n",
    "    module6.add_edge(\"annual_format_and_save\", END)\n",
    "\n",
    "    return module6.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 수정된 ID 매핑에 맞춘 테스트 함수\n",
    "# ================================================================\n",
    "\n",
    "def run_module6_test_efficient_updated(emp_no: str, report_type: str = \"quarterly\"):\n",
    "    \"\"\"효율적인 모듈 6 테스트 실행 - 업데이트된 ID 매핑\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"모듈 6 효율적 테스트 실행 - {emp_no} ({report_type})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 🔄 업데이트된 ID 매핑\n",
    "    if report_type == \"quarterly\":\n",
    "        feedback_report_mapping = {\n",
    "            \"SK102\": 3004,\n",
    "            \"SK103\": 3005, \n",
    "            \"SK104\": 3006\n",
    "        }\n",
    "        feedback_report_id = feedback_report_mapping.get(emp_no)\n",
    "        final_evaluation_report_id = None\n",
    "    else:  # annual\n",
    "        final_evaluation_mapping = {\n",
    "            \"SK102\": 4004,\n",
    "            \"SK103\": 4005,\n",
    "            \"SK104\": 4006\n",
    "        }\n",
    "        feedback_report_id = None\n",
    "        final_evaluation_report_id = final_evaluation_mapping.get(emp_no)\n",
    "    \n",
    "    # State 초기화\n",
    "    state = {\n",
    "        \"messages\": [f\"모듈 6 효율적 {report_type} 평가 시작\"],\n",
    "        \"report_type\": report_type,\n",
    "        \"team_id\": 1,\n",
    "        \"period_id\": 4 if report_type == \"annual\" else 2,\n",
    "        \"emp_no\": emp_no,\n",
    "        \"feedback_report_id\": feedback_report_id,\n",
    "        \"final_evaluation_report_id\": final_evaluation_report_id,\n",
    "        \"raw_evaluation_criteria\": \"\",  # DB에서 채워짐\n",
    "        \"evaluation_criteria\": {},  # 캐시에서 채워짐\n",
    "        \"evaluation_results\": {},\n",
    "        \"integrated_data\": {},\n",
    "    }\n",
    "    \n",
    "    print(f\"📍 설정된 ID: feedback_report_id={feedback_report_id}, final_evaluation_report_id={final_evaluation_report_id}\")\n",
    "    \n",
    "    # 효율적인 그래프 사용\n",
    "    module6_graph = create_module6_graph_efficient()\n",
    "    \n",
    "    try:\n",
    "        result = module6_graph.invoke(state)\n",
    "        \n",
    "        print(f\"\\n📊 실행 결과:\")\n",
    "        for message in result.get('messages', []):\n",
    "            print(f\"  {message}\")\n",
    "        \n",
    "        # 결과 표시\n",
    "        integrated_result = result.get('integrated_data', {}).get('integrated_4p_result', {})\n",
    "        evaluation_results = result.get('evaluation_results', {})\n",
    "        \n",
    "        if integrated_result:\n",
    "            print(f\"\\n🎯 4P 평가 결과:\")\n",
    "            for p_name in ['passionate', 'proactive', 'professional', 'people']:\n",
    "                p_result = evaluation_results.get(p_name, {})\n",
    "                if p_result:\n",
    "                    print(f\"  • {p_name.capitalize()}: {p_result.get('score', 0):.1f}점 ({p_result.get('bars_level', 'N/A')})\")\n",
    "            \n",
    "            print(f\"  • 평균: {integrated_result.get('average_score', 0):.1f}점 ({integrated_result.get('overall_level', 'N/A')})\")\n",
    "            print(f\"  • 균형도: {integrated_result.get('balance_analysis', 'N/A')}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 효율적 모듈 6 실행 오류: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🧪 모듈 6 효율적 테스트 실행 (업데이트된 ID):\n",
      "============================================================\n",
      "\n",
      "🔥 효율적 연말 평가 테스트 (SK103)\n",
      "\n",
      "============================================================\n",
      "모듈 6 효율적 테스트 실행 - SK103 (annual)\n",
      "============================================================\n",
      "📍 설정된 ID: feedback_report_id=None, final_evaluation_report_id=4005\n",
      "🔍 DB 평가 기준 해시: 4cd4f2da...\n",
      "🔄 평가 기준 새로 파싱 중...\n",
      "✅ 평가 기준 파싱 완료 및 캐시 업데이트\n",
      "Passionate 평가 시작: SK103\n",
      "People 평가 시작: SK103\n",
      "Proactive 평가 시작: SK103\n",
      "Professional 평가 시작: SK103\n",
      "4P 통합 평가 시작\n",
      "연말 결과 저장 시작: final_evaluation_report_id=4005\n",
      "\n",
      "📊 실행 결과:\n",
      "  모듈 6 효율적 annual 평가 시작\n",
      "  ✅ 평가 기준 초기화 완료 (캐시 활용)\n",
      "  Passionate 평가 완료: 5점 (압도적 몰입과 혁신 주도)\n",
      "  People 평가 완료: 4.0점 (능동적이고 건설적인 협력)\n",
      "  Proactive 평가 완료: 5점 (선구적 혁신 주도)\n",
      "  Professional 평가 완료: 4.5점 (선진 기술/지식 도입 및 전파)\n",
      "  4P 통합 평가 완료: 평균 4.6점 (탁월)\n",
      "  연말 4P 평가 결과 저장 완료 (ID: 4005)\n",
      "\n",
      "🎯 4P 평가 결과:\n",
      "  • Passionate: 5.0점 (압도적 몰입과 혁신 주도)\n",
      "  • Proactive: 5.0점 (선구적 혁신 주도)\n",
      "  • Professional: 4.5점 (선진 기술/지식 도입 및 전파)\n",
      "  • People: 4.0점 (능동적이고 건설적인 협력)\n",
      "  • 평균: 4.6점 (탁월)\n",
      "  • 균형도: Passionate 영역이 강하며, 전반적으로 균형 잡힌 발전\n",
      "\n",
      "✅ 연말 테스트 성공!\n",
      "\n",
      "------------------------------------------------------------\n",
      "🔥 효율적 분기 평가 테스트 (SK102)\n",
      "\n",
      "============================================================\n",
      "모듈 6 효율적 테스트 실행 - SK102 (quarterly)\n",
      "============================================================\n",
      "📍 설정된 ID: feedback_report_id=3004, final_evaluation_report_id=None\n",
      "🔍 DB 평가 기준 해시: 4cd4f2da...\n",
      "✅ 캐시된 평가 기준 사용 (DB 텍스트 변경 없음)\n",
      "Passionate 평가 시작: SK102\n",
      "People 평가 시작: SK102\n",
      "Proactive 평가 시작: SK102\n",
      "Professional 평가 시작: SK102\n",
      "4P 통합 평가 시작\n",
      "분기 결과 저장 시작: feedback_report_id=3004\n",
      "\n",
      "📊 실행 결과:\n",
      "  모듈 6 효율적 quarterly 평가 시작\n",
      "  ✅ 평가 기준 초기화 완료 (캐시 활용)\n",
      "  Passionate 평가 완료: 4.5점 (지속적인 최고 수준 노력)\n",
      "  People 평가 완료: 4.5점 (적극적인 팀 개선 기여)\n",
      "  Proactive 평가 완료: 4점 (탁월한 열정)\n",
      "  Professional 평가 완료: 4.0점 (심층적 전문성 및 문제 해결력)\n",
      "  4P 통합 평가 완료: 평균 4.2점 (우수)\n",
      "  분기 4P 평가 결과 저장 완료 (ID: 3004)\n",
      "\n",
      "🎯 4P 평가 결과:\n",
      "  • Passionate: 4.5점 (지속적인 최고 수준 노력)\n",
      "  • Proactive: 4.0점 (탁월한 열정)\n",
      "  • Professional: 4.0점 (심층적 전문성 및 문제 해결력)\n",
      "  • People: 4.5점 (적극적인 팀 개선 기여)\n",
      "  • 평균: 4.2점 (우수)\n",
      "  • 균형도: 4P 영역이 매우 균형있게 발달\n",
      "\n",
      "✅ 분기 테스트 성공!\n",
      "\n",
      "------------------------------------------------------------\n",
      "🔥 캐싱 효과 확인 추가 테스트\n",
      "\n",
      "📋 SK104 연말 평가 테스트 (캐시 활용)\n",
      "\n",
      "============================================================\n",
      "모듈 6 효율적 테스트 실행 - SK104 (annual)\n",
      "============================================================\n",
      "📍 설정된 ID: feedback_report_id=None, final_evaluation_report_id=4006\n",
      "🔍 DB 평가 기준 해시: 4cd4f2da...\n",
      "✅ 캐시된 평가 기준 사용 (DB 텍스트 변경 없음)\n",
      "Passionate 평가 시작: SK104\n",
      "People 평가 시작: SK104\n",
      "Proactive 평가 시작: SK104\n",
      "Professional 평가 시작: SK104\n",
      "4P 통합 평가 시작\n",
      "연말 결과 저장 시작: final_evaluation_report_id=4006\n",
      "\n",
      "📊 실행 결과:\n",
      "  모듈 6 효율적 annual 평가 시작\n",
      "  ✅ 평가 기준 초기화 완료 (캐시 활용)\n",
      "  Passionate 평가 완료: 3.5점 (목표 달성을 위한 추가 노력)\n",
      "  People 평가 완료: 3.5점 (원활한 소통 및 상호 존중)\n",
      "  Proactive 평가 완료: 4점 (탁월한 열정)\n",
      "  Professional 평가 완료: 3.5점 (자기 주도적 전문성 확장)\n",
      "  4P 통합 평가 완료: 평균 3.6점 (양호)\n",
      "  연말 4P 평가 결과 저장 완료 (ID: 4006)\n",
      "\n",
      "🎯 4P 평가 결과:\n",
      "  • Passionate: 3.5점 (목표 달성을 위한 추가 노력)\n",
      "  • Proactive: 4.0점 (탁월한 열정)\n",
      "  • Professional: 3.5점 (자기 주도적 전문성 확장)\n",
      "  • People: 3.5점 (원활한 소통 및 상호 존중)\n",
      "  • 평균: 3.6점 (양호)\n",
      "  • 균형도: 4P 영역이 매우 균형있게 발달\n",
      "\n",
      "📋 SK103 분기 평가 테스트 (캐시 활용)\n",
      "\n",
      "============================================================\n",
      "모듈 6 효율적 테스트 실행 - SK103 (quarterly)\n",
      "============================================================\n",
      "📍 설정된 ID: feedback_report_id=3005, final_evaluation_report_id=None\n",
      "🔍 DB 평가 기준 해시: 4cd4f2da...\n",
      "✅ 캐시된 평가 기준 사용 (DB 텍스트 변경 없음)\n",
      "Passionate 평가 시작: SK103\n",
      "People 평가 시작: SK103\n",
      "Proactive 평가 시작: SK103\n",
      "Professional 평가 시작: SK103\n",
      "4P 통합 평가 시작\n",
      "분기 결과 저장 시작: feedback_report_id=3005\n",
      "\n",
      "📊 실행 결과:\n",
      "  모듈 6 효율적 quarterly 평가 시작\n",
      "  ✅ 평가 기준 초기화 완료 (캐시 활용)\n",
      "  Passionate 평가 완료: 4.5점 (지속적인 최고 수준 노력)\n",
      "  People 평가 완료: 3.5점 (원활한 소통 및 상호 존중)\n",
      "  Proactive 평가 완료: 4점 (탁월한 열정)\n",
      "  Professional 평가 완료: 4.0점 (심층적 전문성 및 문제 해결력)\n",
      "  4P 통합 평가 완료: 평균 4.0점 (우수)\n",
      "  분기 4P 평가 결과 저장 완료 (ID: 3005)\n",
      "\n",
      "🎯 4P 평가 결과:\n",
      "  • Passionate: 4.5점 (지속적인 최고 수준 노력)\n",
      "  • Proactive: 4.0점 (탁월한 열정)\n",
      "  • Professional: 4.0점 (심층적 전문성 및 문제 해결력)\n",
      "  • People: 3.5점 (원활한 소통 및 상호 존중)\n",
      "  • 평균: 4.0점 (우수)\n",
      "  • 균형도: Passionate 영역이 강하며, 전반적으로 균형 잡힌 발전\n",
      "\n",
      "📋 SK104 분기 평가 테스트 (캐시 활용)\n",
      "\n",
      "============================================================\n",
      "모듈 6 효율적 테스트 실행 - SK104 (quarterly)\n",
      "============================================================\n",
      "📍 설정된 ID: feedback_report_id=3006, final_evaluation_report_id=None\n",
      "🔍 DB 평가 기준 해시: 4cd4f2da...\n",
      "✅ 캐시된 평가 기준 사용 (DB 텍스트 변경 없음)\n",
      "Passionate 평가 시작: SK104\n",
      "People 평가 시작: SK104\n",
      "Proactive 평가 시작: SK104\n",
      "Professional 평가 시작: SK104\n",
      "4P 통합 평가 시작\n",
      "분기 결과 저장 시작: feedback_report_id=3006\n",
      "\n",
      "📊 실행 결과:\n",
      "  모듈 6 효율적 quarterly 평가 시작\n",
      "  ✅ 평가 기준 초기화 완료 (캐시 활용)\n",
      "  Passionate 평가 완료: 4.5점 (지속적인 최고 수준 노력)\n",
      "  People 평가 완료: 3.5점 (원활한 소통 및 상호 존중)\n",
      "  Proactive 평가 완료: 4점 (탁월한 열정)\n",
      "  Professional 평가 완료: 4.0점 (심층적 전문성 및 문제 해결력)\n",
      "  4P 통합 평가 완료: 평균 4.0점 (우수)\n",
      "  분기 4P 평가 결과 저장 완료 (ID: 3006)\n",
      "\n",
      "🎯 4P 평가 결과:\n",
      "  • Passionate: 4.5점 (지속적인 최고 수준 노력)\n",
      "  • Proactive: 4.0점 (탁월한 열정)\n",
      "  • Professional: 4.0점 (심층적 전문성 및 문제 해결력)\n",
      "  • People: 3.5점 (원활한 소통 및 상호 존중)\n",
      "  • 평균: 4.0점 (우수)\n",
      "  • 균형도: Passionate 영역이 강하며, 전반적으로 균형 잡힌 발전\n",
      "\n",
      "============================================================\n",
      "📊 전체 테스트 결과 요약:\n",
      "============================================================\n",
      "  • SK103 연말 (ID: 4005): ✅ 성공\n",
      "  • SK102 분기 (ID: 3004): ✅ 성공\n",
      "  • SK104 연말 (ID: 4006): ✅ 성공\n",
      "  • SK103 분기 (ID: 3005): ✅ 성공\n",
      "  • SK104 분기 (ID: 3006): ✅ 성공\n",
      "\n",
      "🎯 전체 성공률: 5/5 (100.0%)\n",
      "\n",
      "🎉 모든 테스트 성공! 효율적인 4P 평가 시스템이 완벽히 작동합니다!\n",
      "\n",
      "============================================================\n",
      "🏁 모든 테스트 완료!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 업데이트된 완전한 테스트 실행 코드\n",
    "# ================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🧪 모듈 6 효율적 테스트 실행 (업데이트된 ID):\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 테스트 결과 저장\n",
    "    test_results = []\n",
    "    \n",
    "    try:\n",
    "        # ================================================================\n",
    "        # 연말 평가 테스트\n",
    "        # ================================================================\n",
    "        print(\"\\n🔥 효율적 연말 평가 테스트 (SK103)\")\n",
    "        result_annual = run_module6_test_efficient_updated('SK103', 'annual')\n",
    "        \n",
    "        if result_annual:\n",
    "            print(\"\\n✅ 연말 테스트 성공!\")\n",
    "            test_results.append((\"SK103 연말 (ID: 4005)\", True))\n",
    "        else:\n",
    "            print(\"\\n❌ 연말 테스트 실패\")\n",
    "            test_results.append((\"SK103 연말 (ID: 4005)\", False))\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        \n",
    "        # ================================================================\n",
    "        # 분기 평가 테스트  \n",
    "        # ================================================================\n",
    "        print(\"🔥 효율적 분기 평가 테스트 (SK102)\")\n",
    "        result_quarterly = run_module6_test_efficient_updated('SK102', 'quarterly')\n",
    "        \n",
    "        if result_quarterly:\n",
    "            print(\"\\n✅ 분기 테스트 성공!\")\n",
    "            test_results.append((\"SK102 분기 (ID: 3004)\", True))\n",
    "        else:\n",
    "            print(\"\\n❌ 분기 테스트 실패\")\n",
    "            test_results.append((\"SK102 분기 (ID: 3004)\", False))\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        \n",
    "        # ================================================================\n",
    "        # 추가 테스트 (캐싱 효과 확인)\n",
    "        # ================================================================\n",
    "        print(\"🔥 캐싱 효과 확인 추가 테스트\")\n",
    "        \n",
    "        # SK104 연말 테스트\n",
    "        print(\"\\n📋 SK104 연말 평가 테스트 (캐시 활용)\")\n",
    "        result_sk104_annual = run_module6_test_efficient_updated('SK104', 'annual')\n",
    "        test_results.append((\"SK104 연말 (ID: 4006)\", result_sk104_annual is not None))\n",
    "        \n",
    "        # SK103 분기 테스트  \n",
    "        print(\"\\n📋 SK103 분기 평가 테스트 (캐시 활용)\")\n",
    "        result_sk103_quarterly = run_module6_test_efficient_updated('SK103', 'quarterly')\n",
    "        test_results.append((\"SK103 분기 (ID: 3005)\", result_sk103_quarterly is not None))\n",
    "        \n",
    "        # SK104 분기 테스트\n",
    "        print(\"\\n📋 SK104 분기 평가 테스트 (캐시 활용)\")\n",
    "        result_sk104_quarterly = run_module6_test_efficient_updated('SK104', 'quarterly')\n",
    "        test_results.append((\"SK104 분기 (ID: 3006)\", result_sk104_quarterly is not None))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # ================================================================\n",
    "        # 최종 결과 요약\n",
    "        # ================================================================\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📊 전체 테스트 결과 요약:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for test_name, success in test_results:\n",
    "            status = \"✅ 성공\" if success else \"❌ 실패\"\n",
    "            print(f\"  • {test_name}: {status}\")\n",
    "        \n",
    "        # 성공률 계산\n",
    "        success_count = sum(1 for _, success in test_results if success)\n",
    "        total_count = len(test_results)\n",
    "        success_rate = (success_count / total_count) * 100 if total_count > 0 else 0\n",
    "        \n",
    "        print(f\"\\n🎯 전체 성공률: {success_count}/{total_count} ({success_rate:.1f}%)\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        if success_count == total_count:\n",
    "            print(\"\\n🎉 모든 테스트 성공! 효율적인 4P 평가 시스템이 완벽히 작동합니다!\")\n",
    "        elif success_count > 0:\n",
    "            print(\"\\n⚠️ 일부 테스트 성공. 실패한 테스트를 확인해주세요.\")\n",
    "        else:\n",
    "            print(\"\\n💥 모든 테스트 실패. 시스템 점검이 필요합니다.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n💥 테스트 실행 중 오류: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        test_results.append((\"전체 실행\", False))\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🏁 모든 테스트 완료!\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-m2V9dUhn-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
