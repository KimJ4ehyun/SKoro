# ================================================================
# run_module_09_1.py - ëª¨ë“ˆ 9 ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (í•¨ìˆ˜ ìˆœì„œ ìˆ˜ì •)
# ================================================================

import logging
from typing import Dict, List
from datetime import datetime
from langchain_core.messages import HumanMessage

from agents.evaluation.modules.module_09_cl_normalization.agent import *
from agents.evaluation.modules.module_09_cl_normalization.db_utils import *
from agents.evaluation.modules.module_09_cl_normalization.llm_utils import *

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# httpx ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì • (HTTP ìš”ì²­ ë¡œê·¸ ìˆ¨ê¹€)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("langchain").setLevel(logging.WARNING)
logging.getLogger("langchain_openai").setLevel(logging.WARNING)

# ================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ë¨¼ì € ì •ì˜)
# ================================================================

def print_enhanced_workflow_summary(state: Module9AgentState):
    """í–¥ìƒëœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    
    print(f"ğŸ“‹ í–¥ìƒëœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ ìš”ì•½:")
    
    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬
    messages = state.get("messages", [])
    if messages:
        print(f"\nğŸ“ ì‹¤í–‰ ë‹¨ê³„:")
        for i, msg in enumerate(messages, 1):
            print(f"   {i}. {msg.content}")
    
    # 1ë‹¨ê³„ ê²°ê³¼
    department_data = state.get("department_data", {})
    if department_data:
        print(f"\nğŸ” 1ë‹¨ê³„ - í–¥ìƒëœ ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼:")
        total_members = sum(cl_data.get("member_count", 0) for cl_data in department_data.values())
        adjustment_needed = len([cl for cl, data in department_data.items() if data.get("needs_adjustment", False)])
        total_surplus = sum(cl_data.get("surplus", 0) for cl_data in department_data.values())
        
        print(f"   - ì´ ì¸ì›: {total_members}ëª…")
        print(f"   - ì¡°ì • í•„ìš” CL: {adjustment_needed}ê°œ")
        print(f"   - ì´ ì´ˆê³¼ë¶„: {total_surplus:+.2f}ì ")
        
        for cl_group, cl_data in department_data.items():
            status = "ğŸ”§ ì¡°ì • í•„ìš”" if cl_data.get("needs_adjustment") else "âœ… ì¡°ì • ë¶ˆí•„ìš”"
            validity_summary = cl_data.get("validity_summary", {})
            high_validity = validity_summary.get("ë§¤ìš° íƒ€ë‹¹", 0) + validity_summary.get("íƒ€ë‹¹", 0)
            print(f"   - {cl_group}: {cl_data.get('member_count', 0)}ëª…, {cl_data.get('surplus', 0):+.2f}ì  {status} (ê³ íƒ€ë‹¹ì„± {high_validity}ëª…)")
    
    # 2ë‹¨ê³„ ê²°ê³¼
    enhanced_analysis = state.get("enhanced_analysis", {})
    if enhanced_analysis:
        print(f"\nğŸ§  2ë‹¨ê³„ - í–¥ìƒëœ íƒ€ë‹¹ì„± ë¶„ì„ ê²°ê³¼:")
        analyzed_cls = [analysis for analysis in enhanced_analysis.values() if analysis.get("analysis_completed")]
        total_analyzed = sum(analysis.get("members_analyzed", 0) for analysis in analyzed_cls)
        
        if analyzed_cls:
            avg_validity = sum(analysis["avg_validity"] for analysis in analyzed_cls) / len(analyzed_cls)
            total_high_validity = sum(analysis["high_validity_count"] for analysis in analyzed_cls)
            total_low_validity = sum(analysis["low_validity_count"] for analysis in analyzed_cls)
            
            print(f"   - ë¶„ì„ ì™„ë£Œ CL: {len(analyzed_cls)}ê°œ")
            print(f"   - ì´ ë¶„ì„ ì¸ì›: {total_analyzed}ëª…")
            print(f"   - í‰ê·  íƒ€ë‹¹ì„±: {avg_validity:.3f}")
            print(f"   - ê³ íƒ€ë‹¹ì„± ì¸ì›: {total_high_validity}ëª…")
            print(f"   - ì €íƒ€ë‹¹ì„± ì¸ì›: {total_low_validity}ëª…")
            
            for cl_group, analysis in enhanced_analysis.items():
                if analysis.get("analysis_completed"):
                    recommendation = analysis["analysis_summary"]["recommendation"]
                    print(f"   - {cl_group}: í‰ê·  {analysis['avg_validity']:.3f} ({recommendation})")
    
    # 3ë‹¨ê³„ ê²°ê³¼
    supervisor_results = state.get("supervisor_results", {})
    if supervisor_results:
        print(f"\nğŸ¤– 3ë‹¨ê³„ - í–¥ìƒëœ AI Supervisor ê²°ê³¼:")
        successful_cls = len([cl for cl, result in supervisor_results.items() if result.get("success", False)])
        total_adjustments = sum(result.get("adjustments_made", 0) for result in supervisor_results.values())
        fallback_used = len([cl for cl, result in supervisor_results.items() if result.get("fallback_used", False)])
        enhanced_used = len([cl for cl, result in supervisor_results.items() if result.get("enhanced_features", {}).get("validity_analysis_used", False)])
        
        print(f"   - ì„±ê³µí•œ CL: {successful_cls}/{len(supervisor_results)}ê°œ")
        print(f"   - ì´ ì¡°ì • ì¸ì›: {total_adjustments}ëª…")
        print(f"   - Fallback ì‚¬ìš©: {fallback_used}ê°œ CL")
        print(f"   - í–¥ìƒëœ ê¸°ëŠ¥ ì‚¬ìš©: {enhanced_used}ê°œ CL")
        
        for cl_group, result in supervisor_results.items():
            status_icon = "âœ…" if result.get("success") else "âŒ"
            enhanced_note = " (í–¥ìƒë¨)" if result.get("enhanced_features", {}).get("validity_analysis_used") else ""
            print(f"   - {cl_group}: {status_icon} {result.get('adjustments_made', 0)}ëª… ì¡°ì •{enhanced_note}")
    
    # 4ë‹¨ê³„ ê²°ê³¼
    update_results = state.get("update_results", {})
    if update_results:
        print(f"\nğŸ“Š 4ë‹¨ê³„ - í–¥ìƒëœ ìµœì¢… ì§‘ê³„ ê²°ê³¼:")
        print(f"   - ì„±ê³µë¥ : {update_results.get('success_rate', 0):.1f}%")
        print(f"   - ë¶„í¬ ë‹¬ì„±ë¥ : {update_results.get('distribution_rate', 0):.1f}%")
        print(f"   - í–¥ìƒëœ ê¸°ëŠ¥ ì ìš©ë¥ : {update_results.get('enhanced_rate', 0):.1f}%")
        print(f"   - í‰ê·  ì²˜ë¦¬ì‹œê°„: {update_results.get('avg_processing_time_ms', 0):.0f}ms")
        print(f"   - ì´ ì²˜ë¦¬ì‹œê°„: {update_results.get('total_processing_time_ms', 0):.0f}ms")
    
    # ì—ëŸ¬ ë¡œê·¸
    error_logs = state.get("error_logs", [])
    if error_logs:
        print(f"\nâš ï¸ ì—ëŸ¬ ë¡œê·¸:")
        for error in error_logs:
            print(f"   - {error}")
    
    # ìµœì¢… ìš”ì•½
    total_processed = state.get("total_processed", 0)
    total_failed = state.get("total_failed", 0)
    print(f"\nğŸ í–¥ìƒëœ ìµœì¢… ê²°ê³¼:")
    print(f"   âœ… ì„±ê³µ: {total_processed}ëª…")
    print(f"   âŒ ì‹¤íŒ¨: {total_failed}ëª…")
    print(f"   ğŸ“ˆ ì„±ê³µë¥ : {(total_processed / (total_processed + total_failed) * 100) if (total_processed + total_failed) > 0 else 0:.1f}%")
    print(f"   ğŸš€ í–¥ìƒëœ ê¸°ëŠ¥: ì—…ë¬´ì¦ê±°ë¶„ì„, ë™ë£Œí‰ê°€í†µí•©, ë‹¤ë©´ê²€ì¦ ì ìš©")

def generate_enhanced_summary_report(state: Module9AgentState) -> Dict:
    """í–¥ìƒëœ ìµœì¢… ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    
    headquarter_id = state["headquarter_id"]
    period_id = state["period_id"]
    department_data = state.get("department_data", {})
    enhanced_analysis = state.get("enhanced_analysis", {})
    supervisor_results = state.get("supervisor_results", {})
    update_results = state.get("update_results", {})
    
    # ì²˜ë¦¬ ì „ í˜„í™©
    initial_stats = {
        "total_cls": len(department_data),
        "total_members": sum(cl_data.get("member_count", 0) for cl_data in department_data.values()),
        "adjustment_needed_cls": len([cl for cl, data in department_data.items() if data.get("needs_adjustment", False)]),
        "total_surplus": sum(cl_data.get("surplus", 0) for cl_data in department_data.values())
    }
    
    # í–¥ìƒëœ ë¶„ì„ ê²°ê³¼
    enhanced_stats = {
        "analyzed_cls": len([analysis for analysis in enhanced_analysis.values() if analysis.get("analysis_completed")]),
        "avg_validity_score": 0,
        "high_validity_members": 0,
        "low_validity_members": 0,
        "validity_distribution": {"ë§¤ìš° íƒ€ë‹¹": 0, "íƒ€ë‹¹": 0, "ë³´í†µ": 0, "ì˜ì‹¬": 0, "ë§¤ìš° ì˜ì‹¬": 0}
    }
    
    # íƒ€ë‹¹ì„± í†µê³„ ê³„ì‚°
    all_validities = []
    for analysis in enhanced_analysis.values():
        if analysis.get("analysis_completed"):
            all_validities.append(analysis["avg_validity"])
            enhanced_stats["high_validity_members"] += analysis["high_validity_count"]
            enhanced_stats["low_validity_members"] += analysis["low_validity_count"]
            
            # ë¶„í¬ ì§‘ê³„
            for grade, members in analysis.get("validity_distribution", {}).items():
                enhanced_stats["validity_distribution"][grade] += len(members)
    
    if all_validities:
        enhanced_stats["avg_validity_score"] = round(sum(all_validities) / len(all_validities), 3)
    
    # ì²˜ë¦¬ í›„ ê²°ê³¼
    final_stats = {
        "processed_cls": update_results.get("successful_cls", 0),
        "adjusted_members": update_results.get("total_adjustments", 0),
        "distribution_achieved_cls": update_results.get("distribution_achieved_count", 0),
        "fallback_used_cls": update_results.get("fallback_used_count", 0),
        "enhanced_features_used_cls": update_results.get("enhanced_features_used_count", 0)
    }
    
    # ì„±ê³¼ ì§€í‘œ
    performance_metrics = {
        "success_rate": update_results.get("success_rate", 0),
        "distribution_rate": update_results.get("distribution_rate", 0),
        "enhanced_rate": update_results.get("enhanced_rate", 0),
        "avg_processing_time_ms": update_results.get("avg_processing_time_ms", 0),
        "total_processing_time_ms": update_results.get("total_processing_time_ms", 0)
    }
    
    enhanced_summary_report = {
        "headquarter_id": headquarter_id,
        "period_id": period_id,
        "execution_timestamp": datetime.now().isoformat(),
        "version": "enhanced_v2.0",
        "features": ["ì—…ë¬´ì¦ê±°ë¶„ì„", "ë™ë£Œí‰ê°€í†µí•©", "í–¥ìƒëœíƒ€ë‹¹ì„±íŒë‹¨"],
        "initial_stats": initial_stats,
        "enhanced_analysis_stats": enhanced_stats,
        "final_stats": final_stats,
        "performance_metrics": performance_metrics,
        "cl_details": update_results.get("cl_summaries", []),
        "successful_employees": update_results.get("successful_employees", []),
        "failed_employees": update_results.get("failed_employees", []),
        "messages": [msg.content for msg in state.get("messages", [])],
        "error_logs": state.get("error_logs", [])
    }
    
    return enhanced_summary_report

def run_enhanced_module9_workflow_fixed(headquarter_id: int, period_id: int = 4):
    """í–¥ìƒëœ ëª¨ë“ˆ9 ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
    
    print(f"ğŸš€ í–¥ìƒëœ ëª¨ë“ˆ9 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘")
    print(f"   ë³¸ë¶€: {headquarter_id}, ê¸°ê°„: {period_id}")
    print(f"   íŠ¹ì§•: ì—…ë¬´ì¦ê±°ë¶„ì„ + ë™ë£Œí‰ê°€í†µí•© + í–¥ìƒëœíƒ€ë‹¹ì„±íŒë‹¨")
    print(f"   {'='*70}")
    
    # ì´ˆê¸° State ìƒì„±
    initial_state = Module9AgentState(
        messages=[HumanMessage(content=f"í–¥ìƒëœ ëª¨ë“ˆ9 ì‹œì‘: ë³¸ë¶€ {headquarter_id}")],
        headquarter_id=headquarter_id,
        period_id=period_id,
        department_data={},
        enhanced_analysis={},
        supervisor_results={},
        update_results={},
        total_processed=0,
        total_failed=0,
        error_logs=[]
    )
    
    try:
        # LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„± ë° ì‹¤í–‰
        enhanced_module9_graph = create_enhanced_module9_graph()
        
        print(f"ğŸ”„ í–¥ìƒëœ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘...")
        result_state = enhanced_module9_graph.invoke(initial_state)
        
        # ì‹¤í–‰ ì™„ë£Œ ë©”ì‹œì§€
        print(f"\nâœ… í–¥ìƒëœ ëª¨ë“ˆ9 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ!")
        print(f"   {'='*70}")
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print_enhanced_workflow_summary(result_state)
        
        # í–¥ìƒëœ ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        enhanced_final_report = generate_enhanced_summary_report(result_state)
        
        return {
            "success": True,
            "final_state": result_state,
            "enhanced_summary_report": enhanced_final_report,
            "total_processed": result_state.get("total_processed", 0),
            "total_failed": result_state.get("total_failed", 0)
        }
        
    except Exception as e:
        print(f"âŒ í–¥ìƒëœ ëª¨ë“ˆ9 ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "total_processed": 0,
            "total_failed": 0
        }

# ================================================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ (ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ë‹¤ìŒì— ì •ì˜)
# ================================================================

def execute_module9_pipeline(headquarter_id: int, period_id: int = 4) -> Dict:
    """ëª¨ë“ˆ 9 í–¥ìƒëœ ì œë¡œì„¬ ì¡°ì • í‰ê°€ ì‹¤í–‰"""
    
    start_time = datetime.now()
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸš€ ëª¨ë“ˆ 9: í–¥ìƒëœ ì œë¡œì„¬ ì¡°ì • ë¶„ì„ ì‹œì‘")
    logger.info(f"{'='*60}")
    logger.info(f"ğŸ“ ì„¤ì • ì •ë³´:")
    logger.info(f"   ë³¸ë¶€ ID: {headquarter_id}")
    logger.info(f"   ê¸°ê°„ ID: {period_id}")
    logger.info(f"   íŠ¹ì§•: ì—…ë¬´ì¦ê±°ë¶„ì„ + ë™ë£Œí‰ê°€í†µí•© + í–¥ìƒëœíƒ€ë‹¹ì„±íŒë‹¨")
    
    try:
        # ì´ˆê¸° State ìƒì„±
        initial_state = Module9AgentState(
            messages=[HumanMessage(content=f"í–¥ìƒëœ ëª¨ë“ˆ9 ì‹œì‘: ë³¸ë¶€ {headquarter_id}")],
            headquarter_id=headquarter_id,
            period_id=period_id,
            department_data={},
            enhanced_analysis={},
            supervisor_results={},
            update_results={},
            total_processed=0,
            total_failed=0,
            error_logs=[]
        )
        
        logger.info(f"ğŸš€ ëª¨ë“ˆ 9: í–¥ìƒëœ ì œë¡œì„¬ ì¡°ì • ë¶„ì„ ì‹œì‘ (ë³¸ë¶€ {headquarter_id}, Q{period_id})")
        
        # ëª¨ë“ˆ 9 ê·¸ë˜í”„ ìƒì„± ë° ì‹¤í–‰
        module9_graph = create_enhanced_module9_graph()
        result_state = module9_graph.invoke(initial_state)
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        success_result = {
            "status": "success",
            "execution_time_seconds": execution_time,
            "headquarter_id": headquarter_id,
            "period_id": period_id,
            "results": {
                "total_processed": result_state.get("total_processed", 0),
                "total_failed": result_state.get("total_failed", 0),
                "successful_cls": result_state.get("update_results", {}).get("successful_cls", 0),
                "total_adjustments": result_state.get("update_results", {}).get("total_adjustments", 0),
                "success_rate": result_state.get("update_results", {}).get("success_rate", 0),
                "enhanced_features_used": result_state.get("update_results", {}).get("enhanced_features_used_count", 0)
            },
            "messages": [msg.content for msg in result_state.get("messages", [])],
            "final_state": result_state
        }
        
        logger.info("\nâœ… ëª¨ë“ˆ 9 ì‹¤í–‰ ì™„ë£Œ!")
        logger.info("ğŸ“‹ ì‹¤í–‰ ê³¼ì •:")
        for i, message in enumerate(result_state.get("messages", []), 1):
            logger.info(f"  {i}. {message.content}")
        
        logger.info(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
        logger.info(f"ì²˜ë¦¬ëœ ì§ì›: {success_result['results']['total_processed']}ëª…")
        logger.info(f"ì‹¤íŒ¨í•œ ì§ì›: {success_result['results']['total_failed']}ëª…")
        logger.info(f"ì„±ê³µí•œ CL: {success_result['results']['successful_cls']}ê°œ")
        logger.info(f"ì´ ì¡°ì • ì¸ì›: {success_result['results']['total_adjustments']}ëª…")
        logger.info(f"ì„±ê³µë¥ : {success_result['results']['success_rate']:.1f}%")
        logger.info(f"í–¥ìƒëœ ê¸°ëŠ¥ ì‚¬ìš©: {success_result['results']['enhanced_features_used']}ê°œ CL")
        logger.info(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
        logger.info(f"{'='*60}")
        
        # ìƒì„¸ ìš”ì•½ ì¶œë ¥ - ì´ì œ í•¨ìˆ˜ê°€ ì •ì˜ë˜ì—ˆìœ¼ë¯€ë¡œ í˜¸ì¶œ ê°€ëŠ¥
        print_enhanced_workflow_summary(result_state)
        
        return success_result
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        error_result = {
            "status": "error",
            "execution_time_seconds": execution_time,
            "error_message": str(e),
            "error_type": type(e).__name__,
            "headquarter_id": headquarter_id,
            "period_id": period_id
        }
        
        logger.error(f"\nâŒ ëª¨ë“ˆ 9 ì‹¤í–‰ ì‹¤íŒ¨!")
        logger.error(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
        logger.error(f"ğŸ’¥ ì˜¤ë¥˜: {e}")
        logger.error(f"ğŸ” ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}")
        logger.error(f"{'='*60}")
        
        return error_result

# ================================================================
# í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰ í•¨ìˆ˜
# ================================================================

def test_module9() -> Dict:
    """ëª¨ë“ˆ 9 í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("=== ëª¨ë“ˆ 9 í–¥ìƒëœ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    result = execute_module9_pipeline(headquarter_id=1, period_id=4)
    
    if result and result.get("status") == "success":
        logger.info(f"\nğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        logger.info(f"ìƒíƒœ: {result['status']}")
        logger.info(f"ì‹¤í–‰ ì‹œê°„: {result['execution_time_seconds']:.2f}ì´ˆ")
        logger.info(f"ì²˜ë¦¬ëœ ì§ì›: {result['results']['total_processed']}ëª…")
        logger.info(f"ì‹¤íŒ¨í•œ ì§ì›: {result['results']['total_failed']}ëª…")
        logger.info(f"ì„±ê³µí•œ CL: {result['results']['successful_cls']}ê°œ")
        logger.info(f"ì´ ì¡°ì • ì¸ì›: {result['results']['total_adjustments']}ëª…")
        logger.info(f"ì„±ê³µë¥ : {result['results']['success_rate']:.1f}%")
        logger.info(f"í–¥ìƒëœ ê¸°ëŠ¥ ì‚¬ìš©: {result['results']['enhanced_features_used']}ê°œ CL")
        
        return result
    else:
        logger.error("í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        if result:
            logger.error(f"ì˜¤ë¥˜: {result.get('error_message', 'Unknown error')}")
            logger.error(f"ì˜¤ë¥˜ ìœ í˜•: {result.get('error_type', 'Unknown')}")
        return result

def test_enhanced_module9_fixed():
    """í–¥ìƒëœ ëª¨ë“ˆ9 í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    print("ğŸ§ª í–¥ìƒëœ ëª¨ë“ˆ9 í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    try:
        # ë‹¨ì¼ ë³¸ë¶€ í…ŒìŠ¤íŠ¸
        result = run_enhanced_module9_workflow_fixed(1, 4)
        
        if result["success"]:
            print("âœ… í–¥ìƒëœ ëª¨ë“ˆ9 í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"   ì²˜ë¦¬ëœ ì§ì›: {result['total_processed']}ëª…")
            print(f"   ì‹¤íŒ¨í•œ ì§ì›: {result['total_failed']}ëª…")
        else:
            print("âŒ í–¥ìƒëœ ëª¨ë“ˆ9 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
            print(f"   ì˜¤ë¥˜: {result.get('error', 'Unknown')}")
            
    except Exception as e:
        print(f"ğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def run_multiple_headquarters_module9(headquarter_ids: List[int], period_id: int = 4):
    """ì—¬ëŸ¬ ë³¸ë¶€ í–¥ìƒëœ ì¼ê´„ ì‹¤í–‰"""
    
    logger.info(f"ğŸ¢ ì—¬ëŸ¬ ë³¸ë¶€ í–¥ìƒëœ ëª¨ë“ˆ9 ì¼ê´„ ì‹¤í–‰: {len(headquarter_ids)}ê°œ ë³¸ë¶€")
    logger.info(f"   ëŒ€ìƒ ë³¸ë¶€: {headquarter_ids}")
    logger.info(f"   í–¥ìƒëœ ê¸°ëŠ¥: ì—…ë¬´ì¦ê±°ë¶„ì„ + ë™ë£Œí‰ê°€í†µí•© + ë‹¤ë©´ê²€ì¦")
    logger.info(f"   {'='*80}")
    
    results = {}
    total_success = 0
    total_failed = 0
    total_processed_employees = 0
    total_failed_employees = 0
    
    for i, hq_id in enumerate(headquarter_ids, 1):
        logger.info(f"\nğŸ¢ ë³¸ë¶€ {hq_id} í–¥ìƒëœ ì²˜ë¦¬ ì¤‘... ({i}/{len(headquarter_ids)})")
        logger.info(f"   {'-'*60}")
        
        try:
            result = execute_module9_pipeline(hq_id, period_id)
            results[hq_id] = result
            
            if result["status"] == "success":
                total_success += 1
                total_processed_employees += result["results"]["total_processed"]
                total_failed_employees += result["results"]["total_failed"]
            else:
                total_failed += 1
                
        except Exception as e:
            logger.error(f"âŒ ë³¸ë¶€ {hq_id} í–¥ìƒëœ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            results[hq_id] = {"status": "error", "error_message": str(e)}
            total_failed += 1
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    logger.info(f"\nğŸ‰ ì—¬ëŸ¬ ë³¸ë¶€ í–¥ìƒëœ ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info(f"   {'='*80}")
    logger.info(f"ğŸ ì „ì²´ í–¥ìƒëœ ê²°ê³¼ ìš”ì•½:")
    logger.info(f"   - ì„±ê³µí•œ ë³¸ë¶€: {total_success}/{len(headquarter_ids)}ê°œ")
    logger.info(f"   - ì‹¤íŒ¨í•œ ë³¸ë¶€: {total_failed}/{len(headquarter_ids)}ê°œ")
    logger.info(f"   - ë³¸ë¶€ ì„±ê³µë¥ : {(total_success / len(headquarter_ids) * 100):.1f}%")
    logger.info(f"   - ì´ ì²˜ë¦¬ ì§ì›: {total_processed_employees}ëª…")
    logger.info(f"   - ì´ ì‹¤íŒ¨ ì§ì›: {total_failed_employees}ëª…")
    logger.info(f"   - ì§ì› ì„±ê³µë¥ : {(total_processed_employees / (total_processed_employees + total_failed_employees) * 100) if (total_processed_employees + total_failed_employees) > 0 else 0:.1f}%")
    logger.info(f"   ğŸš€ ì ìš©ëœ í–¥ìƒ ê¸°ëŠ¥: ì—…ë¬´ì‹¤ì ê²€ì¦, ë™ë£Œí‰ê°€ì¼ì¹˜ì„±ë¶„ì„, ì¢…í•©íƒ€ë‹¹ì„±íŒë‹¨")
    
    return results

def run_multiple_headquarters_enhanced_module9_fixed(headquarter_ids: List[int], period_id: int = 4):
    """ì—¬ëŸ¬ ë³¸ë¶€ í–¥ìƒëœ ì¼ê´„ ì‹¤í–‰"""
    
    print(f"ğŸ¢ ì—¬ëŸ¬ ë³¸ë¶€ í–¥ìƒëœ ëª¨ë“ˆ9 ì¼ê´„ ì‹¤í–‰: {len(headquarter_ids)}ê°œ ë³¸ë¶€")
    print(f"   ëŒ€ìƒ ë³¸ë¶€: {headquarter_ids}")
    print(f"   í–¥ìƒëœ ê¸°ëŠ¥: ì—…ë¬´ì¦ê±°ë¶„ì„ + ë™ë£Œí‰ê°€í†µí•© + ë‹¤ë©´ê²€ì¦")
    print(f"   {'='*80}")
    
    results = {}
    total_success = 0
    total_failed = 0
    total_processed_employees = 0
    total_failed_employees = 0
    
    for i, hq_id in enumerate(headquarter_ids, 1):
        print(f"\nğŸ¢ ë³¸ë¶€ {hq_id} í–¥ìƒëœ ì²˜ë¦¬ ì¤‘... ({i}/{len(headquarter_ids)})")
        print(f"   {'-'*60}")
        
        try:
            result = run_enhanced_module9_workflow_fixed(hq_id, period_id)
            results[hq_id] = result
            
            if result["success"]:
                total_success += 1
                total_processed_employees += result["total_processed"]
                total_failed_employees += result["total_failed"]
            else:
                total_failed += 1
                
        except Exception as e:
            print(f"âŒ ë³¸ë¶€ {hq_id} í–¥ìƒëœ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            results[hq_id] = {"success": False, "error": str(e)}
            total_failed += 1
    
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ‰ ì—¬ëŸ¬ ë³¸ë¶€ í–¥ìƒëœ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   {'='*80}")
    print(f"ğŸ ì „ì²´ í–¥ìƒëœ ê²°ê³¼ ìš”ì•½:")
    print(f"   - ì„±ê³µí•œ ë³¸ë¶€: {total_success}/{len(headquarter_ids)}ê°œ")
    print(f"   - ì‹¤íŒ¨í•œ ë³¸ë¶€: {total_failed}/{len(headquarter_ids)}ê°œ")
    print(f"   - ë³¸ë¶€ ì„±ê³µë¥ : {(total_success / len(headquarter_ids) * 100):.1f}%")
    print(f"   - ì´ ì²˜ë¦¬ ì§ì›: {total_processed_employees}ëª…")
    print(f"   - ì´ ì‹¤íŒ¨ ì§ì›: {total_failed_employees}ëª…")
    print(f"   - ì§ì› ì„±ê³µë¥ : {(total_processed_employees / (total_processed_employees + total_failed_employees) * 100) if (total_processed_employees + total_failed_employees) > 0 else 0:.1f}%")
    print(f"   ğŸš€ ì ìš©ëœ í–¥ìƒ ê¸°ëŠ¥: ì—…ë¬´ì‹¤ì ê²€ì¦, ë™ë£Œí‰ê°€ì¼ì¹˜ì„±ë¶„ì„, ì¢…í•©íƒ€ë‹¹ì„±íŒë‹¨")
    
    return results

# ================================================================
# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# ================================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {"headquarter_id": 1, "period_id": 4, "desc": "ë³¸ë¶€1 Q4 ì—°ë§í‰ê°€"},
        {"headquarter_id": 2, "period_id": 4, "desc": "ë³¸ë¶€2 Q4 ì—°ë§í‰ê°€"}
    ]

    for test_case in test_cases:
        logger.info(f"\nğŸ§ª ëª¨ë“ˆ9 í–¥ìƒëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - {test_case['desc']}")
        logger.info(f"   í…ŒìŠ¤íŠ¸ ë³¸ë¶€: {test_case['headquarter_id']}")
        logger.info(f"   í…ŒìŠ¤íŠ¸ ê¸°ê°„: Q{test_case['period_id']}")
        
        try:
            result = run_enhanced_module9_workflow_fixed(
                test_case['headquarter_id'], 
                test_case['period_id']
            )
            
            if result.get('success'):
                logger.info(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                logger.info(f"ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½:")
                logger.info(f"   â€¢ ìƒíƒœ: {result.get('success', False)}")
                logger.info(f"   â€¢ ì²˜ë¦¬ëœ ì§ì›: {result.get('total_processed', 0)}ëª…")
                logger.info(f"   â€¢ ì‹¤íŒ¨í•œ ì§ì›: {result.get('total_failed', 0)}ëª…")
                logger.info(f"   â€¢ ì„±ê³µë¥ : {(result.get('total_processed', 0) / (result.get('total_processed', 0) + result.get('total_failed', 0)) * 100) if (result.get('total_processed', 0) + result.get('total_failed', 0)) > 0 else 0:.1f}%")
            else:
                logger.error(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
                logger.error(f"   â€¢ ì˜¤ë¥˜: {result.get('error', 'Unknown error')}")
            
        except Exception as e:
            logger.error(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ ëª¨ë“ˆ9 í–¥ìƒëœ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info(f"{'='*60}")

# ================================================================
# ìœ í‹¸ë¦¬í‹° ë° ì•ˆë‚´ ë©”ì‹œì§€
# ================================================================

print("ğŸ“‹ ëª¨ë“ˆ9 ì‹¤í–‰ í•¨ìˆ˜:")
print("  - execute_module9_pipeline(headquarter_id, period_id)")
print("  - test_module9()")
print("  - run_multiple_headquarters_module9(headquarter_ids, period_id)")
print("  - run_enhanced_module9_workflow_fixed(headquarter_id, period_id)")
print("  - test_enhanced_module9_fixed()")
print("  - run_multiple_headquarters_enhanced_module9_fixed(headquarter_ids, period_id)")
print()
print("ğŸš€ ì´ì œ ë‹¤ìŒê³¼ ê°™ì´ ì‹¤í–‰í•˜ì„¸ìš”:")
print("   result = execute_module9_pipeline(1, 4)")
print("   ë˜ëŠ”")
print("   result = run_enhanced_module9_workflow_fixed(1, 4)")
print("   ë˜ëŠ”")
print("   test_enhanced_module9_fixed()")