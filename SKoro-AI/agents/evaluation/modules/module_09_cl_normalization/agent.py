
# ================================================================
# agent_1.py - ëª¨ë“ˆ 9 ìƒíƒœ ê´€ë¦¬ ë°ì´í„°í´ë˜ìŠ¤, ë©”ì¸ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤
# ================================================================

import os
import logging
import statistics
from typing import Annotated, List, Literal, TypedDict, Dict, Optional
from langchain_core.messages import HumanMessage 
import operator
from langgraph.graph import StateGraph, START, END
from decimal import Decimal
import math
from datetime import datetime

from agents.evaluation.modules.module_09_cl_normalization.db_utils import *
from agents.evaluation.modules.module_09_cl_normalization.llm_utils import *

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ================================================================
# ìƒíƒœ ì •ì˜
# ================================================================

class Module9AgentState(TypedDict):
    """ëª¨ë“ˆ 9 (ë³¸ë¶€ ë‹¨ìœ„ CLë³„ ì œë¡œì„¬ ì¡°ì •) ìƒíƒœ - í–¥ìƒëœ ë²„ì „"""
    messages: Annotated[List[HumanMessage], operator.add]
    
    # ì…ë ¥ ì •ë³´
    headquarter_id: int
    period_id: int  # ì—°ë§: 4
    
    # 4ë‹¨ê³„ ê²°ê³¼ ì €ì¥ (í™•ì¥)
    department_data: Dict[str, Dict]           # 1ë‹¨ê³„: ë¶€ë¬¸ ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼
    enhanced_analysis: Dict[str, Dict]         # 2ë‹¨ê³„: í–¥ìƒëœ íƒ€ë‹¹ì„± ë¶„ì„ ê²°ê³¼
    supervisor_results: Dict[str, Dict]        # 3ë‹¨ê³„: AI Supervisor ì‹¤í–‰ ê²°ê³¼  
    update_results: Dict                       # 4ë‹¨ê³„: ë°°ì¹˜ ì—…ë°ì´íŠ¸ ê²°ê³¼
    
    # ì²˜ë¦¬ ìƒíƒœ
    total_processed: int
    total_failed: int
    error_logs: List[str]

# ================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ================================================================

def calculate_target_total(member_count: int) -> float:
    """CLë³„ ëª©í‘œ ì´ì  ê³„ì‚° (ì¸ì›ìˆ˜ Ã— 3.5ì )"""
    return member_count * 3.5

def calculate_surplus(manager_score_sum: float, target_total: float) -> float:
    """ì´ˆê³¼ë¶„ ê³„ì‚° (íŒ€ì¥ ìˆ˜ì • ì ìˆ˜í•© - ëª©í‘œ ì´ì )"""
    return round(manager_score_sum - target_total, 2)

def get_cl_target_stdev(cl_group: str) -> float:
    """CLë³„ ëª©í‘œ í‘œì¤€í¸ì°¨ ë°˜í™˜"""
    target_stdevs = {
        "CL3": 1.7,  # ê³ ìœ„ì§ â†’ í° ë³€ë³„ë ¥
        "CL2": 1.5,  # ì¤‘ê°„ì§ â†’ ì ë‹¹í•œ ë³€ë³„ë ¥  
        "CL1": 1.4   # ì£¼ë‹ˆì–´ â†’ ì•ˆì •ì  í‰ê°€
    }
    return target_stdevs.get(cl_group, 1.5)

def calculate_task_complexity_factor(member: Dict) -> float:
    """ì—…ë¬´ ë³µì¡ë„ ë° ë‚œì´ë„ ê³ ë ¤ ìš”ì†Œ"""
    
    task_data = member.get('task_data', [])
    if not task_data:
        return 1.0  # ê¸°ë³¸ê°’
    
    complexity_factors = []
    
    for task in task_data:
        task_weight = task.get('task_weight', 1)
        kpi_weight = task.get('kpi_weight', 1)
        ai_grade = task.get('ai_assessed_grade', 'C')
        
        # ì—…ë¬´ ì¤‘ìš”ë„ (ê°€ì¤‘ì¹˜)
        importance_factor = min(2.0, (task_weight + kpi_weight) / 10)
        
        # AI í‰ê°€ ë“±ê¸‰ ê³ ë ¤
        grade_factors = {'S': 1.5, 'A': 1.3, 'B': 1.1, 'C': 1.0, 'D': 0.8}
        grade_factor = grade_factors.get(ai_grade, 1.0)
        
        complexity_factors.append(importance_factor * grade_factor)
    
    # í‰ê·  ë³µì¡ë„ ë°˜í™˜
    return sum(complexity_factors) / len(complexity_factors) if complexity_factors else 1.0

def calculate_enhanced_captain_validity(member: Dict) -> Dict:
    """í–¥ìƒëœ íŒ€ì¥ ìˆ˜ì • íƒ€ë‹¹ì„± ê³„ì‚° (ì—…ë¬´+ë™ë£Œí‰ê°€ í¬í•¨) - ë³€ê²½ ì—†ìŒì€ ë§Œì  ì²˜ë¦¬"""
    
    # ë³€ê²½í•˜ì§€ ì•Šì€ ê²½ìš° = íƒ€ë‹¹ì„± ë§Œì  (íŒ€ì¥ì´ ì ì ˆí•˜ë‹¤ê³  íŒë‹¨)
    if not member.get('changed_by_manager', True):
        return {
            "basic_validity": 1.0,
            "task_evidence": 1.0,
            "peer_consistency": 1.0,
            "complexity_factor": 1.0,
            "final_validity": 1.0,
            "validity_grade": "ë§¤ìš° íƒ€ë‹¹",
            "detailed_analysis": {
                "direction_score": 1.0,
                "reason_score": 1.0,
                "magnitude_score": 1.0,
                "complexity_adjustment": 0.0
            },
            "no_change_reason": "íŒ€ì¥ì´ ëª¨ë“ˆ7 ì ìˆ˜ë¥¼ ì ì ˆí•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ ë³€ê²½í•˜ì§€ ì•ŠìŒ"
        }
    
    # ë³€ê²½í•œ ê²½ìš°: ê¸°ì¡´ í–¥ìƒëœ íƒ€ë‹¹ì„± ë¶„ì„ ìˆ˜í–‰
    
    # 1. ê¸°ë³¸ íƒ€ë‹¹ì„± (ê¸°ì¡´ ë¡œì§)
    score_change = member.get('score_diff', 0)
    reason = member.get('captain_reason', '') or ''
    kpi_achievement = member.get('kpi_achievement', 100)
    
    # ê¸°ë³¸ ë°©í–¥ì„± ì¼ì¹˜ ì ìˆ˜
    if kpi_achievement >= 100 and score_change > 0:
        direction_score = 1.0
    elif kpi_achievement >= 90 and score_change >= 0:
        direction_score = 0.9
    elif kpi_achievement < 80 and score_change < 0:
        direction_score = 1.0
    elif kpi_achievement < 90 and score_change <= 0:
        direction_score = 0.8
    elif abs(score_change) < 0.1:
        direction_score = 1.0
    elif (kpi_achievement >= 100 and score_change < -0.3) or (kpi_achievement < 70 and score_change > 0.3):
        direction_score = 0.2
    else:
        direction_score = 0.5
    
    # ê¸°ë³¸ ì‚¬ìœ  í’ˆì§ˆ ì ìˆ˜
    reason_length = len(reason.strip()) if reason else 0
    performance_keywords = ['ì„±ê³¼', 'ê¸°ì—¬', 'ìš°ìˆ˜', 'ê°œì„ ', 'ë‹¬ì„±', 'ë…¸ë ¥', 'ì—­ëŸ‰', 'í˜‘ì—…', 'ë¦¬ë”ì‹­']
    specific_keywords = ['í”„ë¡œì íŠ¸', 'ê³ ê°', 'ë§¤ì¶œ', 'í’ˆì§ˆ', 'íš¨ìœ¨', 'í˜ì‹ ', 'ë©˜í† ë§']
    
    keyword_count = sum(1 for word in performance_keywords if word in reason)
    specific_count = sum(1 for word in specific_keywords if word in reason)
    
    if reason_length > 30 and keyword_count >= 2 and specific_count >= 1:
        reason_score = 1.0
    elif reason_length > 20 and keyword_count >= 1:
        reason_score = 0.8
    elif reason_length > 10:
        reason_score = 0.6
    elif reason_length > 0:
        reason_score = 0.4
    else:
        reason_score = 0.1
    
    # ì¡°ì • í­ ì ì ˆì„±
    abs_change = abs(score_change)
    if abs_change <= 0.3:
        magnitude_score = 1.0
    elif abs_change <= 0.6:
        magnitude_score = 0.8
    elif abs_change <= 1.0:
        magnitude_score = 0.6
    elif abs_change <= 1.5:
        magnitude_score = 0.3
    else:
        magnitude_score = 0.1
    
    # 2. ì—…ë¬´ ì¦ê±° ì¼ì¹˜ì„± (ì‹ ê·œ)
    task_evidence = analyze_task_evidence_consistency(member)
    
    # 3. ë™ë£Œí‰ê°€ ì¼ì¹˜ì„± (ì‹ ê·œ)
    peer_consistency = analyze_peer_evaluation_consistency(member)
    
    # 4. ì—…ë¬´ ë³µì¡ë„ ê³ ë ¤ (ì‹ ê·œ)
    complexity_factor = calculate_task_complexity_factor(member)
    
    # 5. ì¢…í•© íƒ€ë‹¹ì„± ê³„ì‚° (í–¥ìƒëœ ê³µì‹)
    basic_validity = (
        direction_score * 0.3 +      # ë°©í–¥ì„± 30%
        reason_score * 0.2 +         # ì‚¬ìœ  í’ˆì§ˆ 20%
        magnitude_score * 0.1        # ì¡°ì • í­ 10%
    )
    
    enhanced_validity = (
        basic_validity * 0.4 +       # ê¸°ë³¸ íƒ€ë‹¹ì„± 40%
        task_evidence * 0.3 +        # ì—…ë¬´ ì¦ê±° 30%
        peer_consistency * 0.3       # ë™ë£Œí‰ê°€ ì¼ì¹˜ì„± 30%
    )
    
    # ë³µì¡ë„ ë³´ì • (ìµœëŒ€ Â±20%)
    complexity_adjustment = min(0.2, max(-0.2, (complexity_factor - 1.0) * 0.2))
    final_validity = max(0.0, min(1.0, enhanced_validity + complexity_adjustment))
    
    return {
        "basic_validity": round(basic_validity, 3),
        "task_evidence": round(task_evidence, 3),
        "peer_consistency": round(peer_consistency, 3),
        "complexity_factor": round(complexity_factor, 3),
        "final_validity": round(final_validity, 3),
        "validity_grade": get_validity_grade(final_validity),
        "detailed_analysis": {
            "direction_score": round(direction_score, 3),
            "reason_score": round(reason_score, 3),
            "magnitude_score": round(magnitude_score, 3),
            "complexity_adjustment": round(complexity_adjustment, 3)
        }
    }

def get_validity_grade(validity_score: float) -> str:
    """íƒ€ë‹¹ì„± ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
    if validity_score >= 0.8:
        return "ë§¤ìš° íƒ€ë‹¹"
    elif validity_score >= 0.6:
        return "íƒ€ë‹¹"
    elif validity_score >= 0.4:
        return "ë³´í†µ"
    elif validity_score >= 0.2:
        return "ì˜ì‹¬"
    else:
        return "ë§¤ìš° ì˜ì‹¬"

def calculate_comprehensive_performance_score(member: Dict) -> float:
    """ì¢…í•© ì„±ê³¼ ì ìˆ˜ ê³„ì‚° (KPI + ì—…ë¬´ì¦ê±° + ë™ë£Œí‰ê°€ íƒ€ë‹¹ì„±)"""
    
    kpi_score = member.get('kpi_achievement', 100)
    validity_analysis = calculate_enhanced_captain_validity(member)
    final_validity = validity_analysis['final_validity']
    
    # KPI ë‹¬ì„±ë¥  70% + íƒ€ë‹¹ì„± 30%ë¡œ ì¢…í•© ì„±ê³¼ ê³„ì‚°
    comprehensive_score = kpi_score * 0.7 + final_validity * 100 * 0.3
    
    return round(comprehensive_score, 1)

def check_performance_reversal(adjustments: List[Dict], kpi_data: Dict) -> Dict:
    """ì„±ê³¼ ì—­ì „ ë°©ì§€ ê²€ì¦ - KPI ì°¨ì´ 20%p ì´ìƒ ì‹œ ì ìˆ˜ ì—­ì „ ë¶ˆê°€"""
    
    reversals = []
    warnings = []
    
    # ëª¨ë“  ì¡°í•©ì„ ì²´í¬
    for i in range(len(adjustments)):
        for j in range(i + 1, len(adjustments)):
            emp1 = adjustments[i]
            emp2 = adjustments[j]
            
            # KPI ë‹¬ì„±ë¥  ê°€ì ¸ì˜¤ê¸°
            kpi1 = kpi_data.get(emp1["emp_no"], 100)
            kpi2 = kpi_data.get(emp2["emp_no"], 100)
            
            # KPI ì°¨ì´ ê³„ì‚°
            kpi_diff = abs(kpi1 - kpi2)
            
            # 20%p ì´ìƒ ì°¨ì´ë‚˜ëŠ” ê²½ìš°ë§Œ ì²´í¬
            if kpi_diff >= 20:
                # ëˆ„ê°€ ë” ë†’ì€ KPIì¸ì§€ í™•ì¸
                if kpi1 > kpi2:
                    high_kpi_emp, low_kpi_emp = emp1, emp2
                    high_kpi, low_kpi = kpi1, kpi2
                else:
                    high_kpi_emp, low_kpi_emp = emp2, emp1
                    high_kpi, low_kpi = kpi2, kpi1
                
                # ì ìˆ˜ ì—­ì „ ì²´í¬
                if high_kpi_emp["final_score"] < low_kpi_emp["final_score"]:
                    reversals.append({
                        "high_kpi_emp": high_kpi_emp["emp_no"],
                        "low_kpi_emp": low_kpi_emp["emp_no"],
                        "high_kpi": high_kpi,
                        "low_kpi": low_kpi,
                        "kpi_diff": kpi_diff,
                        "high_kpi_score": high_kpi_emp["final_score"],
                        "low_kpi_score": low_kpi_emp["final_score"],
                        "score_diff": low_kpi_emp["final_score"] - high_kpi_emp["final_score"]
                    })
                elif high_kpi_emp["final_score"] == low_kpi_emp["final_score"]:
                    warnings.append({
                        "high_kpi_emp": high_kpi_emp["emp_no"],
                        "low_kpi_emp": low_kpi_emp["emp_no"],
                        "kpi_diff": kpi_diff,
                        "message": "KPI ì°¨ì´ í°ë° ë™ì "
                    })
    
    return {
        "has_reversal": len(reversals) > 0,
        "reversal_count": len(reversals),
        "reversals": reversals,
        "warnings": warnings
    }

def validate_zero_sum_result(adjustments: List[Dict], target_reduction: float, 
                           target_stdev: float, cl_group: str) -> Dict:
    """ì œë¡œì„¬ ì¡°ì • ê²°ê³¼ ê²€ì¦"""
    
    if not adjustments:
        return {"valid": False, "errors": ["ì¡°ì • ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤"]}
    
    # ê¸°ë³¸ ê²€ì¦
    final_scores = [adj["final_score"] for adj in adjustments]
    actual_total = sum(final_scores)
    actual_mean = actual_total / len(final_scores)
    actual_stdev = statistics.stdev(final_scores) if len(final_scores) > 1 else 0
    
    # ì‹¤ì œ ì°¨ê°ëŸ‰ ê³„ì‚°
    actual_reduction = sum(adj["original_score"] - adj["final_score"] for adj in adjustments)
    
    errors = []
    warnings = []
    
    # 1. ì œë¡œì„¬ ê²€ì¦
    reduction_error = abs(actual_reduction - target_reduction)
    if reduction_error > 0.02:
        errors.append(f"ì œë¡œì„¬ ì‹¤íŒ¨: ëª©í‘œ {target_reduction:.2f}, ì‹¤ì œ {actual_reduction:.2f}")
    
    # 2. í‰ê·  ê²€ì¦
    mean_error = abs(actual_mean - 3.5)
    if mean_error > 0.02:
        errors.append(f"í‰ê·  ì‹¤íŒ¨: ëª©í‘œ 3.5, ì‹¤ì œ {actual_mean:.2f}")
    
    # 3. í‘œì¤€í¸ì°¨ ê²€ì¦ (ë” ê´€ëŒ€í•˜ê²Œ)
    stdev_error = abs(actual_stdev - target_stdev)
    if stdev_error > 0.4:
        errors.append(f"í‘œì¤€í¸ì°¨ ì‹¤íŒ¨: ëª©í‘œ {target_stdev:.1f}, ì‹¤ì œ {actual_stdev:.1f}")
    elif stdev_error > 0.2:
        warnings.append(f"í‘œì¤€í¸ì°¨ ê²½ê³ : ëª©í‘œ {target_stdev:.1f}, ì‹¤ì œ {actual_stdev:.1f}")
    
    # 4. ì ìˆ˜ ë²”ìœ„ ê²€ì¦
    invalid_scores = [adj for adj in adjustments if adj["final_score"] < 0.0 or adj["final_score"] > 5.0]
    if invalid_scores:
        errors.append(f"ì ìˆ˜ ë²”ìœ„ ì´ˆê³¼: {len(invalid_scores)}ëª…")
    
    # 5. ì„±ê³¼ ì—­ì „ ê²€ì¦
    kpi_data = {adj["emp_no"]: adj.get("kpi_achievement", 100) for adj in adjustments}
    performance_reversal = check_performance_reversal(adjustments, kpi_data)
    
    if performance_reversal["has_reversal"]:
        errors.append(f"ì„±ê³¼ ì—­ì „ ë°œìƒ: {performance_reversal['reversal_count']}ê±´")
    
    return {
        "valid": len(errors) == 0,
        "errors": errors,
        "warnings": warnings,
        "performance_reversal": performance_reversal,
        "metrics": {
            "actual_reduction": round(actual_reduction, 2),
            "target_reduction": round(target_reduction, 2),
            "actual_mean": round(actual_mean, 2),
            "target_mean": 3.5,
            "actual_stdev": round(actual_stdev, 2),
            "target_stdev": round(target_stdev, 2),
            "reduction_error": round(reduction_error, 2),
            "mean_error": round(mean_error, 2),
            "stdev_error": round(stdev_error, 2)
        }
    }

# ================================================================
# Fallback ì•Œê³ ë¦¬ì¦˜
# ================================================================

def execute_proper_zero_sum_adjustment(supervisor_input: Dict) -> Dict:
    """ì˜¬ë°”ë¥¸ ì œë¡œì„¬ ì¡°ì •: ì„±ê³¼ ê¸°ë°˜ ì°¨ë“± ì°¨ê°ìœ¼ë¡œ í‘œì¤€í¸ì°¨ ë‹¬ì„± + ë³€ê²½ ì—†ìŒ ìš°ì„ ìˆœìœ„ ë°˜ì˜"""
    
    members = supervisor_input["members"]
    target_total = supervisor_input["current_situation"]["target_total"]
    surplus = supervisor_input["total_surplus"]
    target_mean = 3.5
    target_stdev = supervisor_input.get("distribution_targets", {}).get("target_stdev", 1.5)
    member_count = len(members)
    cl_group = supervisor_input.get("cl_group", "CL")
    
    print(f"ğŸ”§ {cl_group} ì˜¬ë°”ë¥¸ ì œë¡œì„¬ ì¡°ì • ì‹¤í–‰:")
    print(f"  ëª©í‘œ: í‰ê·  {target_mean}, í‘œì¤€í¸ì°¨ {target_stdev}, ì°¨ê° {surplus:.2f}ì ")
    
    if member_count == 0:
        return {"analysis_summary": "ì²˜ë¦¬í•  ë©¤ë²„ ì—†ìŒ", "adjustments": [], "validation_check": {"all_conditions_met": False}}
    
    # 1. ë³€ê²½ ìš°ì„ ìˆœìœ„ë³„ ë¶„ë¥˜
    high_priority = [m for m in members if m.get('change_priority') == 'high']      # íŒ€ì¥ì´ ë³€ê²½í•¨
    maintain_priority = [m for m in members if m.get('change_priority') == 'maintain']  # íŒ€ì¥ì´ ìœ ì§€í•¨ (ë³€ê²½ ì—†ìŒ)
    
    print(f"  ìš°ì„ ìˆœìœ„ ë¶„ë¥˜:")
    print(f"    ì£¼ìš” ì¡°ì • ëŒ€ìƒ: {len(high_priority)}ëª…")
    print(f"    ìœ ì§€ ìš°ì„  ëŒ€ìƒ: {len(maintain_priority)}ëª… (íƒ€ë‹¹ì„± ë§Œì )")
    
    # 2. í–¥ìƒëœ ì„±ê³¼ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
    members_with_performance = []
    for member in members:
        validity_analysis = calculate_enhanced_captain_validity(member)
        comprehensive_score = calculate_comprehensive_performance_score(member)
        
        member_copy = member.copy()
        member_copy["validity_analysis"] = validity_analysis
        member_copy["comprehensive_performance"] = comprehensive_score
        members_with_performance.append(member_copy)
    
    # ì„±ê³¼ ìˆœìœ„ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
    sorted_members = sorted(members_with_performance, 
                          key=lambda x: x["comprehensive_performance"], 
                          reverse=True)
    
    print(f"  ì„±ê³¼ ìˆœìœ„ (ìƒìœ„ 3ëª…):")
    for i, member in enumerate(sorted_members[:3]):
        validity_grade = member["validity_analysis"]["validity_grade"]
        change_status = "ë³€ê²½í•¨" if member.get('changed_by_manager', True) else "ìœ ì§€í•¨"
        print(f"    {i+1}ìœ„: {member['emp_no']} | ì¢…í•©ì„±ê³¼ {member['comprehensive_performance']:.1f}, í˜„ì¬ì ìˆ˜ {member['current_score']:.1f}, íƒ€ë‹¹ì„± {validity_grade}, {change_status}")
    
    # 3. í˜„ì¬ í‘œì¤€í¸ì°¨ ê³„ì‚°
    current_scores = [m["current_score"] for m in sorted_members]
    current_stdev = statistics.stdev(current_scores) if len(current_scores) > 1 else 0
    current_mean = sum(current_scores) / len(current_scores)
    
    print(f"  í˜„ì¬ ìƒíƒœ: í‰ê·  {current_mean:.2f}, í‘œì¤€í¸ì°¨ {current_stdev:.2f}")
    
    # 4. ì°¨ë“± ì¡°ì • ê°€ì¤‘ì¹˜ ìƒì„± (ë³€ê²½ ìš°ì„ ìˆœìœ„ ë°˜ì˜)
    adjustment_weights = generate_performance_based_weights_with_priority(
        sorted_members, target_stdev, current_stdev, surplus
    )
    
    # 5. ì œë¡œì„¬ ì°¨ê° ë¶„ë°°
    adjustments = []
    total_reduction = 0.0
    
    for i, member in enumerate(sorted_members):
        # ê°œë³„ ì°¨ê°ëŸ‰ ê³„ì‚°
        individual_reduction = surplus * adjustment_weights[i] / sum(adjustment_weights)
        final_score = member["current_score"] - individual_reduction
        
        # 0-5 ë²”ìœ„ ì œí•œ
        final_score = max(0.0, min(5.0, final_score))
        actual_reduction = member["current_score"] - final_score
        total_reduction += actual_reduction
        
        change_type = "maintain" if abs(actual_reduction) < 0.01 else "decrease"
        
        # ì¡°ì • ì‚¬ìœ  ìƒì„±
        rank = i + 1
        performance_tier = "ìƒìœ„" if i < member_count * 0.3 else "ì¤‘ìœ„" if i < member_count * 0.7 else "í•˜ìœ„"
        validity_grade = member["validity_analysis"]["validity_grade"]
        change_status = "ë³€ê²½í•¨" if member.get('changed_by_manager', True) else "ìœ ì§€í•¨"
        
        if member.get('change_priority') == 'maintain':
            adjustment_reason = f"ì„±ê³¼ê¸°ë°˜ ì¡°ì •: {rank}ìœ„/{member_count} ({performance_tier}êµ°, íƒ€ë‹¹ì„± {validity_grade}, íŒ€ì¥ {change_status} - ìµœì†Œì¡°ì •)"
        else:
            adjustment_reason = f"ì„±ê³¼ê¸°ë°˜ ì¡°ì •: {rank}ìœ„/{member_count} ({performance_tier}êµ°, íƒ€ë‹¹ì„± {validity_grade}, íŒ€ì¥ {change_status})"
        
        adjustments.append({
            "emp_no": member["emp_no"],
            "original_score": member["current_score"],
            "final_score": round(final_score, 2),
            "change_amount": round(-actual_reduction, 2),  # ìŒìˆ˜ (ì°¨ê°)
            "change_type": change_type,
            "reason": adjustment_reason,
            "final_evaluation_report_id": member.get("final_evaluation_report_id"),
            "performance_rank": rank,
            "performance_tier": performance_tier,
            "validity_analysis": member["validity_analysis"],
            "kpi_achievement": member.get("kpi_achievement", 100),  # ì„±ê³¼ ì—­ì „ ê²€ì¦ìš©
            "change_priority": member.get("change_priority", "high")
        })
    
    # 6. ìµœì¢… ê²€ì¦
    validation_result = validate_zero_sum_result(adjustments, surplus, target_stdev, cl_group)
    
    print(f"  ê²°ê³¼: ì´ì°¨ê° {validation_result['metrics']['actual_reduction']:.2f}ì ")
    print(f"  ê²€ì¦: {'âœ… í†µê³¼' if validation_result['valid'] else 'âŒ ì‹¤íŒ¨'}")
    
    if not validation_result["valid"]:
        for error in validation_result["errors"][:2]:  # ìƒìœ„ 2ê°œ ì—ëŸ¬ë§Œ ì¶œë ¥
            print(f"    - {error}")
    
    # ì„±ê³¼ ì—­ì „ ì²´í¬
    if validation_result["performance_reversal"]["has_reversal"]:
        print(f"  âš ï¸ ì„±ê³¼ ì—­ì „ ë°œìƒ: {validation_result['performance_reversal']['reversal_count']}ê±´")
    
    return {
        "analysis_summary": f"{cl_group} ì„±ê³¼ê¸°ë°˜ ì¡°ì • (ìš°ì„ ìˆœìœ„ ë°˜ì˜): {member_count}ëª… â†’ í‰ê·  {validation_result['metrics']['actual_mean']:.2f}, í‘œì¤€í¸ì°¨ {validation_result['metrics']['actual_stdev']:.2f}",
        "adjustments": adjustments,
        "validation_check": {
            "target_total": target_total,
            "actual_total": validation_result["metrics"]["actual_mean"] * member_count,
            "target_mean": target_mean,
            "actual_mean": validation_result["metrics"]["actual_mean"],
            "target_stdev": target_stdev,
            "actual_stdev": validation_result["metrics"]["actual_stdev"],
            "target_reduction": surplus,
            "actual_reduction": validation_result["metrics"]["actual_reduction"],
            "zero_sum_achieved": validation_result["metrics"]["reduction_error"] < 0.02,
            "stdev_achieved": validation_result["metrics"]["stdev_error"] < 0.3,
            "mean_achieved": validation_result["metrics"]["mean_error"] < 0.02,
            "all_conditions_met": validation_result["valid"],
            "performance_reversal": validation_result["performance_reversal"],
            "priority_analysis": {
                "high_priority_count": len(high_priority),
                "maintain_priority_count": len(maintain_priority),
                "high_priority_members": [m["emp_no"] for m in high_priority],
                "maintain_priority_members": [m["emp_no"] for m in maintain_priority]
            }
        }
    }

def generate_performance_based_weights_with_priority(sorted_members: List[Dict], target_stdev: float, 
                                                   current_stdev: float, surplus: float) -> List[float]:
    """ì„±ê³¼ ê¸°ë°˜ ì°¨ë“± ì°¨ê° ê°€ì¤‘ì¹˜ ìƒì„± - ë³€ê²½ ìš°ì„ ìˆœìœ„ ë°˜ì˜"""
    
    member_count = len(sorted_members)
    
    # í‘œì¤€í¸ì°¨ ì¡°ì • í•„ìš”ì„± ê³„ì‚°
    stdev_factor = calculate_stdev_adjustment_factor(current_stdev, target_stdev)
    
    # ê¸°ë³¸ ì „ëµ ê²°ì •
    if stdev_factor <= 0.3:
        strategy = "uniform_with_priority"
        print(f"  í‘œì¤€í¸ì°¨ ì „ëµ: ìš°ì„ ìˆœìœ„ ë°˜ì˜ ê· ë“±ì°¨ê° (factor: {stdev_factor:.2f})")
    else:
        strategy = "differential_with_priority"
        print(f"  í‘œì¤€í¸ì°¨ ì „ëµ: ìš°ì„ ìˆœìœ„ ë°˜ì˜ ì°¨ë“±ì°¨ê° (factor: {stdev_factor:.2f})")
    
    base_weights = []
    
    for i in range(member_count):
        member = sorted_members[i]
        rank_ratio = i / max(1, member_count - 1)  # 0(1ìœ„) ~ 1(ê¼´ì°Œ)
        
        # ë³€ê²½ ìš°ì„ ìˆœìœ„ ë°˜ì˜
        if member.get('change_priority') == 'maintain':
            # ë³€ê²½í•˜ì§€ ì•Šì€ ì§ì›: ìµœì†Œ ê°€ì¤‘ì¹˜ (ê±°ì˜ ì¡°ì • ì•ˆí•¨)
            base_weight = 0.1
        else:
            # ë³€ê²½í•œ ì§ì›: ì„±ê³¼ì™€ stdev_factor ê¸°ë°˜ ê°€ì¤‘ì¹˜
            if strategy == "uniform_with_priority":
                base_weight = 1.0  # ê¸°ë³¸ ê°€ì¤‘ì¹˜
            else:
                # ì°¨ë“± ê°€ì¤‘ì¹˜
                if rank_ratio <= 0.3:  # ìƒìœ„ 30%
                    base_weight = 1.0 - (0.6 * stdev_factor)  # ìµœì†Œ 0.4ê¹Œì§€
                elif rank_ratio <= 0.7:  # ì¤‘ìœ„ 40%
                    base_weight = 1.0  # ê¸°ì¤€ì 
                else:  # í•˜ìœ„ 30%
                    base_weight = 1.0 + (0.6 * stdev_factor)  # ìµœëŒ€ 1.6ê¹Œì§€
        
        base_weights.append(base_weight)
    
    # íƒ€ë‹¹ì„± ë³´ì •
    adjusted_weights = []
    for i, member in enumerate(sorted_members):
        base_weight = base_weights[i]
        validity_score = member["validity_analysis"]["final_validity"]
        
        # ë³€ê²½í•˜ì§€ ì•Šì€ ì§ì›ì€ íƒ€ë‹¹ì„± ë³´ì • ì œì™¸ (ì´ë¯¸ ìµœì†Œ ê°€ì¤‘ì¹˜)
        if member.get('change_priority') == 'maintain':
            validity_modifier = 1.0  # ë³´ì • ì—†ìŒ
        else:
            # íƒ€ë‹¹ì„±ì´ ë†’ìœ¼ë©´ ì°¨ê° ë³´í˜¸, ë‚®ìœ¼ë©´ ë” ì°¨ê°
            if validity_score >= 0.7:  # ê³ íƒ€ë‹¹ì„±
                validity_modifier = 0.8
            elif validity_score >= 0.4:  # ì¤‘íƒ€ë‹¹ì„±
                validity_modifier = 1.0
            else:  # ì €íƒ€ë‹¹ì„±
                validity_modifier = 1.2
        
        adjusted_weight = base_weight * validity_modifier
        adjusted_weights.append(adjusted_weight)
    
    return adjusted_weights

def calculate_stdev_adjustment_factor(current_stdev: float, target_stdev: float) -> float:
    """í‘œì¤€í¸ì°¨ ì¡°ì • í•„ìš”ì„± ê³„ì‚°"""
    
    if target_stdev == 0:
        return 1.0
    
    stdev_ratio = current_stdev / target_stdev
    
    if stdev_ratio >= 1.2:
        # í˜„ì¬ ë³€ë³„ë ¥ì´ ê³¼ë„í•¨ â†’ ê· ë“± ì°¨ê°
        return 0.0  # ì°¨ë“± ì—†ìŒ
    elif stdev_ratio >= 0.8:
        # ì ì • ë³€ë³„ë ¥ â†’ ì•½ê°„ ì°¨ë“±
        return 0.3
    else:
        # ë³€ë³„ë ¥ ë¶€ì¡± â†’ ê°•í•œ ì°¨ë“±
        return 1.0

# ================================================================
# í•„í„°ë§ í•¨ìˆ˜
# ================================================================

def fetch_headquarter_cl_members_enhanced_filtered(headquarter_id: int, cl_group: str, period_id: int) -> List[Dict]:
    """ë³¸ë¶€ ë‚´ íŠ¹ì • CL ê·¸ë£¹ì˜ ì§ì› ë°ì´í„° ì¡°íšŒ - íŒ€ì¥ ë³€ê²½ë¶„ë§Œ í•„í„°ë§"""
    
    # ëª¨ë“  ì§ì› ì¡°íšŒ
    all_members = fetch_headquarter_cl_members_enhanced(headquarter_id, cl_group, period_id)
    
    # ë³€ê²½ ì—¬ë¶€ ë¶„ì„ (ì œì™¸í•˜ì§€ ì•Šê³  ë¶„ë¥˜ë§Œ)
    changed_count = 0
    unchanged_count = 0
    
    for member in all_members:
        baseline_score = safe_decimal_to_float(member.get('baseline_score', 0))
        manager_score = safe_decimal_to_float(member.get('manager_score', 0))
        score_diff = abs(manager_score - baseline_score)
        
        if score_diff > 0.01:
            member['changed_by_manager'] = True
            member['score_diff'] = round(manager_score - baseline_score, 2)
            member['change_priority'] = 'high'    # ì£¼ìš” ì¡°ì • ëŒ€ìƒ
            changed_count += 1
        else:
            member['changed_by_manager'] = False
            member['score_diff'] = 0.0
            member['change_priority'] = 'maintain'  # ìœ ì§€ ìš°ì„ 
            unchanged_count += 1
    
    # ëª¨ë“  ë©¤ë²„ì— ì „ì²´ ì •ë³´ ì¶”ê°€
    total_members_count = len(all_members)
    
    for member in all_members:
        member['total_cl_members'] = total_members_count
        member['unchanged_cl_members'] = unchanged_count
    
    print(f"   ğŸ“Š {cl_group} íŒ€ì¥ ë³€ê²½ ë¶„ì„:")
    print(f"     - ì „ì²´ ì§ì›: {len(all_members)}ëª…")
    print(f"     - ë³€ê²½ëœ ì§ì›: {changed_count}ëª…")
    print(f"     - ë³€ê²½ ì—†ëŠ” ì§ì›: {unchanged_count}ëª…")
    
    if unchanged_count > 0:
        unchanged_list = [m['emp_no'] for m in all_members if not m['changed_by_manager']]
        print(f"     - ë³€ê²½ ì—†ìŒ: {', '.join(unchanged_list)} (íƒ€ë‹¹ì„± ë§Œì )")
    
    # ëª¨ë“  ì§ì› ë°˜í™˜ (ì œì™¸í•˜ì§€ ì•ŠìŒ)
    return all_members

# ================================================================
# ì„œë¸Œëª¨ë“ˆ í•¨ìˆ˜ ì •ì˜
# ================================================================

def department_data_collection(state: Module9AgentState) -> Module9AgentState:
    """1ë‹¨ê³„: ë¶€ë¬¸ ë°ì´í„° ìˆ˜ì§‘ - íŒ€ì¥ ë³€ê²½ë¶„ë§Œ ì²˜ë¦¬"""
    
    headquarter_id = state["headquarter_id"]
    period_id = state["period_id"]
    
    try:
        print(f"ğŸ” 1ë‹¨ê³„: ë³¸ë¶€ {headquarter_id} íŒ€ì¥ ë³€ê²½ë¶„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        # 1. ë³¸ë¶€ ë‚´ ëª¨ë“  CL ê·¸ë£¹ ì¡°íšŒ
        cl_groups = get_all_cl_groups_in_headquarter(headquarter_id, period_id)
        print(f"   ë°œê²¬ëœ CL ê·¸ë£¹: {cl_groups}")
        
        department_data = {}
        total_members = 0
        total_changed_members = 0
        adjustment_needed_cls = []
        
        # 2. CLë³„ í•„í„°ë§ëœ ë°ì´í„° ìˆ˜ì§‘
        for cl_group in cl_groups:
            print(f"\nğŸ“Š {cl_group} íŒ€ì¥ ë³€ê²½ë¶„ ë¶„ì„ ì¤‘...")
            
            # íŒ€ì¥ì´ ë³€ê²½í•œ ì§ì›ë§Œ ì¡°íšŒ
            changed_members = fetch_headquarter_cl_members_enhanced_filtered(headquarter_id, cl_group, period_id)
            
            if len(changed_members) == 0:
                print(f"   âœ… {cl_group}: íŒ€ì¥ ë³€ê²½ ì—†ìŒ - ì¡°ì • ë¶ˆí•„ìš”")
                department_data[cl_group] = {
                    "surplus": 0.0,
                    "needs_adjustment": False,
                    "member_count": 0,
                    "total_cl_members": 0,
                    "unchanged_members": 0,
                    "members_with_requests": [],
                    "validity_summary": {"ë§¤ìš° íƒ€ë‹¹": 0, "íƒ€ë‹¹": 0, "ë³´í†µ": 0, "ì˜ì‹¬": 0, "ë§¤ìš° ì˜ì‹¬": 0},
                    "target_total": 0,
                    "manager_score_sum": 0,
                    "target_stdev": get_cl_target_stdev(cl_group),
                    "members_data": []
                }
                continue
            
            # ë³€ê²½ëœ ì§ì›ë“¤ì˜ ì´ˆê³¼ë¶„ ê³„ì‚°
            manager_scores = [m['manager_score'] for m in changed_members]
            module7_scores = [m['module7_score'] for m in changed_members]
            
            manager_score_sum = sum(manager_scores)
            module7_score_sum = sum(module7_scores)
            
            # ì´ˆê³¼ë¶„ = íŒ€ì¥ ìˆ˜ì • í›„ ì´ì  - íŒ€ì¥ ìˆ˜ì • ì „ ì´ì 
            surplus = round(manager_score_sum - module7_score_sum, 2)
            
            # ì „ì²´ CL ì¸ì› ì •ë³´
            total_cl_members = changed_members[0]['total_cl_members'] if changed_members else 0
            unchanged_members = changed_members[0]['unchanged_cl_members'] if changed_members else 0
            
            # ìƒìŠ¹ ìš”ì²­í•œ ì‚¬ëŒë“¤ ì‹ë³„ ë° íƒ€ë‹¹ì„± ë¶„ì„
            members_with_requests = []
            validity_summary = {"ë§¤ìš° íƒ€ë‹¹": 0, "íƒ€ë‹¹": 0, "ë³´í†µ": 0, "ì˜ì‹¬": 0, "ë§¤ìš° ì˜ì‹¬": 0}
            
            for m in changed_members:
                if m['score_diff'] > 0:  # ìƒìŠ¹ ìš”ì²­í•œ ê²½ìš°ë§Œ
                    validity_analysis = calculate_enhanced_captain_validity(m)
                    validity_grade = validity_analysis['validity_grade']
                    validity_summary[validity_grade] += 1
                    
                    members_with_requests.append({
                        "emp_no": m['emp_no'],
                        "score_diff": m['score_diff'],
                        "validity_grade": validity_grade,
                        "validity_score": validity_analysis['final_validity']
                    })
            
            # ì¡°ì • í•„ìš”ì„± íŒë‹¨ (ì´ˆê³¼ë¶„ì´ 0.05ì  ì´ìƒì´ë©´ ì¡°ì • í•„ìš”)
            needs_adjustment = abs(surplus) > 0.05
            
            # í†µê³„ ì¶œë ¥
            print(f"   ë³€ê²½ëœ ì¸ì›: {len(changed_members)}ëª… (ì „ì²´ {total_cl_members}ëª… ì¤‘)")
            print(f"   ë³€ê²½ ì—†ëŠ” ì¸ì›: {unchanged_members}ëª…")
            print(f"   ì ìˆ˜ ë³€í™” ì´í•©: {surplus:+.2f}ì ")
            print(f"   ìƒìŠ¹ ìš”ì²­ì: {len(members_with_requests)}ëª…")
            print(f"   íƒ€ë‹¹ì„± ë¶„í¬: ë§¤ìš°íƒ€ë‹¹ {validity_summary['ë§¤ìš° íƒ€ë‹¹']}ëª…, íƒ€ë‹¹ {validity_summary['íƒ€ë‹¹']}ëª…, ì˜ì‹¬ {validity_summary['ì˜ì‹¬']}ëª…")
            print(f"   ì¡°ì • í•„ìš”: {'âœ… Yes' if needs_adjustment else 'âŒ No'}")
            
            # department_dataì— ì €ì¥
            department_data[cl_group] = {
                "surplus": surplus,
                "needs_adjustment": needs_adjustment,
                "member_count": len(changed_members),
                "total_cl_members": total_cl_members,
                "unchanged_members": unchanged_members,
                "members_with_requests": members_with_requests,
                "validity_summary": validity_summary,
                "target_total": len(changed_members) * 3.5,  # ë³€ê²½ëœ ì§ì› ê¸°ì¤€
                "manager_score_sum": manager_score_sum,
                "target_stdev": get_cl_target_stdev(cl_group),
                "members_data": changed_members  # ë³€ê²½ëœ ì§ì›ë§Œ
            }
            
            total_members += total_cl_members
            total_changed_members += len(changed_members)
            
            if needs_adjustment:
                adjustment_needed_cls.append(cl_group)
        
        # ì „ì²´ ìš”ì•½
        print(f"\nğŸ“ˆ ë³¸ë¶€ {headquarter_id} íŒ€ì¥ ë³€ê²½ë¶„ ë¶„ì„ ìš”ì•½:")
        print(f"   ì „ì²´ ì¸ì›: {total_members}ëª…")
        print(f"   íŒ€ì¥ ë³€ê²½ ì¸ì›: {total_changed_members}ëª…")
        print(f"   ë³€ê²½ ì—†ëŠ” ì¸ì›: {total_members - total_changed_members}ëª…")
        print(f"   ì „ì²´ CL ê·¸ë£¹: {len(cl_groups)}ê°œ")
        print(f"   ì¡°ì • í•„ìš” CL: {len(adjustment_needed_cls)}ê°œ {adjustment_needed_cls}")
        
        # State ì—…ë°ì´íŠ¸
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"1ë‹¨ê³„ ì™„ë£Œ: {total_changed_members}/{total_members}ëª… ë³€ê²½, {len(adjustment_needed_cls)}ê°œ CL ì¡°ì • í•„ìš”")],
            "department_data": department_data
        })
        
        return updated_state
        
    except Exception as e:
        print(f"âŒ 1ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"1ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")],
            "error_logs": state.get("error_logs", []) + [f"department_data_collection: {str(e)}"]
        })
        return updated_state

def enhanced_analysis_submodule(state: Module9AgentState) -> Module9AgentState:
    """2ë‹¨ê³„: í–¥ìƒëœ íƒ€ë‹¹ì„± ë¶„ì„ - ë³€ê²½ëœ ì§ì›ë§Œ ë¶„ì„"""
    
    try:
        department_data = state["department_data"]
        headquarter_id = state["headquarter_id"]
        period_id = state["period_id"]
        
        print(f"ğŸ§  2ë‹¨ê³„: ë³€ê²½ëœ ì§ì› íƒ€ë‹¹ì„± ë¶„ì„ ì‹œì‘")
        
        enhanced_analysis = {}
        total_analyzed = 0
        
        # ì¡°ì •ì´ í•„ìš”í•œ CLë“¤ë§Œ ì²˜ë¦¬
        for cl_group, cl_data in department_data.items():
            if not cl_data["needs_adjustment"] or cl_data["member_count"] == 0:
                print(f"â­ï¸ {cl_group}: ë¶„ì„ ë¶ˆí•„ìš” (ë³€ê²½ëœ ì§ì› {cl_data['member_count']}ëª…)")
                enhanced_analysis[cl_group] = {
                    "analysis_completed": False,
                    "skip_reason": "ë³€ê²½ëœ ì§ì› ì—†ìŒ" if cl_data["member_count"] == 0 else "ì¡°ì • ë¶ˆí•„ìš”",
                    "members_analyzed": 0
                }
                continue
            
            print(f"\nğŸ” {cl_group} ë³€ê²½ëœ ì§ì› íƒ€ë‹¹ì„± ë¶„ì„ ì¤‘...")
            
            # ì•ˆì „í•œ í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            total_cl_members = cl_data.get('total_cl_members', cl_data['member_count'])
            print(f"   ëŒ€ìƒ: {cl_data['member_count']}ëª… (ì „ì²´ {total_cl_members}ëª… ì¤‘)")
            
            members = cl_data["members_data"]
            analyzed_members = []
            validity_distribution = {"ë§¤ìš° íƒ€ë‹¹": [], "íƒ€ë‹¹": [], "ë³´í†µ": [], "ì˜ì‹¬": [], "ë§¤ìš° ì˜ì‹¬": []}
            
            # ë³€ê²½ëœ ë©¤ë²„ë³„ ìƒì„¸ ë¶„ì„
            for member in members:
                score_diff = member.get('score_diff', 0)
                print(f"   ğŸ“‹ {member['emp_no']} ë¶„ì„ ì¤‘... (ë³€ê²½ëŸ‰: {score_diff:+.2f}ì )")
                
                # í–¥ìƒëœ íƒ€ë‹¹ì„± ë¶„ì„ ì‹¤í–‰
                validity_analysis = calculate_enhanced_captain_validity(member)
                
                # ì¢…í•© ì„±ê³¼ ì ìˆ˜ ê³„ì‚°
                comprehensive_score = calculate_comprehensive_performance_score(member)
                
                # ë¶„ì„ ê²°ê³¼ ì €ì¥
                analyzed_member = {
                    "emp_no": member["emp_no"],
                    "emp_name": member["emp_name"],
                    "original_manager_score": member["manager_score"],
                    "module7_score": member["module7_score"],
                    "score_diff": score_diff,
                    "captain_reason": member.get("captain_reason", ""),
                    "kpi_achievement": member.get("kpi_achievement", 100),
                    "validity_analysis": validity_analysis,
                    "comprehensive_performance": comprehensive_score,
                    "task_count": len(member.get("task_data", [])),
                    "peer_summary_available": bool(member.get("peer_evaluation_data", {}).get("peer_summary")),
                    "changed_by_manager": member.get("changed_by_manager", True)
                }
                
                analyzed_members.append(analyzed_member)
                validity_distribution[validity_analysis["validity_grade"]].append(member["emp_no"])
                total_analyzed += 1
                
                # ìƒì„¸ ì¶œë ¥
                print(f"     íƒ€ë‹¹ì„±: {validity_analysis['final_validity']:.3f} ({validity_analysis['validity_grade']})")
                print(f"     ì—…ë¬´ì¦ê±°: {validity_analysis['task_evidence']:.3f}, ë™ë£Œì¼ì¹˜: {validity_analysis['peer_consistency']:.3f}")
                print(f"     ì¢…í•©ì„±ê³¼: {comprehensive_score:.1f}ì ")
            
            # CLë³„ ë¶„ì„ ìš”ì•½
            if analyzed_members:
                avg_validity = sum(m["validity_analysis"]["final_validity"] for m in analyzed_members) / len(analyzed_members)
                high_validity_count = len([m for m in analyzed_members if m["validity_analysis"]["final_validity"] >= 0.7])
                low_validity_count = len([m for m in analyzed_members if m["validity_analysis"]["final_validity"] < 0.4])
                
                enhanced_analysis[cl_group] = {
                    "analysis_completed": True,
                    "members_analyzed": len(analyzed_members),
                    "analyzed_members": analyzed_members,
                    "validity_distribution": validity_distribution,
                    "avg_validity": round(avg_validity, 3),
                    "high_validity_count": high_validity_count,
                    "low_validity_count": low_validity_count,
                    "analysis_summary": {
                        "total_members": len(analyzed_members),
                        "avg_validity": round(avg_validity, 3),
                        "validity_range": f"{min(m['validity_analysis']['final_validity'] for m in analyzed_members):.3f} - {max(m['validity_analysis']['final_validity'] for m in analyzed_members):.3f}",
                        "high_validity_ratio": round(high_validity_count / len(analyzed_members) * 100, 1),
                        "recommendation": "ê³ íƒ€ë‹¹ì„±" if avg_validity >= 0.7 else "ë³´í†µíƒ€ë‹¹ì„±" if avg_validity >= 0.4 else "ì €íƒ€ë‹¹ì„±"
                    }
                }
                
                print(f"   âœ… {cl_group} ë¶„ì„ ì™„ë£Œ: í‰ê·  íƒ€ë‹¹ì„± {avg_validity:.3f}, ê³ íƒ€ë‹¹ì„± {high_validity_count}ëª…, ì €íƒ€ë‹¹ì„± {low_validity_count}ëª…")
            else:
                # ë¶„ì„í•  ë©¤ë²„ê°€ ì—†ëŠ” ê²½ìš°
                enhanced_analysis[cl_group] = {
                    "analysis_completed": False,
                    "skip_reason": "ë¶„ì„ ëŒ€ìƒ ì—†ìŒ",
                    "members_analyzed": 0
                }
        
        # ì „ì²´ ë¶„ì„ ìš”ì•½
        print(f"\nğŸ“Š 2ë‹¨ê³„ ë³€ê²½ëœ ì§ì› ë¶„ì„ ì™„ë£Œ:")
        print(f"   ì´ ë¶„ì„ ì¸ì›: {total_analyzed}ëª… (íŒ€ì¥ì´ ì ìˆ˜ ë³€ê²½í•œ ì§ì›ë§Œ)")
        
        completed_analyses = [analysis for analysis in enhanced_analysis.values() if analysis.get("analysis_completed")]
        if completed_analyses:
            overall_avg_validity = sum(analysis["avg_validity"] for analysis in completed_analyses) / len(completed_analyses)
            print(f"   ì „ì²´ í‰ê·  íƒ€ë‹¹ì„±: {overall_avg_validity:.3f}")
        
        # State ì—…ë°ì´íŠ¸
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"2ë‹¨ê³„ ì™„ë£Œ: {total_analyzed}ëª… ë³€ê²½ëœ ì§ì› ë¶„ì„")],
            "enhanced_analysis": enhanced_analysis
        })
        
        return updated_state
        
    except Exception as e:
        print(f"âŒ 2ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")
        print(f"   ë””ë²„ê·¸ ì •ë³´: {type(e).__name__}")
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"2ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")],
            "error_logs": state.get("error_logs", []) + [f"enhanced_analysis: {str(e)}"],
            "enhanced_analysis": {}  # ë¹ˆ ë¶„ì„ ê²°ê³¼ë¡œ ì´ˆê¸°í™”
        })
        return updated_state

# ================================================================
# 3ë‹¨ê³„ ì„œë¸Œëª¨ë“ˆ: cl_supervisor_execution
# ================================================================

def build_enhanced_supervisor_input_data(cl_group: str, cl_data: Dict, enhanced_analysis: Dict, headquarter_id: int) -> Dict:
    """í–¥ìƒëœ AI Supervisor ì…ë ¥ ë°ì´í„° êµ¬ì„±"""
    
    surplus = cl_data["surplus"]
    target_total = cl_data["target_total"]
    manager_score_sum = cl_data["manager_score_sum"]
    target_stdev = cl_data["target_stdev"]
    
    # í–¥ìƒëœ ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    analysis_data = enhanced_analysis.get(cl_group, {})
    analyzed_members = analysis_data.get("analyzed_members", [])
    
    # ë³¸ë¶€ëª… ì¡°íšŒ (ì‹¤ì œë¡œëŠ” DBì—ì„œ, ì§€ê¸ˆì€ ë”ë¯¸)
    headquarter_name = f"ë³¸ë¶€{headquarter_id}"
    
    supervisor_input = {
        "cl_group": cl_group,
        "headquarter_name": headquarter_name,
        "total_surplus": surplus,
        "current_situation": {
            "target_total": target_total,
            "manager_score_sum": manager_score_sum,
            "required_reduction": surplus
        },
        "distribution_targets": {
            "target_mean": 3.5,
            "target_stdev": target_stdev,
            "member_count": len(analyzed_members)
        },
        "enhanced_analysis_summary": analysis_data.get("analysis_summary", {}),
        "members": []
    }
    
    # ë©¤ë²„ë³„ í–¥ìƒëœ ë°ì´í„° êµ¬ì„±
    for analysis in analyzed_members:
        member_data = {
            "emp_no": analysis["emp_no"],
            "emp_name": analysis["emp_name"],
            "current_score": analysis["original_manager_score"],
            "baseline_score": analysis["module7_score"],
            "score_change": analysis["score_diff"],
            "captain_reason": analysis["captain_reason"],
            "kpi_achievement": analysis["kpi_achievement"],
            "validity_analysis": analysis["validity_analysis"],
            "comprehensive_performance": analysis["comprehensive_performance"],
            "task_count": analysis["task_count"],
            "peer_summary_available": analysis["peer_summary_available"],
            "final_evaluation_report_id": None  # ì›ë³¸ ë°ì´í„°ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨
        }
        
        # original member dataì—ì„œ final_evaluation_report_id ì°¾ê¸°
        for original_member in cl_data["members_data"]:
            if original_member["emp_no"] == analysis["emp_no"]:
                member_data["final_evaluation_report_id"] = original_member.get("final_evaluation_report_id")
                break
        
        supervisor_input["members"].append(member_data)
    
    return supervisor_input

def apply_standard_deviation_algorithm(llm_result: Dict, target_stdev: float, cl_group: str) -> Dict:
    """í‘œì¤€í¸ì°¨ë§Œ ìˆ˜í•™ì ìœ¼ë¡œ ì¡°ì •í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ - êµ¬ì¡° ì•ˆì „ì„± ê°•í™”"""
    
    # 1. ì•ˆì „í•œ adjustments ì¶”ì¶œ
    try:
        if "adjustments" in llm_result:
            # ì§ì ‘ êµ¬ì¡° (Fallback ê²°ê³¼)
            adjustments = llm_result["adjustments"]
            validation_check = llm_result.get("validation_check", {})
            is_nested_structure = False
        elif "result" in llm_result and "adjustments" in llm_result["result"]:
            # ì¤‘ì²© êµ¬ì¡° (LLM ê²°ê³¼)
            adjustments = llm_result["result"]["adjustments"]
            validation_check = llm_result["result"].get("validation_check", {})
            is_nested_structure = True
        else:
            raise KeyError(f"adjustmentsë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(llm_result.keys())}")
    except Exception as e:
        print(f"âŒ {cl_group}: adjustments ì¶”ì¶œ ì‹¤íŒ¨ - {str(e)}")
        return llm_result
    
    member_count = len(adjustments)
    if member_count == 0:
        print(f"âš ï¸ {cl_group}: ì¡°ì •í•  ë©¤ë²„ê°€ ì—†ìŠµë‹ˆë‹¤")
        return llm_result
    
    print(f"ğŸ“Š {cl_group} í‘œì¤€í¸ì°¨ ìˆ˜í•™ì  ì¡°ì •:")
    print(f"   ëŒ€ìƒ: {member_count}ëª…")
    
    # 2. í˜„ì¬ ìƒíƒœ ë¶„ì„
    try:
        current_scores = [(adj["final_score"], adj["emp_no"]) for adj in adjustments]
        current_scores.sort(key=lambda x: x[0], reverse=True)  # ì ìˆ˜ ìˆœ ì •ë ¬ (ë†’ì€ ìˆœ)
        
        score_values = [score for score, _ in current_scores]
        current_stdev = statistics.stdev(score_values) if member_count > 1 else 0
        current_mean = sum(score_values) / member_count
        
        print(f"   í˜„ì¬: í‰ê·  {current_mean:.3f}, í‘œì¤€í¸ì°¨ {current_stdev:.2f}")
        print(f"   ëª©í‘œ: í‰ê·  3.500, í‘œì¤€í¸ì°¨ {target_stdev:.1f}")
        
    except Exception as e:
        print(f"âŒ {cl_group}: í˜„ì¬ ìƒíƒœ ë¶„ì„ ì‹¤íŒ¨ - {str(e)}")
        return llm_result
    
    # 3. í‘œì¤€í¸ì°¨ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
    stdev_diff = abs(current_stdev - target_stdev)
    if stdev_diff <= 0.2:
        print(f"   âœ… í‘œì¤€í¸ì°¨ ì´ë¯¸ ë‹¬ì„± (ì°¨ì´: {stdev_diff:.2f})")
        return llm_result
    
    # 4. ëª©í‘œ í‘œì¤€í¸ì°¨ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì ìˆ˜ ê³„ì‚°
    target_mean = 3.5
    
    try:
        if member_count == 1:
            # 1ëª…ì¸ ê²½ìš°: í‰ê· ê°’ë§Œ ì„¤ì •
            new_scores = [target_mean]
            
        elif member_count == 2:
            # 2ëª…ì¸ ê²½ìš°: í‰ê·  ê¸°ì¤€ ëŒ€ì¹­ ë¶„í¬
            spread = target_stdev * 1.0  # 2ëª…ì¼ ë•Œ ì ì ˆí•œ ë¶„ì‚°
            new_scores = [
                target_mean + spread,
                target_mean - spread
            ]
            
        else:
            # 3ëª… ì´ìƒì¸ ê²½ìš°: ë“±ì°¨ìˆ˜ì—´ ê¸°ë°˜ ë¶„í¬
            # í‘œì¤€í¸ì°¨ ê³µì‹: Ïƒ = sqrt(Î£(x-Î¼)Â²/n)
            # ë“±ì°¨ìˆ˜ì—´ì—ì„œ í‘œì¤€í¸ì°¨ë¥¼ ì—­ì‚°í•˜ì—¬ ë²”ìœ„ ê²°ì •
            
            # ì•ˆì „í•œ ë²”ìœ„ ì„¤ì • (0.0 ~ 5.0 ë‚´ì—ì„œ)
            max_spread = min(2.0, target_stdev * 2.0)  # ìµœëŒ€ ë¶„ì‚° ì œí•œ
            max_score = min(5.0, target_mean + max_spread)
            min_score = max(0.0, target_mean - max_spread)
            
            # ë“±ì°¨ìˆ˜ì—´ ìƒì„±
            if member_count > 1:
                step = (max_score - min_score) / (member_count - 1)
                new_scores = [max_score - i * step for i in range(member_count)]
            else:
                new_scores = [target_mean]
            
            # í‰ê·  ë³´ì •
            current_new_mean = sum(new_scores) / member_count
            mean_adjustment = target_mean - current_new_mean
            new_scores = [score + mean_adjustment for score in new_scores]
            
            # ë²”ìœ„ ì œí•œ ì¬ì ìš©
            new_scores = [max(0.0, min(5.0, score)) for score in new_scores]
            
            # í‰ê·  ì¬ë³´ì • (ë²”ìœ„ ì œí•œ í›„)
            actual_mean = sum(new_scores) / member_count
            if abs(actual_mean - target_mean) > 0.01:
                final_adjustment = target_mean - actual_mean
                new_scores = [max(0.0, min(5.0, score + final_adjustment)) for score in new_scores]
        
        print(f"   ê³„ì‚°ëœ ìƒˆ ì ìˆ˜: {[round(s, 2) for s in new_scores]}")
        
    except Exception as e:
        print(f"âŒ {cl_group}: ìƒˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨ - {str(e)}")
        return llm_result
    
    # 5. ìƒˆë¡œìš´ ì ìˆ˜ ì ìš© (ì„±ê³¼ ìˆœìœ„ ìœ ì§€)
    try:
        for i, (old_score, emp_no) in enumerate(current_scores):
            for adj in adjustments:
                if adj["emp_no"] == emp_no:
                    adj["final_score"] = round(new_scores[i], 2)
                    adj["change_amount"] = round(adj["final_score"] - adj["original_score"], 2)
                    
                    # change_type ì—…ë°ì´íŠ¸
                    if adj["change_amount"] < -0.01:
                        adj["change_type"] = "decrease"
                    elif adj["change_amount"] > 0.01:
                        adj["change_type"] = "increase"
                    else:
                        adj["change_type"] = "maintain"
                    
                    # ì¡°ì • ì‚¬ìœ  ì—…ë°ì´íŠ¸
                    rank = i + 1
                    adj["reason"] = f"í‘œì¤€í¸ì°¨ ì¡°ì •: {rank}ìœ„/{member_count}ëª… (ëª©í‘œ Ïƒ={target_stdev:.1f})"
                    break
                    
    except Exception as e:
        print(f"âŒ {cl_group}: ì ìˆ˜ ì ìš© ì‹¤íŒ¨ - {str(e)}")
        return llm_result
    
    # 6. ìµœì¢… ê²€ì¦
    try:
        final_scores = [adj["final_score"] for adj in adjustments]
        final_mean = sum(final_scores) / member_count
        final_stdev = statistics.stdev(final_scores) if member_count > 1 else 0
        
        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        mean_achieved = abs(final_mean - 3.5) <= 0.02
        stdev_achieved = abs(final_stdev - target_stdev) <= 0.3
        
        print(f"   ê²°ê³¼: í‰ê·  {final_mean:.3f}, í‘œì¤€í¸ì°¨ {final_stdev:.2f}")
        print(f"   í‰ê·  ë‹¬ì„±: {'âœ…' if mean_achieved else 'âš ï¸'}")
        print(f"   í‘œì¤€í¸ì°¨ ë‹¬ì„±: {'âœ…' if stdev_achieved else 'âš ï¸'}")
        
        # validation_check ì—…ë°ì´íŠ¸
        validation_updates = {
            "actual_mean": round(final_mean, 3),
            "actual_stdev": round(final_stdev, 2),
            "target_stdev": target_stdev,
            "mean_achieved": mean_achieved,
            "stdev_achieved": stdev_achieved,
            "stdev_adjustment_applied": True
        }
        
        validation_check.update(validation_updates)
        
    except Exception as e:
        print(f"âŒ {cl_group}: ìµœì¢… ê²€ì¦ ì‹¤íŒ¨ - {str(e)}")
        return llm_result
    
    # 7. ê²°ê³¼ êµ¬ì¡° ë³µì›
    try:
        if is_nested_structure:
            # LLM ê²°ê³¼ êµ¬ì¡°: result í‚¤ ì•ˆì— ì €ì¥
            result_data = {
                "analysis_summary": llm_result.get("result", {}).get("analysis_summary", f"{cl_group} í‘œì¤€í¸ì°¨ ì¡°ì • ì™„ë£Œ"),
                "adjustments": adjustments,
                "validation_check": validation_check
            }
            return result_data
        else:
            # Fallback ê²°ê³¼ êµ¬ì¡°: ì§ì ‘ ì €ì¥
            return {
                "analysis_summary": llm_result.get("analysis_summary", f"{cl_group} í‘œì¤€í¸ì°¨ ì¡°ì • ì™„ë£Œ"),
                "adjustments": adjustments,
                "validation_check": validation_check
            }
            
    except Exception as e:
        print(f"âŒ {cl_group}: ê²°ê³¼ êµ¬ì¡° ë³µì› ì‹¤íŒ¨ - {str(e)}")
        return llm_result

def cl_supervisor_execution_submodule(state: Module9AgentState) -> Module9AgentState:
    """3ë‹¨ê³„: CLë³„ í–¥ìƒëœ Supervisor ì‹¤í–‰ ì„œë¸Œëª¨ë“ˆ"""
    
    try:
        department_data = state["department_data"]
        enhanced_analysis = state["enhanced_analysis"]
        headquarter_id = state["headquarter_id"]
        period_id = state["period_id"]
        
        print(f"ğŸ¯ 3ë‹¨ê³„: LLM ì œë¡œì„¬ + ìˆ˜í•™ í‘œì¤€í¸ì°¨ ë¶„ë¦¬ ì‹¤í–‰ ì‹œì‘")
        
        supervisor_results = {}
        total_adjustments = 0
        
        # ì¡°ì •ì´ í•„ìš”í•œ CLë“¤ë§Œ ì²˜ë¦¬
        for cl_group, cl_data in department_data.items():
            if not cl_data["needs_adjustment"]:
                print(f"â­ï¸ {cl_group}: ì¡°ì • ë¶ˆí•„ìš” (surplus: {cl_data['surplus']:.2f})")
                supervisor_results[cl_group] = {
                    "success": True,
                    "adjustments_made": 0,
                    "distribution_achieved": True,
                    "processing_time_ms": 0,
                    "fallback_used": False,
                    "skip_reason": "ì¡°ì • ë¶ˆí•„ìš”"
                }
                continue
            
            print(f"\nğŸ¯ {cl_group} 2ë‹¨ê³„ ì²˜ë¦¬ ì¤‘... (surplus: {cl_data['surplus']:+.2f}ì )")
            
            # 1. Supervisor ì…ë ¥ ë°ì´í„° êµ¬ì„±
            supervisor_input = build_enhanced_supervisor_input_data(cl_group, cl_data, enhanced_analysis, headquarter_id)
            
            # 2. LLM ì œë¡œì„¬ ì¡°ì • ì‹¤í–‰ (í‘œì¤€í¸ì°¨ ì œì™¸)
            import time
            start_time = time.time()
            
            print(f"ğŸ§  {cl_group}: LLM ì„±ê³¼ ê¸°ë°˜ ì œë¡œì„¬ ì¡°ì •")
            llm_result = call_enhanced_supervisor_llm(supervisor_input)
            
            processing_time = int((time.time() - start_time) * 1000)
            
            # 3. LLM ê²°ê³¼ ì²˜ë¦¬
            if llm_result["success"]:
                print(f"âœ… {cl_group}: LLM ì œë¡œì„¬ ì¡°ì • ì„±ê³µ")
                
                # 4. í‘œì¤€í¸ì°¨ ìˆ˜í•™ì  ì¡°ì • ì‹¤í–‰
                target_stdev = cl_data.get("target_stdev", get_cl_target_stdev(cl_group))
                print(f"ğŸ“Š {cl_group}: í‘œì¤€í¸ì°¨ ìˆ˜í•™ì  ì¡°ì • ({target_stdev:.1f}ì  ëª©í‘œ)")
                
                # êµ¬ì¡°ì— ë§ê²Œ ì „ë‹¬
                final_result = apply_standard_deviation_algorithm(llm_result["result"], target_stdev, cl_group)
                supervisor_output = final_result
                fallback_used = False
                
            else:
                print(f"ğŸ”§ {cl_group}: LLM ì‹¤íŒ¨, Fallback ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰")
                
                # Fallback ì‹¤í–‰ ì „ì— supervisor_input í™•ì¸
                if not supervisor_input.get("members"):
                    print(f"âŒ {cl_group}: supervisor_inputì— members ë°ì´í„° ì—†ìŒ")
                    supervisor_results[cl_group] = {
                        "success": False,
                        "error": "supervisor_inputì— members ë°ì´í„° ì—†ìŒ",
                        "adjustments_made": 0,
                        "fallback_used": True
                    }
                    continue
                
                try:
                    supervisor_output = execute_proper_zero_sum_adjustment(supervisor_input)
                    if not supervisor_output.get("adjustments"):
                        print(f"âŒ {cl_group}: Fallbackì—ì„œ adjustments ìƒì„± ì‹¤íŒ¨")
                        supervisor_results[cl_group] = {
                            "success": False,
                            "error": "Fallbackì—ì„œ adjustments ìƒì„± ì‹¤íŒ¨",
                            "adjustments_made": 0,
                            "fallback_used": True
                        }
                        continue
                except Exception as fallback_error:
                    print(f"âŒ {cl_group}: Fallback ì‹¤í–‰ ì‹¤íŒ¨ - {str(fallback_error)}")
                    supervisor_results[cl_group] = {
                        "success": False,
                        "error": f"Fallback ì‹¤í–‰ ì‹¤íŒ¨: {str(fallback_error)}",
                        "adjustments_made": 0,
                        "fallback_used": True
                    }
                    continue
                
                # Fallback ê²°ê³¼ì—ë„ í‘œì¤€í¸ì°¨ ì¡°ì • ì ìš©
                target_stdev = cl_data.get("target_stdev", get_cl_target_stdev(cl_group))
                fake_llm_result = {"result": supervisor_output, "success": True}
                try:
                    final_result = apply_standard_deviation_algorithm(fake_llm_result, target_stdev, cl_group)
                    supervisor_output = final_result["result"]
                except Exception as stdev_error:
                    print(f"âš ï¸ {cl_group}: í‘œì¤€í¸ì°¨ ì¡°ì • ì‹¤íŒ¨ - {str(stdev_error)}")
                    # í‘œì¤€í¸ì°¨ ì¡°ì • ì‹¤íŒ¨í•´ë„ ì›ë³¸ ê²°ê³¼ ì‚¬ìš©
                    pass
                    
                fallback_used = True
            
            # 5. ìµœì¢… ê²€ì¦
            adjustments = supervisor_output["adjustments"]
            target_reduction = cl_data["surplus"]
            target_stdev = cl_data.get("target_stdev", get_cl_target_stdev(cl_group))
            
            validation_result = validate_zero_sum_result(adjustments, target_reduction, target_stdev, cl_group)
            
            # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
            if validation_result["valid"]:
                print(f"âœ… {cl_group} 2ë‹¨ê³„ ì²˜ë¦¬ ì™„ë£Œ")
                print(f"   ğŸ“Š ê²°ê³¼: í‰ê·  {validation_result['metrics']['actual_mean']:.3f}, í‘œì¤€í¸ì°¨ {validation_result['metrics']['actual_stdev']:.2f}")
                print(f"   ğŸ’° ì°¨ê°: {validation_result['metrics']['actual_reduction']:.3f}/{validation_result['metrics']['target_reduction']:.3f}")
            else:
                print(f"âš ï¸ {cl_group} ê²€ì¦ ê²½ê³ :")
                for warning in validation_result["warnings"][:2]:
                    print(f"     - {warning}")
            
            # ì„±ê³¼ ì—­ì „ ì²´í¬
            if validation_result["performance_reversal"]["has_reversal"]:
                print(f"   âš ï¸ ì„±ê³¼ ì—­ì „: {validation_result['performance_reversal']['reversal_count']}ê±´")
            
            # 6. DB ì—…ë°ì´íŠ¸ (ì ìˆ˜)
            update_result = batch_update_final_evaluation_reports(adjustments, period_id)
            
            # 7. íŒ€ë³„ ìˆœìœ„ ì—…ë°ì´íŠ¸ (ìƒˆë¡œ ì¶”ê°€)
            print(f"ğŸ† {cl_group}: íŒ€ë³„ ìˆœìœ„ ì—…ë°ì´íŠ¸ ì‹œì‘...")
            try:
                ranking_result = update_team_rankings(period_id)
                if ranking_result["success_count"] > 0:
                    print(f"   âœ… ìˆœìœ„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {ranking_result['success_count']}/{ranking_result['total_teams']}ê°œ íŒ€ ì„±ê³µ")
                else:
                    print(f"   âš ï¸ ìˆœìœ„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {ranking_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            except Exception as ranking_error:
                print(f"   âŒ ìˆœìœ„ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(ranking_error)}")
                ranking_result = {"success_count": 0, "error": str(ranking_error)}
            
            # 8. ê²°ê³¼ ì €ì¥
            supervisor_results[cl_group] = {
                "success": True,
                "adjustments_made": update_result["success_count"],
                "distribution_achieved": validation_result["valid"],
                "processing_time_ms": processing_time,
                "fallback_used": fallback_used,
                "update_success_count": update_result["success_count"],
                "update_failed_count": update_result["failed_count"],
                "validation_result": validation_result,
                "supervisor_output": supervisor_output,
                "ranking_update": ranking_result,
                "enhanced_features": {
                    "llm_zero_sum_used": not fallback_used,
                    "math_stdev_applied": True,
                    "two_stage_processing": True
                }
            }
            
            total_adjustments += update_result["success_count"]
            
            print(f"âœ… {cl_group} 2ë‹¨ê³„ ì²˜ë¦¬ ì™„ë£Œ: {update_result['success_count']}ëª… ì¡°ì •, ìˆœìœ„ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # State ì—…ë°ì´íŠ¸
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"3ë‹¨ê³„ ì™„ë£Œ: {total_adjustments}ëª… 2ë‹¨ê³„ ì¡°ì • (LLM ì œë¡œì„¬ + ìˆ˜í•™ í‘œì¤€í¸ì°¨)")],
            "supervisor_results": supervisor_results
        })
        
        return updated_state
        
    except Exception as e:
        print(f"âŒ 3ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"3ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")],
            "error_logs": state.get("error_logs", []) + [f"cl_supervisor_execution: {str(e)}"]
        })
        return updated_state

# ================================================================
# 4ë‹¨ê³„ ì„œë¸Œëª¨ë“ˆ: batch_update
# ================================================================

def batch_update_submodule(state: Module9AgentState) -> Module9AgentState:
    """4ë‹¨ê³„: ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì„œë¸Œëª¨ë“ˆ - í–¥ìƒëœ ë¶„ì„ ê²°ê³¼ í†µí•© ë° ìµœì¢… ì§‘ê³„"""
    
    try:
        supervisor_results = state["supervisor_results"]
        enhanced_analysis = state["enhanced_analysis"]
        
        print(f"ğŸ“Š 4ë‹¨ê³„: í–¥ìƒëœ ë°°ì¹˜ ì—…ë°ì´íŠ¸ ë° ê²°ê³¼ ì§‘ê³„ ì‹œì‘")
        
        # ì „ì²´ ê²°ê³¼ ì§‘ê³„
        total_cls_processed = len(supervisor_results)
        successful_cls = 0
        failed_cls = 0
        total_adjustments = 0
        total_distribution_achieved = 0
        total_processing_time = 0
        fallback_used_count = 0
        enhanced_features_used = 0
        
        successful_employees = []
        failed_employees = []
        cl_summaries = []
        
        # CLë³„ ê²°ê³¼ ë¶„ì„
        for cl_group, result in supervisor_results.items():
            cl_summary = {
                "cl_group": cl_group,
                "success": result["success"],
                "adjustments_made": result["adjustments_made"],
                "distribution_achieved": result.get("distribution_achieved", False),
                "processing_time_ms": result["processing_time_ms"],
                "fallback_used": result["fallback_used"],
                "enhanced_features": result.get("enhanced_features", {})
            }
            
            # í–¥ìƒëœ ë¶„ì„ ì •ë³´ ì¶”ê°€
            if cl_group in enhanced_analysis:
                analysis_info = enhanced_analysis[cl_group]
                if analysis_info.get("analysis_completed"):
                    cl_summary["enhanced_analysis"] = {
                        "avg_validity": analysis_info["avg_validity"],
                        "high_validity_count": analysis_info["high_validity_count"],
                        "low_validity_count": analysis_info["low_validity_count"],
                        "recommendation": analysis_info["analysis_summary"]["recommendation"]
                    }
            
            # ì§‘ê³„
            if result["success"]:
                successful_cls += 1
                total_adjustments += result["adjustments_made"]
                
                if result.get("distribution_achieved"):
                    total_distribution_achieved += 1
                
                if result["fallback_used"]:
                    fallback_used_count += 1
                
                if result.get("enhanced_features", {}).get("validity_analysis_used"):
                    enhanced_features_used += 1
                
                total_processing_time += result["processing_time_ms"]
                
                # ì„±ê³µí•œ ì§ì›ë“¤ ìˆ˜ì§‘
                if result.get("supervisor_output") and result["supervisor_output"].get("adjustments"):
                    for adj in result["supervisor_output"]["adjustments"]:
                        employee_info = {
                            "emp_no": adj["emp_no"],
                            "cl_group": cl_group,
                            "original_score": adj["original_score"],
                            "final_score": adj["final_score"],
                            "change_amount": adj["change_amount"],
                            "reason": adj["reason"]
                        }
                        
                        # í–¥ìƒëœ ë¶„ì„ ì •ë³´ ì¶”ê°€
                        if "validity_analysis" in adj:
                            employee_info["validity_grade"] = adj["validity_analysis"]["validity_grade"]
                            employee_info["final_validity"] = adj["validity_analysis"]["final_validity"]
                        
                        successful_employees.append(employee_info)
                
                cl_summary["status"] = "ì™„ë£Œ"
                if result.get("skip_reason"):
                    cl_summary["note"] = result["skip_reason"]
                elif result["fallback_used"]:
                    cl_summary["note"] = "í–¥ìƒëœ Fallback ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©"
                else:
                    cl_summary["note"] = "í–¥ìƒëœ AI Supervisor ì„±ê³µ"
                    
                # ê²€ì¦ ê²°ê³¼ ì¶”ê°€
                if "validation_result" in result:
                    validation = result["validation_result"]
                    cl_summary["validation_summary"] = {
                        "valid": validation["valid"],
                        "zero_sum_achieved": validation["metrics"]["reduction_error"] < 0.02,
                        "stdev_achieved": validation["metrics"]["stdev_error"] < 0.3,
                        "performance_reversal": validation["performance_reversal"]["has_reversal"]
                    }
            else:
                failed_cls += 1
                cl_summary["status"] = "ì‹¤íŒ¨"
                cl_summary["error"] = result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                
                # ì‹¤íŒ¨í•œ ì§ì›ë“¤ ì¶”ì •
                department_data = state.get("department_data", {})
                if cl_group in department_data:
                    for member in department_data[cl_group].get("members_data", []):
                        failed_employees.append({
                            "emp_no": member["emp_no"],
                            "cl_group": cl_group,
                            "error": result.get("error", "ì²˜ë¦¬ ì‹¤íŒ¨")
                        })
            
            cl_summaries.append(cl_summary)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            status_icon = "âœ…" if result["success"] else "âŒ"
            enhanced_note = " (í–¥ìƒë¨)" if result.get("enhanced_features", {}).get("validity_analysis_used") else ""
            validation_note = ""
            
            if result["success"] and "validation_result" in result:
                validation = result["validation_result"]
                if validation["valid"]:
                    validation_note = " âœ“ê²€ì¦í†µê³¼"
                else:
                    validation_note = f" âš ï¸ê²€ì¦ì‹¤íŒ¨({len(validation['errors'])}ê±´)"
            
            print(f"   {status_icon} {cl_group}: {cl_summary['status']} ({result['adjustments_made']}ëª…){enhanced_note}{validation_note}")
        
        # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°
        success_rate = (successful_cls / total_cls_processed * 100) if total_cls_processed > 0 else 0
        distribution_rate = (total_distribution_achieved / successful_cls * 100) if successful_cls > 0 else 0
        enhanced_rate = (enhanced_features_used / successful_cls * 100) if successful_cls > 0 else 0
        avg_processing_time = (total_processing_time / successful_cls) if successful_cls > 0 else 0
        
        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        update_results = {
            "total_cls_processed": total_cls_processed,
            "successful_cls": successful_cls,
            "failed_cls": failed_cls,
            "success_rate": round(success_rate, 1),
            "total_adjustments": total_adjustments,
            "distribution_achieved_count": total_distribution_achieved,
            "distribution_rate": round(distribution_rate, 1),
            "fallback_used_count": fallback_used_count,
            "enhanced_features_used_count": enhanced_features_used,
            "enhanced_rate": round(enhanced_rate, 1),
            "total_processing_time_ms": total_processing_time,
            "avg_processing_time_ms": round(avg_processing_time, 0),
            "successful_employees": successful_employees,
            "failed_employees": failed_employees,
            "cl_summaries": cl_summaries
        }
        
        # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“ˆ í–¥ìƒëœ ìµœì¢… ì§‘ê³„ ê²°ê³¼:")
        print(f"   ì²˜ë¦¬ëœ CL ê·¸ë£¹: {total_cls_processed}ê°œ")
        print(f"   ì„±ê³µí•œ CL: {successful_cls}ê°œ ({success_rate:.1f}%)")
        print(f"   ì‹¤íŒ¨í•œ CL: {failed_cls}ê°œ")
        print(f"   ì´ ì¡°ì • ì¸ì›: {total_adjustments}ëª…")
        print(f"   ë¶„í¬ ë‹¬ì„±: {total_distribution_achieved}/{successful_cls}ê°œ CL ({distribution_rate:.1f}%)")
        print(f"   Fallback ì‚¬ìš©: {fallback_used_count}ê°œ CL")
        print(f"   í–¥ìƒëœ ê¸°ëŠ¥ ì‚¬ìš©: {enhanced_features_used}/{successful_cls}ê°œ CL ({enhanced_rate:.1f}%)")
        print(f"   í‰ê·  ì²˜ë¦¬ì‹œê°„: {avg_processing_time:.0f}ms")
        
        if failed_employees:
            print(f"   âŒ ì‹¤íŒ¨ ì§ì›: {len(failed_employees)}ëª…")
            for failed in failed_employees[:3]:  # ì²˜ìŒ 3ëª…ë§Œ
                print(f"     - {failed['emp_no']} ({failed['cl_group']}): {failed['error']}")
        
        # State ì—…ë°ì´íŠ¸
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"4ë‹¨ê³„ ì™„ë£Œ: {total_adjustments}ëª… í–¥ìƒëœ ì¡°ì •, {successful_cls}/{total_cls_processed}ê°œ CL ì„±ê³µ")],
            "update_results": update_results,
            "total_processed": len(successful_employees),
            "total_failed": len(failed_employees)
        })
        
        return updated_state
        
    except Exception as e:
        print(f"âŒ 4ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")
        updated_state = state.copy()
        updated_state.update({
            "messages": [HumanMessage(content=f"4ë‹¨ê³„ ì‹¤íŒ¨: {str(e)}")],
            "error_logs": state.get("error_logs", []) + [f"batch_update: {str(e)}"],
            "update_results": {"error": str(e)},
            "total_processed": 0,
            "total_failed": 0
        })
        return updated_state


# ================================================================
# LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
# ================================================================

def create_enhanced_module9_graph():
    """í–¥ìƒëœ ëª¨ë“ˆ9 LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    
    # StateGraph ìƒì„±
    enhanced_module9_workflow = StateGraph(Module9AgentState)
    
    # ë…¸ë“œ ì¶”ê°€ (4ê°œ ì„œë¸Œëª¨ë“ˆ)
    enhanced_module9_workflow.add_node("department_data_collection", department_data_collection)
    enhanced_module9_workflow.add_node("validity_analysis", enhanced_analysis_submodule)
    enhanced_module9_workflow.add_node("cl_supervisor_execution", cl_supervisor_execution_submodule)
    enhanced_module9_workflow.add_node("batch_update", batch_update_submodule)
    
    # ì—£ì§€ ì •ì˜ (ìˆœì°¨ ì‹¤í–‰)
    enhanced_module9_workflow.add_edge(START, "department_data_collection")
    enhanced_module9_workflow.add_edge("department_data_collection", "validity_analysis")
    enhanced_module9_workflow.add_edge("validity_analysis", "cl_supervisor_execution")
    enhanced_module9_workflow.add_edge("cl_supervisor_execution", "batch_update")
    enhanced_module9_workflow.add_edge("batch_update", END)
    
    return enhanced_module9_workflow.compile()