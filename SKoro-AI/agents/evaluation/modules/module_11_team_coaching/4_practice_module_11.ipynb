{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨\n",
    "import pymysql\n",
    "from pymysql.cursors import DictCursor\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Row\n",
    "from sqlalchemy.exc import OperationalError\n",
    "\n",
    "# AI/LLM ê´€ë ¨\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# ì„¤ì • ê´€ë¦¬\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(\"C:/Users/Administrator/Desktop/skala10/SKoro-AI/.env\", override=True)\n",
    "\n",
    "# ====================================\n",
    "# 2. ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜\n",
    "# ====================================\n",
    "\n",
    "class Module11Error(Exception):\n",
    "    \"\"\"ëª¨ë“ˆ 11 ì „ìš© ì˜ˆì™¸\"\"\"\n",
    "    pass\n",
    "\n",
    "class DatabaseError(Module11Error):\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì˜ˆì™¸\"\"\"\n",
    "    pass\n",
    "\n",
    "# ====================================\n",
    "# 3. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •\n",
    "# ====================================\n",
    "\n",
    "# DB ì—°ê²° ì„¤ì •\n",
    "db_type = os.getenv(\"DB_TYPE\")  # mariadb\n",
    "db_username = os.getenv(\"DB_USERNAME\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# MariaDB/MySQLì˜ ê²½ìš° mysql+pymysql ë“œë¼ì´ë²„ ì‚¬ìš©\n",
    "if db_type.lower() in [\"mariadb\", \"mysql\"]:\n",
    "    DATABASE_URL = f\"mysql+pymysql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "else:\n",
    "    DATABASE_URL = f\"{db_type}://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    "\n",
    "# DB ì—”ì§„ ìƒì„±\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# LLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "llm_client = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# ====================================\n",
    "\n",
    "def row_to_dict(row: Row) -> Dict:\n",
    "    \"\"\"SQLAlchemy Row ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\"\"\"\n",
    "    if row is None:\n",
    "        return {}\n",
    "    return row._asdict()\n",
    "\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# 5. ë°ì´í„° í´ë˜ìŠ¤\n",
    "# ====================================\n",
    "\n",
    "@dataclass\n",
    "class Module11AgentState:\n",
    "    # í•„ìˆ˜ í‚¤ê°’ë“¤\n",
    "    team_id: int\n",
    "    period_id: int\n",
    "    team_evaluation_id: int\n",
    "    is_final: bool\n",
    "    \n",
    "    # ë¶„ì„ ê³¼ì •ì—ì„œ ë„ì¶œëœ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë§Œ (ê°€ë²¼ìš´ ë°ì´í„°)\n",
    "    key_risks: Optional[List[str]] = None\n",
    "    collaboration_bias_level: Optional[str] = None  # \"high\", \"medium\", \"low\"\n",
    "    performance_trend: Optional[str] = None\n",
    "    \n",
    "    # ìµœì¢… JSON ê²°ê³¼\n",
    "    ai_risk_result: Optional[Dict[str, Any]] = None\n",
    "    ai_plan_result: Optional[Dict[str, Any]] = None\n",
    "    overall_comment_result: Optional[str] = None  # TEXT í˜•íƒœ\n",
    "\n",
    "# ====================================\n",
    "# 6. DB ë˜í¼ í´ë˜ìŠ¤\n",
    "# ====================================\n",
    "\n",
    "class SQLAlchemyDBWrapper:\n",
    "    \"\"\"ìˆ˜ì •ëœ DB ë˜í¼ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "    \n",
    "    def fetch_one(self, query, params=None):\n",
    "        \"\"\"ë‹¨ì¼ í–‰ ì¡°íšŒ\"\"\"\n",
    "        with self.engine.connect() as conn:\n",
    "            result = conn.execute(text(query), params or {})\n",
    "            row = result.fetchone()\n",
    "            return row._asdict() if row else None\n",
    "    \n",
    "    def fetch_all(self, query, params=None):\n",
    "        \"\"\"ì „ì²´ í–‰ ì¡°íšŒ\"\"\"\n",
    "        with self.engine.connect() as conn:\n",
    "            result = conn.execute(text(query), params or {})\n",
    "            rows = result.fetchall()\n",
    "            return [row._asdict() for row in rows] if rows else []\n",
    "    \n",
    "    def execute_update(self, query, params=None):\n",
    "        \"\"\"ì—…ë°ì´íŠ¸ ì‹¤í–‰ (ìˆ˜ì •ëœ ë²„ì „)\"\"\"\n",
    "        with self.engine.begin() as conn:  # ğŸ”¥ ìë™ íŠ¸ëœì­ì…˜ ê´€ë¦¬\n",
    "            result = conn.execute(text(query), params or {})\n",
    "            affected_rows = result.rowcount\n",
    "            \n",
    "            # ëª…ì‹œì  ê²€ì¦\n",
    "            if affected_rows == 0:\n",
    "                logger.warning(f\"ì—…ë°ì´íŠ¸ëœ í–‰ì´ ì—†ìŒ: query={query[:100]}...\")\n",
    "            else:\n",
    "                logger.info(f\"ì—…ë°ì´íŠ¸ ì™„ë£Œ: {affected_rows}í–‰ ì˜í–¥\")\n",
    "            \n",
    "            return affected_rows\n",
    "\n",
    "# DB ë˜í¼ í´ë˜ìŠ¤ ì´ˆê¸°í™”\n",
    "db_wrapper = SQLAlchemyDBWrapper(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================\n",
    "# 7. ë©”ì¸ Module11 í´ë˜ìŠ¤\n",
    "# ====================================\n",
    "\n",
    "class Module11TeamRiskManagementAgent:\n",
    "    def __init__(self, db_connection):\n",
    "        self.db = db_connection\n",
    "    \n",
    "    def _parse_json_field(self, json_str: Optional[str]) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"JSON í•„ë“œ ì•ˆì „ íŒŒì‹± (í´ë˜ìŠ¤ ë©”ì„œë“œ)\"\"\"\n",
    "        if not json_str:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            logger.warning(f\"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)[:100]}...\")\n",
    "            return None\n",
    "    \n",
    "    def _extract_json_from_llm_response(self, text: str) -> str:\n",
    "        \"\"\"ê°œì„ ëœ LLM ì‘ë‹µì—ì„œ JSON ë¸”ë¡ ì¶”ì¶œ\"\"\"\n",
    "        \n",
    "        # 1. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ (ê°€ì¥ ì¼ë°˜ì )\n",
    "        json_block_pattern = r\"```(?:json)?\\s*(.*?)\\s*```\"\n",
    "        match = re.search(json_block_pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            json_content = match.group(1).strip()\n",
    "            if self._is_valid_json_string(json_content):\n",
    "                return json_content\n",
    "        \n",
    "        # 2. ì¤‘ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ JSON ê°ì²´ ì°¾ê¸° (ì¤‘ì²© ê³ ë ¤)\n",
    "        json_objects = self._extract_nested_json_objects(text)\n",
    "        for json_obj in json_objects:\n",
    "            if self._is_valid_json_string(json_obj):\n",
    "                return json_obj\n",
    "        \n",
    "        # 3. ì „ì²´ í…ìŠ¤íŠ¸ê°€ JSONì¸ì§€ í™•ì¸\n",
    "        stripped_text = text.strip()\n",
    "        if stripped_text.startswith('{') and stripped_text.endswith('}'):\n",
    "            if self._is_valid_json_string(stripped_text):\n",
    "                return stripped_text\n",
    "        \n",
    "        # 4. ìµœí›„ì˜ ìˆ˜ë‹¨: ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€\n",
    "        first_brace = text.find('{')\n",
    "        last_brace = text.rfind('}')\n",
    "        if first_brace != -1 and last_brace != -1 and first_brace < last_brace:\n",
    "            potential_json = text[first_brace:last_brace + 1]\n",
    "            if self._is_valid_json_string(potential_json):\n",
    "                return potential_json\n",
    "        \n",
    "        logger.warning(f\"JSON ì¶”ì¶œ ì‹¤íŒ¨, ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜: {text[:200]}...\")\n",
    "        return text.strip()\n",
    "        \n",
    "    async def execute(self, team_id: int, period_id: int, team_evaluation_id: int) -> Module11AgentState:\n",
    "        \"\"\"ëª¨ë“ˆ 11 ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "        logger.info(f\"Module11 ì‹œì‘: team_id={team_id}, period_id={period_id}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. State ì´ˆê¸°í™”\n",
    "            state = Module11AgentState(\n",
    "                team_id=team_id,\n",
    "                period_id=period_id,\n",
    "                team_evaluation_id=team_evaluation_id,\n",
    "                is_final=self._check_is_final(period_id)\n",
    "            )\n",
    "            \n",
    "            # 2. ë°ì´í„° ìˆ˜ì§‘\n",
    "            data = self._collect_all_data_sequential(state)\n",
    "            \n",
    "            # 3. ë¦¬ìŠ¤í¬ ë¶„ì„\n",
    "            state.ai_risk_result = await self._analyze_parallel(state, data)\n",
    "            \n",
    "            # 4. ê²°ê³¼ ìƒì„± \n",
    "            state = await self._generate_outputs_parallel(state, data)\n",
    "            \n",
    "            # 5. ì €ì¥\n",
    "            self._save_results(state)\n",
    "            \n",
    "            logger.info(f\"Module11 ì™„ë£Œ: team_id={team_id}\")\n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Module11 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "            raise Module11Error(f\"ëª¨ë“ˆ 11 ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}\")\n",
    "        \n",
    "    def _extract_nested_json_objects(self, text: str) -> List[str]:\n",
    "        \"\"\"ì¤‘ì²©ëœ JSON ê°ì²´ë“¤ì„ ì¶”ì¶œ\"\"\"\n",
    "        json_objects = []\n",
    "        brace_count = 0\n",
    "        start_pos = -1\n",
    "        \n",
    "        for i, char in enumerate(text):\n",
    "            if char == '{':\n",
    "                if brace_count == 0:\n",
    "                    start_pos = i\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0 and start_pos != -1:\n",
    "                    json_candidate = text[start_pos:i + 1]\n",
    "                    json_objects.append(json_candidate)\n",
    "                    start_pos = -1\n",
    "        \n",
    "        # ê¸¸ì´ìˆœìœ¼ë¡œ ì •ë ¬ (ë” ì™„ì „í•œ JSONì´ ë’¤ì— ì˜¤ë„ë¡)\n",
    "        return sorted(json_objects, key=len, reverse=True)\n",
    "    \n",
    "    def _is_valid_json_string(self, text: str) -> bool:\n",
    "        \"\"\"JSON ë¬¸ìì—´ ìœ íš¨ì„± ê²€ì‚¬\"\"\"\n",
    "        try:\n",
    "            json.loads(text)\n",
    "            return True\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            return False\n",
    "    \n",
    "    def _check_is_final(self, period_id: int) -> bool:\n",
    "        \"\"\"ê¸°ê°„ì´ ì—°ë§ì¸ì§€ í™•ì¸\"\"\"\n",
    "        try:\n",
    "            query = \"SELECT is_final FROM periods WHERE period_id = :period_id\"\n",
    "            result = self.db.fetch_one(query, {'period_id': period_id})\n",
    "            return bool(result['is_final']) if result else False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì—°ë§ ì—¬ë¶€ í™•ì¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "            raise DatabaseError(f\"ê¸°ê°„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}\")\n",
    "    \n",
    "    def _collect_all_data_sequential(self, state: Module11AgentState) -> Dict[str, Any]:\n",
    "        \"\"\"ìˆœì°¨ì  ë°ì´í„° ìˆ˜ì§‘ (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶¤)\"\"\"\n",
    "        logger.info(f\"ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: team_evaluation_id={state.team_evaluation_id}\")\n",
    "        \n",
    "        data = {}\n",
    "        \n",
    "        try:\n",
    "            # 1. ê¸°ë³¸ ì •ë³´\n",
    "            data['period_info'] = self._get_period_info(state.period_id)\n",
    "            data['team_info'] = self._get_team_info(state.team_id)\n",
    "            data['team_members'] = self._get_team_members(state.team_id)\n",
    "            \n",
    "            # 2. ì„±ê³¼ ë°ì´í„°\n",
    "            year = data['period_info']['year']\n",
    "            data['team_kpis'] = self._get_team_kpis(state.team_id, year)\n",
    "            data['team_performance'] = self._get_team_performance(state.team_id, state.period_id)\n",
    "            \n",
    "            # 3. í˜‘ì—… ë¶„ì„ (JSON íŒŒì‹±)\n",
    "            collaboration_data = self._get_collaboration_data(state.team_evaluation_id)\n",
    "            data['collaboration_matrix'] = self._parse_json_field(collaboration_data.get('ai_collaboration_matrix'))\n",
    "            data['team_coaching'] = collaboration_data.get('ai_team_coaching')  # TEXT í•„ë“œ\n",
    "            \n",
    "            # ai_team_comparisonì€ ë¶„ê¸°ì—ë§Œ í•„ìš”\n",
    "            if not state.is_final:\n",
    "                data['team_comparison'] = collaboration_data.get('ai_team_comparison')  # TEXT í•„ë“œ\n",
    "            \n",
    "            # 4. ê°œì¸ ë¦¬ìŠ¤í¬\n",
    "            data['individual_risks'] = self._get_individual_risks(state.team_evaluation_id, state.is_final)\n",
    "            \n",
    "            # 5. ë¶„ê¸°ë³„/ì—°ë§ë³„ ì¶”ê°€ ë°ì´í„°\n",
    "            if not state.is_final:\n",
    "                # ë¶„ê¸°: ì „ë¶„ê¸° ë°ì´í„°\n",
    "                data['previous_quarter'] = self._get_previous_quarter_data(state.team_id, data['period_info'])\n",
    "            else:\n",
    "                # ì—°ë§: temp_evaluations ë°ì´í„°\n",
    "                data['temp_evaluations'] = self._get_temp_evaluations(state.team_id)\n",
    "            \n",
    "            logger.info(f\"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(data)} ê°œ ë°ì´í„°ì…‹\")\n",
    "            return data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}\")\n",
    "            raise DatabaseError(f\"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "    \n",
    "    # ====================================\n",
    "    # ë°ì´í„° ìˆ˜ì§‘ ë©”ì„œë“œë“¤ (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶¤)\n",
    "    # ====================================\n",
    "    \n",
    "    def _get_period_info(self, period_id: int) -> Dict[str, Any]:\n",
    "        \"\"\"ê¸°ê°„ ì •ë³´ ì¡°íšŒ\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT period_id, year, period_name, order_in_year, is_final,\n",
    "               start_date, end_date\n",
    "        FROM periods \n",
    "        WHERE period_id = :period_id\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.db.fetch_one(query, {'period_id': period_id})\n",
    "        if not result:\n",
    "            raise DatabaseError(f\"ê¸°ê°„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: period_id={period_id}\")\n",
    "        \n",
    "        return dict(result)\n",
    "\n",
    "    def _get_team_info(self, team_id: int) -> Dict[str, Any]:\n",
    "        \"\"\"íŒ€ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT t.team_id, t.team_name, t.team_description,\n",
    "               h.headquarter_id, h.headquarter_name, \n",
    "               p.part_id, p.part_name\n",
    "        FROM teams t\n",
    "        JOIN headquarters h ON t.headquarter_id = h.headquarter_id\n",
    "        JOIN parts p ON h.part_id = p.part_id\n",
    "        WHERE t.team_id = :team_id\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.db.fetch_one(query, {'team_id': team_id})\n",
    "        if not result:\n",
    "            raise DatabaseError(f\"íŒ€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: team_id={team_id}\")\n",
    "        \n",
    "        return dict(result)\n",
    "\n",
    "    def _get_team_members(self, team_id: int) -> List[Dict[str, Any]]:\n",
    "        \"\"\"íŒ€ì› ëª©ë¡ ì¡°íšŒ\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT emp_no, emp_name, email, cl, position, role, salary\n",
    "        FROM employees \n",
    "        WHERE team_id = :team_id\n",
    "        ORDER BY cl DESC, emp_no\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.db.fetch_all(query, {'team_id': team_id})\n",
    "        if not results:\n",
    "            logger.warning(f\"íŒ€ì›ì´ ì—†ìŒ: team_id={team_id}\")\n",
    "        \n",
    "        return [dict(row) for row in results]\n",
    "\n",
    "    def _get_team_kpis(self, team_id: int, year: int) -> List[Dict[str, Any]]:\n",
    "        \"\"\"íŒ€ KPI ì¡°íšŒ\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT team_kpi_id, kpi_name, kpi_description, weight, \n",
    "               ai_kpi_progress_rate, ai_kpi_analysis_comment\n",
    "        FROM team_kpis \n",
    "        WHERE team_id = :team_id AND year = :year\n",
    "        ORDER BY weight DESC, team_kpi_id\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.db.fetch_all(query, {'team_id': team_id, 'year': year})\n",
    "        if not results:\n",
    "            logger.warning(f\"íŒ€ KPIê°€ ì—†ìŒ: team_id={team_id}, year={year}\")\n",
    "        \n",
    "        return [dict(row) for row in results]\n",
    "\n",
    "    def _get_team_performance(self, team_id: int, period_id: int) -> Dict[str, Any]:\n",
    "        \"\"\"íŒ€ ì„±ê³¼ ì§€í‘œ ì¡°íšŒ (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶¤)\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT average_achievement_rate, relative_performance, year_over_year_growth,\n",
    "               ai_team_overall_analysis_comment\n",
    "        FROM team_evaluations \n",
    "        WHERE team_id = :team_id AND period_id = :period_id\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.db.fetch_one(query, {'team_id': team_id, 'period_id': period_id})\n",
    "        if not result:\n",
    "            logger.warning(f\"íŒ€ ì„±ê³¼ ë°ì´í„° ì—†ìŒ: team_id={team_id}, period_id={period_id}\")\n",
    "            return {}\n",
    "        \n",
    "        return dict(result)\n",
    "\n",
    "    def _get_collaboration_data(self, team_evaluation_id: int) -> Dict[str, Any]:\n",
    "        \"\"\"í˜‘ì—… ë¶„ì„ ë°ì´í„° ì¡°íšŒ\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT ai_collaboration_matrix, ai_team_comparison, ai_team_coaching\n",
    "        FROM team_evaluations \n",
    "        WHERE team_evaluation_id = :team_evaluation_id\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.db.fetch_one(query, {'team_evaluation_id': team_evaluation_id})\n",
    "        if not result:\n",
    "            logger.warning(f\"í˜‘ì—… ë¶„ì„ ë°ì´í„° ì—†ìŒ: team_evaluation_id={team_evaluation_id}\")\n",
    "            return {}\n",
    "        \n",
    "        return dict(result)\n",
    "\n",
    "    def _get_individual_risks(self, team_evaluation_id: int, is_final: bool) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ê°œì¸ë³„ ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶¤)\"\"\"\n",
    "        if is_final:\n",
    "            # ì—°ë§: final_evaluation_reports\n",
    "            query = \"\"\"\n",
    "            SELECT emp_no, ai_growth_coaching, score, contribution_rate,\n",
    "                   ai_annual_performance_summary_comment, cl_reason\n",
    "            FROM final_evaluation_reports \n",
    "            WHERE team_evaluation_id = :team_evaluation_id\n",
    "            ORDER BY score DESC\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # ë¶„ê¸°: feedback_reports\n",
    "            query = \"\"\"\n",
    "            SELECT emp_no, ai_growth_coaching, contribution_rate,\n",
    "                   ai_overall_contribution_summary_comment, attitude\n",
    "            FROM feedback_reports \n",
    "            WHERE team_evaluation_id = :team_evaluation_id\n",
    "            ORDER BY contribution_rate DESC\n",
    "            \"\"\"\n",
    "        \n",
    "        results = self.db.fetch_all(query, {'team_evaluation_id': team_evaluation_id})\n",
    "        \n",
    "        # ai_growth_coaching JSON íŒŒì‹±\n",
    "        parsed_results = []\n",
    "        for row in results:\n",
    "            row_dict = dict(row)\n",
    "            row_dict['ai_growth_coaching'] = self._parse_json_field(row.get('ai_growth_coaching'))\n",
    "            parsed_results.append(row_dict)\n",
    "        \n",
    "        if not parsed_results:\n",
    "            logger.warning(f\"ê°œì¸ í‰ê°€ ë°ì´í„° ì—†ìŒ: team_evaluation_id={team_evaluation_id}\")\n",
    "        \n",
    "        return parsed_results\n",
    "\n",
    "    def _get_previous_quarter_data(self, team_id: int, period_info: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"ì „ë¶„ê¸° ë°ì´í„° ì¡°íšŒ (ë¶„ê¸°ìš©)\"\"\"\n",
    "        current_year = period_info['year']\n",
    "        current_order = period_info['order_in_year']\n",
    "        \n",
    "        # ì´ì „ ë¶„ê¸° ê³„ì‚°\n",
    "        if current_order > 1:\n",
    "            # ê°™ì€ í•´ ì´ì „ ë¶„ê¸°\n",
    "            prev_year = current_year\n",
    "            prev_order = current_order - 1\n",
    "        else:\n",
    "            # ì „ë…„ë„ 4ë¶„ê¸°\n",
    "            prev_year = current_year - 1\n",
    "            prev_order = 4\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT te.average_achievement_rate, te.relative_performance, \n",
    "               te.ai_risk, te.overall_comment,\n",
    "               p.period_name\n",
    "        FROM team_evaluations te\n",
    "        JOIN periods p ON te.period_id = p.period_id\n",
    "        WHERE te.team_id = :team_id AND p.year = :year AND p.order_in_year = :order_in_year\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.db.fetch_one(query, {\n",
    "            'team_id': team_id, \n",
    "            'year': prev_year, \n",
    "            'order_in_year': prev_order\n",
    "        })\n",
    "        \n",
    "        if result:\n",
    "            result_dict = dict(result)\n",
    "            result_dict['ai_risk'] = self._parse_json_field(result.get('ai_risk'))\n",
    "            # overall_commentëŠ” TEXTì´ë¯€ë¡œ JSON íŒŒì‹±í•˜ì§€ ì•ŠìŒ\n",
    "            logger.info(f\"ì „ë¶„ê¸° ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {prev_year}ë…„ {prev_order}ë¶„ê¸°\")\n",
    "            return result_dict\n",
    "        \n",
    "        logger.warning(f\"ì „ë¶„ê¸° ë°ì´í„° ì—†ìŒ: team_id={team_id}, {prev_year}ë…„ {prev_order}ë¶„ê¸°\")\n",
    "        return None\n",
    "\n",
    "    def _get_temp_evaluations(self, team_id: int) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ì¤‘ê°„í‰ê°€ ë°ì´í„° ì¡°íšŒ (ì—°ë§ìš©) - DBì—ì„œ ì§ì ‘ ì¡°íšŒ\"\"\"\n",
    "        logger.info(f\"DBì—ì„œ temp_evaluations ì¡°íšŒ: team_id={team_id}\")\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT te.temp_evaluation_id, te.ai_reason, te.score, te.raw_score,\n",
    "               te.manager_score, te.comment, te.reason, te.status, te.emp_no\n",
    "        FROM temp_evaluations te\n",
    "        WHERE te.emp_no IN (\n",
    "            SELECT emp_no FROM employees WHERE team_id = :team_id\n",
    "        )\n",
    "        ORDER BY te.score DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.db.fetch_all(query, {'team_id': team_id})\n",
    "        \n",
    "        if not results:\n",
    "            logger.warning(f\"ì¤‘ê°„í‰ê°€ ë°ì´í„° ì—†ìŒ: team_id={team_id}\")\n",
    "            return []\n",
    "        \n",
    "        logger.info(f\"ì¤‘ê°„í‰ê°€ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(results)}ê±´\")\n",
    "        return [dict(row) for row in results]\n",
    "\n",
    "    # ====================================\n",
    "    # 8. ë¦¬ìŠ¤í¬ ë¶„ì„ ë©”ì„œë“œë“¤ (ìˆ˜ì •ëœ êµ¬ì¡°)\n",
    "    # ====================================\n",
    "\n",
    "    async def _analyze_parallel(self, state: Module11AgentState, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"LLM ê¸°ë°˜ ë³‘ë ¬ ë¦¬ìŠ¤í¬ ë¶„ì„ (ìˆ˜ì •ëœ êµ¬ì¡°)\"\"\"\n",
    "        logger.info(\"LLM ê¸°ë°˜ ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹œì‘ (ë³‘ë ¬)\")\n",
    "        \n",
    "        try:\n",
    "            # ë…ë¦½ì ì¸ LLM ë¶„ì„ë“¤ì„ ë³‘ë ¬ ì²˜ë¦¬\n",
    "            tasks = [\n",
    "                self._analyze_collaboration_risks_with_llm_async(data.get('collaboration_matrix'), data.get('team_members', [])),\n",
    "                self._analyze_individual_risk_patterns_with_llm_async(data.get('individual_risks', []), data.get('team_members', [])),\n",
    "                self._analyze_performance_trends_with_llm_async(data.get('team_performance', {}), data.get('team_kpis', []))\n",
    "            ]\n",
    "            \n",
    "            risk_analyses = await asyncio.gather(*tasks)\n",
    "            \n",
    "            # LLMìœ¼ë¡œ ìµœì¢… í†µí•© ë¶„ì„ (ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ)\n",
    "            integrated_analysis = await self._integrate_risk_analysis_with_llm_async(\n",
    "                collaboration_risks=risk_analyses[0],\n",
    "                individual_patterns=risk_analyses[1], \n",
    "                performance_trends=risk_analyses[2],\n",
    "                state=state,\n",
    "                data=data\n",
    "            )\n",
    "            \n",
    "            logger.info(\"LLM ê¸°ë°˜ ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ\")\n",
    "            return integrated_analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            raise Module11Error(f\"LLM ë¦¬ìŠ¤í¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "    async def _integrate_risk_analysis_with_llm_async(self, collaboration_risks: Dict, individual_patterns: Dict, \n",
    "                                                    performance_trends: Dict, state: 'Module11AgentState', data: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"ê°œì„ ëœ LLM ê¸°ë°˜ ë¦¬ìŠ¤í¬ ë¶„ì„ í†µí•© ë° ìµœì¢… JSON ìƒì„±\"\"\"\n",
    "        \n",
    "        # íŒ€ ê¸°ë³¸ ì •ë³´\n",
    "        team_info = data.get('team_info', {})\n",
    "        period_info = data.get('period_info', {})\n",
    "        team_members = data.get('team_members', [])\n",
    "        team_performance = data.get('team_performance', {})\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ íŒ€ ìš´ì˜ ë° ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì„¸ë¶€ ë¶„ì„ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ team_evaluations.ai_riskì— ì €ì¥ë  êµ¬ì¡°í™”ëœ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## íŒ€ ê¸°ë³¸ ì •ë³´:\n",
    "- íŒ€ëª…: {team_info.get('team_name', '')}\n",
    "- í‰ê°€ê¸°ê°„: {period_info.get('period_name', '')} ({'ì—°ë§' if state.is_final else 'ë¶„ê¸°'} í‰ê°€)\n",
    "- íŒ€ì› ìˆ˜: {len(team_members)}ëª…\n",
    "- íŒ€ ì„±ê³¼: ë‹¬ì„±ë¥  {team_performance.get('average_achievement_rate', 0)}%, ìƒëŒ€ì„±ê³¼ {team_performance.get('relative_performance', 0)}%\n",
    "\n",
    "## í˜‘ì—… ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼:\n",
    "{json.dumps(collaboration_risks, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## ê°œì¸ë³„ ë¦¬ìŠ¤í¬ íŒ¨í„´ ë¶„ì„ ê²°ê³¼:\n",
    "{json.dumps(individual_patterns, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## ì„±ê³¼ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼:\n",
    "{json.dumps(performance_trends, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ìœ„ ë¶„ì„ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì •í™•í•œ êµ¬ì¡°ì˜ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"risk_analysis\": {{\n",
    "    \"major_risks\": [\n",
    "      {{\n",
    "        \"risk_name\": \"ì‹¤ì œ ë°ì´í„°ì— ê¸°ë°˜í•œ êµ¬ì²´ì  ë¦¬ìŠ¤í¬ëª…\",\n",
    "        \"severity\": \"high/medium/low\",\n",
    "        \"description\": \"ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë¦¬ìŠ¤í¬ ì„¤ëª…\",\n",
    "        \"causes\": [\n",
    "          \"ë°ì´í„°ì—ì„œ í™•ì¸ëœ êµ¬ì²´ì  ë°œìƒ ì›ì¸ 1\",\n",
    "          \"ë°ì´í„°ì—ì„œ í™•ì¸ëœ êµ¬ì²´ì  ë°œìƒ ì›ì¸ 2\"\n",
    "        ],\n",
    "        \"impacts\": [\n",
    "          {{\n",
    "            \"impact_scope\": \"individual/team/organization\",\n",
    "            \"timeline\": \"immediate/short_term/long_term\",\n",
    "            \"description\": \"ì‹¤ì œ ì˜ˆìƒë˜ëŠ” êµ¬ì²´ì  ì˜í–¥ ì„¤ëª…\"\n",
    "          }}\n",
    "        ],\n",
    "        \"strategies\": [\n",
    "          {{\n",
    "            \"description\": \"ë°ì´í„° ë¶„ì„ ê²°ê³¼ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìš´ì˜ ê°œì„  ì „ëµ\"\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "## ì¤‘ìš” ìš”êµ¬ì‚¬í•­:\n",
    "1. ì‹¤ì œ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‚´ìš© ì‘ì„±\n",
    "2. major_risksëŠ” ì‹¬ê°ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœëŒ€ 5ê°œê¹Œì§€\n",
    "3. ê° ë¦¬ìŠ¤í¬ëŠ” ì‹¤ì œ ë°ì´í„° ê·¼ê±°ì™€ í•¨ê»˜ ì„¤ëª…\n",
    "4. causes, impacts, strategiesëŠ” ì¶”ìƒì ì´ì§€ ì•Šê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±\n",
    "5. íŒ€ ì‹¤ì •ì— ë§ëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ ì œì‹œ\n",
    "6. JSON í˜•ì‹ì„ ì •í™•íˆ ì¤€ìˆ˜\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await asyncio.to_thread(llm_client.invoke, prompt)\n",
    "            result_json = self._extract_json_from_llm_response(response.content)\n",
    "            final_result = json.loads(result_json)\n",
    "            \n",
    "            # ì¶”ê°€ ê²€ì¦ ë° í›„ì²˜ë¦¬\n",
    "            if not self._validate_risk_json_structure(final_result):\n",
    "                logger.warning(\"ë¦¬ìŠ¤í¬ JSON êµ¬ì¡° ê²€ì¦ ì‹¤íŒ¨ - í´ë°± ì‚¬ìš©\")\n",
    "                return self._create_fallback_risk_analysis(state)\n",
    "            \n",
    "            # Stateì— í•µì‹¬ ì •ë³´ ì €ì¥\n",
    "            major_risks = final_result.get('risk_analysis', {}).get('major_risks', [])\n",
    "            state.key_risks = [risk['risk_name'] for risk in major_risks]\n",
    "            state.collaboration_bias_level = collaboration_risks.get('bias_level', 'medium')\n",
    "            \n",
    "            logger.info(f\"âœ… ê³ í’ˆì§ˆ ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ: {len(major_risks)}ê°œ ë¦¬ìŠ¤í¬ ì‹ë³„\")\n",
    "            return final_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ìµœì¢… ë¦¬ìŠ¤í¬ ë¶„ì„ í†µí•© ì‹¤íŒ¨: {str(e)}\")\n",
    "            return self._create_fallback_risk_analysis(state)\n",
    "        \n",
    "    def _validate_risk_json_structure(self, result: Dict) -> bool:\n",
    "        \"\"\"ë¦¬ìŠ¤í¬ JSON êµ¬ì¡° ê²€ì¦\"\"\"\n",
    "        try:\n",
    "            risk_analysis = result.get('risk_analysis', {})\n",
    "            major_risks = risk_analysis.get('major_risks', [])\n",
    "            \n",
    "            if not isinstance(major_risks, list) or len(major_risks) == 0:\n",
    "                return False\n",
    "            \n",
    "            # ì²« ë²ˆì§¸ ë¦¬ìŠ¤í¬ì˜ í•„ìˆ˜ í•„ë“œ ê²€ì¦\n",
    "            first_risk = major_risks[0]\n",
    "            required_fields = ['risk_name', 'severity', 'description', 'causes', 'impacts', 'strategies']\n",
    "            \n",
    "            for field in required_fields:\n",
    "                if field not in first_risk:\n",
    "                    return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def _create_fallback_risk_analysis(self, state: 'Module11AgentState') -> Dict[str, Any]:\n",
    "        \"\"\"ê°œì„ ëœ í´ë°± ë¦¬ìŠ¤í¬ ë¶„ì„\"\"\"\n",
    "        \n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        \n",
    "        return {\n",
    "            \"risk_analysis\": {\n",
    "                \"major_risks\": [\n",
    "                    {\n",
    "                        \"risk_name\": \"ì‹œìŠ¤í…œ ë¶„ì„ í•œê³„ë¡œ ì¸í•œ ë¦¬ìŠ¤í¬ ì‹ë³„ ì œì•½\",\n",
    "                        \"severity\": \"medium\",\n",
    "                        \"description\": f\"LLM ë¶„ì„ í”„ë¡œì„¸ìŠ¤ì—ì„œ ê¸°ìˆ ì  í•œê³„ê°€ ë°œìƒí•˜ì—¬ ì •í™•í•œ ë¦¬ìŠ¤í¬ ì‹ë³„ì´ ì œí•œë¨ (ë°œìƒì‹œê°„: {current_time})\",\n",
    "                        \"causes\": [\n",
    "                            \"ìë™í™”ëœ ë¶„ì„ ì‹œìŠ¤í…œì˜ ê¸°ìˆ ì  í•œê³„\",\n",
    "                            \"ë³µì¡í•œ ì¡°ì§ ë°ì´í„° ì²˜ë¦¬ ê³¼ì •ì˜ ì˜ˆì™¸ ìƒí™©\"\n",
    "                        ],\n",
    "                        \"impacts\": [\n",
    "                            {\n",
    "                                \"impact_scope\": \"team\",\n",
    "                                \"timeline\": \"immediate\",\n",
    "                                \"description\": \"ì •í™•í•œ ë¦¬ìŠ¤í¬ ëŒ€ì‘ ê³„íš ìˆ˜ë¦½ì˜ ì–´ë ¤ì›€ ë° ì˜ì‚¬ê²°ì • ì§€ì—° ê°€ëŠ¥ì„±\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"strategies\": [\n",
    "                            {\n",
    "                                \"description\": \"íŒ€ì¥ ì£¼ë„ì˜ ìˆ˜ë™ ë¦¬ìŠ¤í¬ ê²€í†  í”„ë¡œì„¸ìŠ¤ ì¦‰ì‹œ ì‹œí–‰ ë° ì£¼ìš” ë¦¬ìŠ¤í¬ ìš”ì†Œ ì§ì ‘ ì‹ë³„\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # ê¸°ì¡´ ê°œë³„ ë¶„ì„ ë©”ì„œë“œë“¤\n",
    "    async def _analyze_collaboration_risks_with_llm_async(self, collaboration_matrix: Optional[Dict], team_members: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"ê°œì„ ëœ LLM ê¸°ë°˜ í˜‘ì—… ë¦¬ìŠ¤í¬ ë¶„ì„\"\"\"\n",
    "        \n",
    "        if not collaboration_matrix:\n",
    "            return {\n",
    "                'risks': [],\n",
    "                'collaboration_insights': ['í˜‘ì—… ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€'],\n",
    "                'bias_level': 'unknown'\n",
    "            }\n",
    "        \n",
    "        # íŒ€ì› ì •ë³´ êµ¬ì¡°í™”\n",
    "        member_info = []\n",
    "        for member in team_members:\n",
    "            member_info.append({\n",
    "                'emp_no': member.get('emp_no'),\n",
    "                'name': member.get('emp_name'),\n",
    "                'position': member.get('position'),\n",
    "                'cl': member.get('cl')\n",
    "            })\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì¡°ì§ í˜‘ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í˜‘ì—… ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì²´ì ì¸ ë¦¬ìŠ¤í¬ë¥¼ ì‹ë³„í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## íŒ€ì› ì •ë³´:\n",
    "{json.dumps(member_info, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## í˜‘ì—… ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„°:\n",
    "{json.dumps(collaboration_matrix, ensure_ascii=False, indent=2)}\n",
    "\n",
    "í˜‘ì—… ë¦¬ìŠ¤í¬ë¥¼ ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"risks\": [\n",
    "    {{\n",
    "      \"risk_name\": \"êµ¬ì²´ì  í˜‘ì—… ë¦¬ìŠ¤í¬ëª…\",\n",
    "      \"severity\": \"high/medium/low\",\n",
    "      \"description\": \"ë¦¬ìŠ¤í¬ì— ëŒ€í•œ êµ¬ì²´ì  ì„¤ëª… (ë°ì´í„° ê·¼ê±° í¬í•¨)\",\n",
    "      \"evidence\": [\n",
    "        \"í˜‘ì—… ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì  ì¦ê±° 1\",\n",
    "        \"í˜‘ì—… ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì  ì¦ê±° 2\"\n",
    "      ],\n",
    "      \"affected_members\": [\"emp_no1\", \"emp_no2\"]\n",
    "    }}\n",
    "  ],\n",
    "  \"collaboration_insights\": [\n",
    "    \"í˜‘ì—… íŒ¨í„´ì—ì„œ ë°œê²¬ëœ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 1\",\n",
    "    \"í˜‘ì—… íŒ¨í„´ì—ì„œ ë°œê²¬ëœ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 2\"\n",
    "  ],\n",
    "  \"bias_level\": \"high/medium/low\"\n",
    "}}\n",
    "```\n",
    "\n",
    "## ë¶„ì„ ê¸°ì¤€:\n",
    "1. í˜‘ì—… ë§¤íŠ¸ë¦­ìŠ¤ì˜ ì‹¤ì œ ìˆ˜ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„\n",
    "2. íŒ€ì›ê°„ í˜‘ì—… ë¶ˆê· í˜•, ì†Œì™¸ëœ êµ¬ì„±ì›, ê³¼ë„í•œ ì˜ì¡´ì„± ë“±ì„ ì‹ë³„\n",
    "3. êµ¬ì²´ì ì¸ ë°ì´í„° ê·¼ê±°ì™€ í•¨ê»˜ ë¦¬ìŠ¤í¬ ì„¤ëª…\n",
    "4. ì‹¤ì œ ì˜í–¥ë°›ì„ íŒ€ì›ë“¤ì„ ëª…ì‹œ\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await asyncio.to_thread(llm_client.invoke, prompt)\n",
    "            result_json = self._extract_json_from_llm_response(response.content)\n",
    "            return json.loads(result_json)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"í˜‘ì—… ë¦¬ìŠ¤í¬ LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return {\n",
    "                'risks': [{\n",
    "                    'risk_name': 'í˜‘ì—… ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜',\n",
    "                    'severity': 'medium',\n",
    "                    'description': f'LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:100]}',\n",
    "                    'evidence': ['ì‹œìŠ¤í…œ ë¶„ì„ í•œê³„'],\n",
    "                    'affected_members': []\n",
    "                }],\n",
    "                'collaboration_insights': ['ì‹œìŠ¤í…œ ë¶„ì„ í•œê³„ë¡œ ì¸í•œ ì œí•œì  ë¶„ì„'],\n",
    "                'bias_level': 'unknown'\n",
    "            }\n",
    "\n",
    "    async def _analyze_individual_risk_patterns_with_llm_async(self, individual_risks: List[Dict], team_members: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"ê°œì„ ëœ LLM ê¸°ë°˜ ê°œì¸ë³„ ë¦¬ìŠ¤í¬ íŒ¨í„´ ë¶„ì„\"\"\"\n",
    "        \n",
    "        if not individual_risks:\n",
    "            return {\n",
    "                'risks': [],\n",
    "                'performance_patterns': ['ê°œì¸ í‰ê°€ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€']\n",
    "            }\n",
    "        \n",
    "        # ê°œì¸ë³„ ì„±ê³¼ ë°ì´í„° êµ¬ì¡°í™”\n",
    "        performance_data = []\n",
    "        for risk in individual_risks:\n",
    "            performance_data.append({\n",
    "                'emp_no': risk.get('emp_no'),\n",
    "                'score': risk.get('score'),\n",
    "                'contribution_rate': risk.get('contribution_rate'),\n",
    "                'attitude': risk.get('attitude'),\n",
    "                'growth_coaching': risk.get('ai_growth_coaching'),\n",
    "                'summary_comment': risk.get('ai_overall_contribution_summary_comment') or risk.get('ai_annual_performance_summary_comment')\n",
    "            })\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì¸ì‚¬ ì„±ê³¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê°œì¸ë³„ ì„±ê³¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íŒ€ ì°¨ì›ì˜ ë¦¬ìŠ¤í¬ë¥¼ ì‹ë³„í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## íŒ€ì› ê¸°ë³¸ ì •ë³´:\n",
    "{json.dumps([{'emp_no': m.get('emp_no'), 'name': m.get('emp_name'), 'position': m.get('position'), 'cl': m.get('cl')} for m in team_members], ensure_ascii=False, indent=2)}\n",
    "\n",
    "## ê°œì¸ë³„ ì„±ê³¼ ë°ì´í„°:\n",
    "{json.dumps(performance_data, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ê°œì¸ ì„±ê³¼ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ íŒ€ ë¦¬ìŠ¤í¬ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"risks\": [\n",
    "    {{\n",
    "      \"risk_name\": \"ê°œì¸ ì„±ê³¼ ê¸°ë°˜ íŒ€ ë¦¬ìŠ¤í¬ëª…\",\n",
    "      \"severity\": \"high/medium/low\", \n",
    "      \"description\": \"ì„±ê³¼ ë°ì´í„°ë¥¼ ê·¼ê±°ë¡œ í•œ êµ¬ì²´ì  ë¦¬ìŠ¤í¬ ì„¤ëª…\",\n",
    "      \"affected_members\": [\"emp_no1\", \"emp_no2\"],\n",
    "      \"evidence\": [\n",
    "        \"ì„±ê³¼ ë°ì´í„°ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì  ì¦ê±° 1\",\n",
    "        \"ì„±ê³¼ ë°ì´í„°ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì  ì¦ê±° 2\"\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"performance_patterns\": [\n",
    "    \"íŒ€ ì„±ê³¼ íŒ¨í„´ì—ì„œ ë°œê²¬ëœ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 1\",\n",
    "    \"íŒ€ ì„±ê³¼ íŒ¨í„´ì—ì„œ ë°œê²¬ëœ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ 2\"\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "## ë¶„ì„ í¬ì¸íŠ¸:\n",
    "1. ì„±ê³¼ í¸ì°¨ê°€ í° êµ¬ì„±ì›ë“¤ì˜ íŒ€ ì˜í–¥ë„\n",
    "2. ì €ì„±ê³¼ìì˜ íŒ€ ì‚¬ê¸° ë° ë¶„ìœ„ê¸° ì˜í–¥\n",
    "3. ê³ ì„±ê³¼ìì˜ ë²ˆì•„ì›ƒ ë˜ëŠ” ì´ì§ ìœ„í—˜ì„±\n",
    "4. ì„±ì¥ ì½”ì¹­ í•„ìš”ì„±ì´ ë†’ì€ êµ¬ì„±ì›ë“¤ì˜ íŒ¨í„´\n",
    "5. ì‹¤ì œ ìˆ˜ì¹˜ë¥¼ ê·¼ê±°ë¡œ êµ¬ì²´ì  ë¶„ì„\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await asyncio.to_thread(llm_client.invoke, prompt)\n",
    "            result_json = self._extract_json_from_llm_response(response.content)\n",
    "            return json.loads(result_json)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ê°œì¸ ë¦¬ìŠ¤í¬ LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return {\n",
    "                'risks': [{\n",
    "                    'risk_name': 'ê°œì¸ ì„±ê³¼ ë¶„ì„ í•œê³„',\n",
    "                    'severity': 'medium',\n",
    "                    'description': f'ê°œì¸ ì„±ê³¼ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)[:100]}',\n",
    "                    'affected_members': [],\n",
    "                    'evidence': ['ì‹œìŠ¤í…œ ë¶„ì„ í•œê³„']\n",
    "                }],\n",
    "                'performance_patterns': ['ì‹œìŠ¤í…œ í•œê³„ë¡œ ì¸í•œ ì œí•œì  ë¶„ì„']\n",
    "            }\n",
    "\n",
    "    async def _analyze_performance_trends_with_llm_async(self, team_performance: Dict, team_kpis: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"ê°œì„ ëœ LLM ê¸°ë°˜ ì„±ê³¼ íŠ¸ë Œë“œ ë¶„ì„\"\"\"\n",
    "        \n",
    "        if not team_performance:\n",
    "            return {\n",
    "                'risks': [],\n",
    "                'trends': ['ì„±ê³¼ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¶„ì„ ë¶ˆê°€']\n",
    "            }\n",
    "        \n",
    "        # KPI ë°ì´í„° êµ¬ì¡°í™”\n",
    "        kpi_summary = []\n",
    "        for kpi in team_kpis:\n",
    "            kpi_summary.append({\n",
    "                'kpi_name': kpi.get('kpi_name'),\n",
    "                'weight': kpi.get('weight'),\n",
    "                'progress_rate': kpi.get('ai_kpi_progress_rate'),\n",
    "                'analysis_comment': kpi.get('ai_kpi_analysis_comment')\n",
    "            })\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ íŒ€ ì„±ê³¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì„±ê³¼ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„í•˜ì—¬ íŒ€ì˜ ì„±ê³¼ ê´€ë ¨ ë¦¬ìŠ¤í¬ë¥¼ ì‹ë³„í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## íŒ€ ì „ì²´ ì„±ê³¼:\n",
    "{json.dumps(team_performance, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## íŒ€ KPI í˜„í™©:\n",
    "{json.dumps(kpi_summary, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ì„±ê³¼ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON êµ¬ì¡°ë¡œ ë¦¬ìŠ¤í¬ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"risks\": [\n",
    "    {{\n",
    "      \"risk_name\": \"ì„±ê³¼ ê´€ë ¨ êµ¬ì²´ì  ë¦¬ìŠ¤í¬ëª…\",\n",
    "      \"severity\": \"high/medium/low\",\n",
    "      \"description\": \"ì„±ê³¼ ë°ì´í„°ë¥¼ ê·¼ê±°ë¡œ í•œ êµ¬ì²´ì  ë¦¬ìŠ¤í¬ ì„¤ëª…\",\n",
    "      \"affected_kpis\": [\"kpi_name1\", \"kpi_name2\"],\n",
    "      \"evidence\": [\n",
    "        \"ì„±ê³¼ ë°ì´í„°ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì  ìˆ˜ì¹˜ì  ê·¼ê±° 1\",\n",
    "        \"ì„±ê³¼ ë°ì´í„°ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì  ìˆ˜ì¹˜ì  ê·¼ê±° 2\"\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"performance_trends\": [\n",
    "    \"ì„±ê³¼ íŠ¸ë Œë“œì—ì„œ ë°œê²¬ëœ ì£¼ìš” íŒ¨í„´ 1\",\n",
    "    \"ì„±ê³¼ íŠ¸ë Œë“œì—ì„œ ë°œê²¬ëœ ì£¼ìš” íŒ¨í„´ 2\"\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "## ë¶„ì„ ê¸°ì¤€:\n",
    "1. í‰ê·  ë‹¬ì„±ë¥ , ìƒëŒ€ ì„±ê³¼, ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ ì˜ ì‹¤ì œ ìˆ˜ì¹˜ ë¶„ì„\n",
    "2. KPIë³„ ì§„í–‰ë¥ ê³¼ ê°€ì¤‘ì¹˜ë¥¼ ê³ ë ¤í•œ ìœ„í—˜ë„ í‰ê°€\n",
    "3. ì„±ê³¼ íŠ¸ë Œë“œì˜ ì§€ì†ê°€ëŠ¥ì„± ë° ê°œì„  ê°€ëŠ¥ì„± íŒë‹¨\n",
    "4. êµ¬ì²´ì  ìˆ˜ì¹˜ë¥¼ ê·¼ê±°ë¡œ í•œ ëª…í™•í•œ ë¦¬ìŠ¤í¬ ì‹ë³„\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await asyncio.to_thread(llm_client.invoke, prompt)\n",
    "            result_json = self._extract_json_from_llm_response(response.content)\n",
    "            return json.loads(result_json)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì„±ê³¼ íŠ¸ë Œë“œ LLM ë¶„ì„ ì‹¤íŒ¨: {str(e)}\")\n",
    "            return {\n",
    "                'risks': [{\n",
    "                    'risk_name': 'ì„±ê³¼ ë°ì´í„° ë¶„ì„ í•œê³„',\n",
    "                    'severity': 'medium',\n",
    "                    'description': f'ì„±ê³¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:100]}',\n",
    "                    'affected_kpis': [],\n",
    "                    'evidence': ['ì‹œìŠ¤í…œ ë¶„ì„ í•œê³„']\n",
    "                }],\n",
    "                'performance_trends': ['ì‹œìŠ¤í…œ í•œê³„ë¡œ ì¸í•œ ì œí•œì  ë¶„ì„']\n",
    "            }\n",
    "\n",
    "\n",
    "    # ====================================\n",
    "    # 9. ê²°ê³¼ ìƒì„± ë©”ì„œë“œë“¤ (ìˆ˜ì •ëœ êµ¬ì¡°)\n",
    "    # ====================================\n",
    "\n",
    "    async def _generate_outputs_parallel(self, state: Module11AgentState, data: Dict[str, Any]) -> Module11AgentState:\n",
    "        \"\"\"LLM ê¸°ë°˜ ë³‘ë ¬ ê²°ê³¼ ìƒì„±\"\"\"\n",
    "        logger.info(\"ìµœì¢… ê²°ê³¼ ìƒì„± ì‹œì‘ (ë³‘ë ¬)\")\n",
    "        \n",
    "        try:\n",
    "            if state.is_final:\n",
    "                # ì—°ë§: ai_planê³¼ overall_comment ë³‘ë ¬ ìƒì„±\n",
    "                tasks = [\n",
    "                    self._generate_annual_plan_with_llm_async(state, data),\n",
    "                    self._generate_overall_comment_with_llm_async(state, data)\n",
    "                ]\n",
    "                \n",
    "                ai_plan, overall_comment = await asyncio.gather(*tasks)\n",
    "                state.ai_plan_result = ai_plan\n",
    "                state.overall_comment_result = overall_comment\n",
    "                \n",
    "            else:\n",
    "                # ë¶„ê¸°: overall_commentë§Œ\n",
    "                state.overall_comment_result = await self._generate_overall_comment_with_llm_async(state, data)\n",
    "            \n",
    "            logger.info(\"ìµœì¢… ê²°ê³¼ ìƒì„± ì™„ë£Œ\")\n",
    "            return state\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ìµœì¢… ê²°ê³¼ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            raise Module11Error(f\"ìµœì¢… ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "    async def _generate_annual_plan_with_llm_async(self, state: 'Module11AgentState', data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"ê°œì„ ëœ LLM ê¸°ë°˜ ì—°ë§ ê³„íš ìƒì„±\"\"\"\n",
    "        \n",
    "        team_info = data.get('team_info', {})\n",
    "        period_info = data.get('period_info', {})\n",
    "        team_members = data.get('team_members', [])\n",
    "        temp_evaluations = data.get('temp_evaluations', [])\n",
    "        individual_risks = data.get('individual_risks', [])\n",
    "        \n",
    "        # íŒ€ì›ë³„ ì¤‘ê°„í‰ê°€ ê²°ê³¼ êµ¬ì¡°í™”\n",
    "        member_evaluations = {}\n",
    "        for temp_eval in temp_evaluations:\n",
    "            emp_no = temp_eval.get('emp_no')\n",
    "            if emp_no:\n",
    "                member_evaluations[emp_no] = {\n",
    "                    'score': temp_eval.get('score'),\n",
    "                    'manager_score': temp_eval.get('manager_score'),\n",
    "                    'reason': temp_eval.get('reason'),\n",
    "                    'status': temp_eval.get('status')\n",
    "                }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ íŒ€ ìš´ì˜ ì „ëµ ìˆ˜ë¦½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¢…í•© ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì°¨ë…„ë„({period_info.get('year', 2024) + 1}ë…„) íŒ€ ìš´ì˜ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## íŒ€ ê¸°ë³¸ ì •ë³´:\n",
    "{json.dumps(team_info, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## íŒ€ì› í˜„í™©:\n",
    "{json.dumps([{'emp_no': m.get('emp_no'), 'name': m.get('emp_name'), 'position': m.get('position'), 'cl': m.get('cl'), 'salary': m.get('salary')} for m in team_members], ensure_ascii=False, indent=2)}\n",
    "\n",
    "## ì¤‘ê°„í‰ê°€ ê²°ê³¼:\n",
    "{json.dumps(member_evaluations, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## ìµœì¢… í‰ê°€ ê²°ê³¼:\n",
    "{json.dumps(individual_risks, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## ì‹ë³„ëœ ë¦¬ìŠ¤í¬:\n",
    "{json.dumps(state.ai_risk_result, ensure_ascii=False, indent=2)}\n",
    "\n",
    "## í˜‘ì—… ë¶„ì„ ê²°ê³¼:\n",
    "{json.dumps(data.get('collaboration_matrix'), ensure_ascii=False, indent=2)}\n",
    "\n",
    "ì°¨ë…„ë„ ìš´ì˜ ê³„íšì„ ë‹¤ìŒê³¼ ê°™ì€ ì •í™•í•œ JSON êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"annual_plans\": [\n",
    "    {{\n",
    "      \"personnel_strategies\": [\n",
    "        {{\n",
    "          \"target\": \"êµ¬ì²´ì  ëŒ€ìƒìëª… ë˜ëŠ” í¬ì§€ì…˜\",\n",
    "          \"action\": \"ì‹¤ì œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ë°©ì•ˆ (êµìœ¡, ìŠ¹ì§„, ì±„ìš©, ì—­í•  ë³€ê²½ ë“±)\"\n",
    "        }}\n",
    "      ],\n",
    "      \"collaboration_improvements\": [\n",
    "        {{\n",
    "          \"current_issue\": \"í˜„ì¬ í™•ì¸ëœ êµ¬ì²´ì  í˜‘ì—… ë¬¸ì œì \",\n",
    "          \"improvement\": \"ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ êµ¬ì²´ì  ê°œì„  ë°©ì•ˆ\",\n",
    "          \"expected_benefit\": \"ê°œì„ ìœ¼ë¡œ ì¸í•œ êµ¬ì²´ì  ê¸°ëŒ€íš¨ê³¼\",\n",
    "          \"target\": \"ì¸¡ì • ê°€ëŠ¥í•œ êµ¬ì²´ì  ëª©í‘œ ì§€í‘œ\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "## ì‘ì„± ê°€ì´ë“œë¼ì¸:\n",
    "1. **personnel_strategies**: \n",
    "   - ì‹¤ì œ íŒ€ì›ë“¤ì˜ ì„±ê³¼ì™€ í‰ê°€ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì  ì „ëµ ìˆ˜ë¦½\n",
    "   - ê³ ì„±ê³¼ì ìœ ì§€, ì €ì„±ê³¼ì ê°œì„ , ì‹ ê·œ ì±„ìš© í•„ìš”ì„± ë“±ì„ ì‹¤ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨\n",
    "   - ì‹¤ì œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œìœ¼ë¡œ ì‘ì„±\n",
    "\n",
    "2. **collaboration_improvements**: \n",
    "   - í˜‘ì—… ë§¤íŠ¸ë¦­ìŠ¤ì™€ ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ë¬¸ì œì  ì‹ë³„\n",
    "   - êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ ì œì‹œ\n",
    "   - ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ ì§€í‘œ ì„¤ì •\n",
    "\n",
    "3. **ì „ì²´ì ìœ¼ë¡œ**: \n",
    "   - ì¶”ìƒì ì´ì§€ ì•Šê³  êµ¬ì²´ì ì¸ ë‚´ìš©\n",
    "   - ì‹¤ì œ ë°ì´í„°ì™€ ë¶„ì„ ê²°ê³¼ì— ê¸°ë°˜\n",
    "   - ì°¨ë…„ë„ì— ì‹¤ì œë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê³„íš\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = await asyncio.to_thread(llm_client.invoke, prompt)\n",
    "            result_json = self._extract_json_from_llm_response(response.content)\n",
    "            final_result = json.loads(result_json)\n",
    "            \n",
    "            # êµ¬ì¡° ê²€ì¦\n",
    "            if not self._validate_plan_json_structure(final_result):\n",
    "                logger.warning(\"ì—°ë§ ê³„íš JSON êµ¬ì¡° ê²€ì¦ ì‹¤íŒ¨ - í´ë°± ì‚¬ìš©\")\n",
    "                return self._create_fallback_annual_plan(period_info)\n",
    "            \n",
    "            logger.info(\"âœ… ê³ í’ˆì§ˆ ì—°ë§ ê³„íš ìƒì„± ì™„ë£Œ\")\n",
    "            return final_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì—°ë§ ê³„íš LLM ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            return self._create_fallback_annual_plan(period_info)\n",
    "        \n",
    "    def _validate_plan_json_structure(self, result: Dict) -> bool:\n",
    "        \"\"\"ì—°ë§ ê³„íš JSON êµ¬ì¡° ê²€ì¦\"\"\"\n",
    "        try:\n",
    "            annual_plans = result.get('annual_plans', [])\n",
    "            if not isinstance(annual_plans, list) or len(annual_plans) == 0:\n",
    "                return False\n",
    "            \n",
    "            plan = annual_plans[0]\n",
    "            if 'personnel_strategies' not in plan or 'collaboration_improvements' not in plan:\n",
    "                return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def _create_fallback_annual_plan(self, period_info: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"ê°œì„ ëœ í´ë°± ì—°ë§ ê³„íš\"\"\"\n",
    "        \n",
    "        next_year = period_info.get('year', 2024) + 1\n",
    "        \n",
    "        return {\n",
    "            \"annual_plans\": [\n",
    "                {\n",
    "                    \"personnel_strategies\": [\n",
    "                        {\n",
    "                            \"target\": \"íŒ€ ì „ì²´ êµ¬ì„±ì›\",\n",
    "                            \"action\": f\"{next_year}ë…„ ìƒë°˜ê¸° ì¤‘ íŒ€ì¥ ì£¼ë„ì˜ ê°œë³„ ë©´ë‹´ì„ í†µí•œ ë§ì¶¤í˜• ì„±ì¥ ê³„íš ìˆ˜ë¦½ ë° ì‹¤í–‰\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"target\": \"ì‹œìŠ¤í…œ ë¶„ì„ í”„ë¡œì„¸ìŠ¤\",\n",
    "                            \"action\": \"ìë™í™” ë¶„ì„ ì‹œìŠ¤í…œì˜ í•œê³„ ë³´ì™„ì„ ìœ„í•œ ìˆ˜ë™ ê²€í†  ì²´ê³„ êµ¬ì¶• ë° ì •ê¸°ì  ëª¨ë‹ˆí„°ë§ ì‹¤ì‹œ\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"collaboration_improvements\": [\n",
    "                        {\n",
    "                            \"current_issue\": \"ìë™í™”ëœ í˜‘ì—… ë¶„ì„ì˜ ê¸°ìˆ ì  í•œê³„\",\n",
    "                            \"improvement\": \"íŒ€ ë‚´ ì •ê¸°ì  í˜‘ì—… íš¨ê³¼ì„± ì ê²€ ë¯¸íŒ… ë° í”¼ë“œë°± ìˆ˜ì§‘ ì²´ê³„ êµ¬ì¶•\",\n",
    "                            \"expected_benefit\": \"ì‹¤ì œ í˜‘ì—… ì´ìŠˆì˜ ì‹ ì†í•œ ë°œê²¬ ë° í•´ê²°ì„ í†µí•œ íŒ€ íš¨ìœ¨ì„± í–¥ìƒ\",\n",
    "                            \"target\": \"ì›” 1íšŒ í˜‘ì—… ì ê²€ ë¯¸íŒ… ì‹¤ì‹œ ë° ë¶„ê¸°ë³„ í˜‘ì—… ë§Œì¡±ë„ 80% ì´ìƒ ë‹¬ì„±\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    async def _generate_overall_comment_with_llm_async(self, state: 'Module11AgentState', data: Dict[str, Any]) -> str:\n",
    "        \"\"\"ê°œì„ ëœ LLM ê¸°ë°˜ ì´í‰ ìƒì„±\"\"\"\n",
    "        \n",
    "        if state.is_final:\n",
    "            return await self._generate_annual_overall_comment_text_improved(state, data)\n",
    "        else:\n",
    "            return await self._generate_quarterly_overall_comment_text_improved(state, data)\n",
    "\n",
    "    async def _generate_annual_overall_comment_text_improved(self, state: 'Module11AgentState', data: Dict[str, Any]) -> str:\n",
    "        \"\"\"ê°œì„ ëœ ì—°ë§ ì´í‰ ìƒì„±\"\"\"\n",
    "        \n",
    "        team_info = data.get('team_info', {})\n",
    "        period_info = data.get('period_info', {})\n",
    "        team_performance = data.get('team_performance', {})\n",
    "        team_kpis = data.get('team_kpis', [])\n",
    "        temp_evaluations = data.get('temp_evaluations', [])\n",
    "        \n",
    "        # ì„±ê³¼ ì§€í‘œ ìš”ì•½\n",
    "        performance_summary = {\n",
    "            'achievement_rate': team_performance.get('average_achievement_rate', 0),\n",
    "            'relative_performance': team_performance.get('relative_performance', 0),\n",
    "            'year_over_year_growth': team_performance.get('year_over_year_growth', 0),\n",
    "            'kpi_count': len(team_kpis),\n",
    "            'team_size': len(data.get('team_members', [])),\n",
    "            'temp_eval_avg': sum(eval.get('score', 0) for eval in temp_evaluations) / len(temp_evaluations) if temp_evaluations else 0\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ê²½ì˜ì§„ì—ê²Œ ë³´ê³ í•˜ëŠ” íŒ€ ìš´ì˜ ì „ëµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¢…í•© ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—°ë§ ì´í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## íŒ€ ê¸°ë³¸ ì •ë³´:\n",
    "- íŒ€ëª…: {team_info.get('team_name')} \n",
    "- ì†Œì†: {team_info.get('part_name')} > {team_info.get('headquarter_name')}\n",
    "- íŒ€ì› ìˆ˜: {performance_summary['team_size']}ëª…\n",
    "\n",
    "## ì—°ê°„ ì„±ê³¼ ìš”ì•½:\n",
    "- í‰ê·  ë‹¬ì„±ë¥ : {performance_summary['achievement_rate']}%\n",
    "- ìƒëŒ€ì  ì„±ê³¼: {performance_summary['relative_performance']}%  \n",
    "- ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ : {performance_summary['year_over_year_growth']}%\n",
    "- KPI ê°œìˆ˜: {performance_summary['kpi_count']}ê°œ\n",
    "- ì¤‘ê°„í‰ê°€ í‰ê· : {performance_summary['temp_eval_avg']:.1f}ì \n",
    "\n",
    "## ìƒì„¸ KPI í˜„í™©:\n",
    "{json.dumps([{'name': kpi.get('kpi_name'), 'weight': kpi.get('weight'), 'progress': kpi.get('ai_kpi_progress_rate')} for kpi in team_kpis], ensure_ascii=False, indent=2)}\n",
    "\n",
    "## ì‹ë³„ëœ ì£¼ìš” ë¦¬ìŠ¤í¬:\n",
    "{json.dumps(state.key_risks, ensure_ascii=False)}\n",
    "\n",
    "## ì°¨ë…„ë„ ê³„íš ìš”ì•½:\n",
    "{json.dumps(state.ai_plan_result, ensure_ascii=False, indent=2)}\n",
    "\n",
    "ë‹¤ìŒ êµ¬ì¡°ë¡œ ì—°ë§ ì´í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "**[íŒ€ ì„±ê³¼ ë°©í–¥]**\n",
    "ì—°ê°„ ì„±ê³¼ ë‹¬ì„±ë„ì™€ ì„±ì¥ ê¶¤ì ì„ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ í‰ê°€í•˜ê³ , íŒ€ì˜ ì „ëµì  ë°©í–¥ì„±ê³¼ ì„±ê³¼ ì°½ì¶œ ëŠ¥ë ¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. (3-4ë¬¸ì¥)\n",
    "\n",
    "**[êµ¬ì¡°ì  ì¸ì‹]**  \n",
    "íŒ€ì˜ ì¡°ì§ì  ê°•ì ê³¼ êµ¬ì¡°ì  ë„ì „ê³¼ì œë¥¼ ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼ì™€ ì—°ê³„í•˜ì—¬ ì„¤ëª…í•˜ê³ , ì§€ì†ê°€ëŠ¥í•œ ì„±ì¥ì„ ìœ„í•œ í•µì‹¬ ìš”ì†Œë¥¼ ì‹ë³„í•´ì£¼ì„¸ìš”. (3-4ë¬¸ì¥)\n",
    "\n",
    "**[í–¥í›„ ìš´ì˜ ì „ëµ]**\n",
    "ì°¨ë…„ë„ ê³„íšê³¼ ì—°ê³„í•˜ì—¬ ì „ëµì  ìš°ì„ ìˆœìœ„ì™€ ì„±ê³µì„ ìœ„í•œ í•µì‹¬ ì‹¤í–‰ ê³¼ì œë¥¼ ì œì‹œí•˜ê³ , êµ¬ì²´ì ì¸ ì„±ê³¼ ëª©í‘œì™€ ì‹¤í–‰ ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”. (3-4ë¬¸ì¥)\n",
    "\n",
    "## ì‘ì„± ìš”êµ¬ì‚¬í•­:\n",
    "1. ì‹¤ì œ ìˆ˜ì¹˜ì™€ ë°ì´í„°ë¥¼ ê·¼ê±°ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±\n",
    "2. ì¶”ìƒì  í‘œí˜„ë³´ë‹¤ëŠ” ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš© ì¤‘ì‹¬\n",
    "3. ê²½ì˜ì§„ì´ ì˜ì‚¬ê²°ì •ì— í™œìš©í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ì¸ì‚¬ì´íŠ¸ ì œê³µ\n",
    "4. ê° ì„¹ì…˜ì€ ë…ë¦½ì ì´ë©´ì„œë„ ì „ì²´ì ìœ¼ë¡œ ì¼ê´€ëœ ìŠ¤í† ë¦¬ êµ¬ì„±\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await asyncio.to_thread(llm_client.invoke, prompt)\n",
    "            result = response.content.strip()\n",
    "            \n",
    "            # ë‚´ìš© í’ˆì§ˆ ê²€ì¦\n",
    "            if len(result) < 300:\n",
    "                logger.warning(\"ì—°ë§ ì´í‰ì´ ë„ˆë¬´ ì§§ìŒ - í´ë°± ì‚¬ìš©\")\n",
    "                return self._create_fallback_annual_comment_text()\n",
    "            \n",
    "            logger.info(f\"âœ… ê³ í’ˆì§ˆ ì—°ë§ ì´í‰ ìƒì„± ì™„ë£Œ: {len(result)}ì\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ì—°ë§ ì´í‰ LLM ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            return self._create_fallback_annual_comment_text()\n",
    "\n",
    "    async def _generate_quarterly_overall_comment_text_improved(self, state: 'Module11AgentState', data: Dict[str, Any]) -> str:\n",
    "        \"\"\"ê°œì„ ëœ ë¶„ê¸° ì´í‰ ìƒì„±\"\"\"\n",
    "        \n",
    "        team_info = data.get('team_info', {})\n",
    "        period_info = data.get('period_info', {})\n",
    "        team_performance = data.get('team_performance', {})\n",
    "        previous_quarter = data.get('previous_quarter', {})\n",
    "        team_comparison = data.get('team_comparison', '')\n",
    "        \n",
    "        # ì „ë¶„ê¸° ëŒ€ë¹„ ë³€í™” ê³„ì‚°\n",
    "        current_achievement = team_performance.get('average_achievement_rate', 0)\n",
    "        prev_achievement = previous_quarter.get('average_achievement_rate', 0) if previous_quarter else 0\n",
    "        achievement_change = current_achievement - prev_achievement\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ë¶„ê¸°ë³„ ì„±ê³¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ê¸° ì´í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "## íŒ€ ê¸°ë³¸ ì •ë³´:\n",
    "- íŒ€ëª…: {team_info.get('team_name')}\n",
    "- í‰ê°€ ê¸°ê°„: {period_info.get('period_name')}\n",
    "\n",
    "## í˜„ì¬ ë¶„ê¸° ì„±ê³¼:\n",
    "- í‰ê·  ë‹¬ì„±ë¥ : {current_achievement}%\n",
    "- ìƒëŒ€ì  ì„±ê³¼: {team_performance.get('relative_performance', 0)}%\n",
    "\n",
    "## ì „ë¶„ê¸° ì„±ê³¼ (ë¹„êµ):\n",
    "- ì „ë¶„ê¸° ë‹¬ì„±ë¥ : {prev_achievement}%\n",
    "- ë‹¬ì„±ë¥  ë³€í™”: {achievement_change:+.1f}%p\n",
    "\n",
    "## ìœ ì‚¬íŒ€ ë¹„êµ ë¶„ì„:\n",
    "{team_comparison}\n",
    "\n",
    "## ì‹ë³„ëœ ì£¼ìš” ë¦¬ìŠ¤í¬:\n",
    "{json.dumps(state.key_risks, ensure_ascii=False)}\n",
    "\n",
    "ë‹¤ìŒ êµ¬ì¡°ë¡œ ë¶„ê¸° ì´í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "**[ì „ë¶„ê¸° ëŒ€ë¹„ ë³€í™”]**\n",
    "ì „ë¶„ê¸° ëŒ€ë¹„ ì£¼ìš” ë³€í™”ì‚¬í•­ê³¼ ì„±ê³¼ íŠ¸ë Œë“œë¥¼ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í•¨ê»˜ ë¶„ì„í•´ì£¼ì„¸ìš”. (2-3ë¬¸ì¥)\n",
    "\n",
    "**[ìœ ì‚¬ì¡°ì§ ëŒ€ë¹„ í˜„í™©]**\n",
    "ìƒëŒ€ì  ìœ„ì¹˜ì™€ ë²¤ì¹˜ë§ˆí‚¹ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œì‹œí•˜ê³ , ê°œì„  ë˜ëŠ” ìœ ì§€í•´ì•¼ í•  í¬ì¸íŠ¸ë¥¼ ëª…í™•íˆ í•´ì£¼ì„¸ìš”. (2-3ë¬¸ì¥)\n",
    "\n",
    "**[ì¢…í•© í‰ê°€]**\n",
    "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ì™€ ë‹¤ìŒ ë¶„ê¸°ê¹Œì§€ ì¦‰ì‹œ ì§‘ì¤‘í•´ì•¼ í•  ì˜ì—­ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ê³¼ í•¨ê»˜ ì œì‹œí•´ì£¼ì„¸ìš”. (2-3ë¬¸ì¥)\n",
    "\n",
    "## ì‘ì„± ìš”êµ¬ì‚¬í•­:\n",
    "1. êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ë³€í™”ëŸ‰ì„ ë°˜ë“œì‹œ í¬í•¨\n",
    "2. ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©í–¥ ì œì‹œ\n",
    "3. ë‹¤ìŒ ë¶„ê¸° ì„±ê³¼ í–¥ìƒì„ ìœ„í•œ ëª…í™•í•œ ê°€ì´ë“œ ì œê³µ\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = await asyncio.to_thread(llm_client.invoke, prompt)\n",
    "            result = response.content.strip()\n",
    "            \n",
    "            # ë‚´ìš© í’ˆì§ˆ ê²€ì¦\n",
    "            if len(result) < 200:\n",
    "                logger.warning(\"ë¶„ê¸° ì´í‰ì´ ë„ˆë¬´ ì§§ìŒ - í´ë°± ì‚¬ìš©\")\n",
    "                return self._create_fallback_quarterly_comment_text()\n",
    "            \n",
    "            logger.info(f\"âœ… ê³ í’ˆì§ˆ ë¶„ê¸° ì´í‰ ìƒì„± ì™„ë£Œ: {len(result)}ì\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ë¶„ê¸° ì´í‰ LLM ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n",
    "            return self._create_fallback_quarterly_comment_text()\n",
    "        \n",
    "\n",
    "    def _create_fallback_annual_comment_text(self) -> str:\n",
    "        \"\"\"ê°œì„ ëœ í´ë°± ì—°ë§ ì´í‰\"\"\"\n",
    "        return \"\"\"**[íŒ€ ì„±ê³¼ ë°©í–¥]**\n",
    "ì‹œìŠ¤í…œ ë¶„ì„ì˜ ê¸°ìˆ ì  í•œê³„ë¡œ ì¸í•´ ì •í™•í•œ ì—°ê°„ ì„±ê³¼ ë¶„ì„ì´ ì œí•œë˜ì—ˆìœ¼ë‚˜, íŒ€ì˜ ì§€ì†ì ì¸ ì„±ì¥ê³¼ ë°œì „ì„ ìœ„í•´ì„œëŠ” ì²´ê³„ì ì¸ ì„±ê³¼ ê´€ë¦¬ì™€ ëª©í‘œ ë‹¬ì„± ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤. ìë™í™”ëœ ë¶„ì„ ì‹œìŠ¤í…œì„ ë³´ì™„í•˜ëŠ” ìˆ˜ë™ ê²€í†  í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ë”ìš± ì •í™•í•œ ì„±ê³¼ í‰ê°€ ì²´ê³„ë¥¼ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**[êµ¬ì¡°ì  ì¸ì‹]**\n",
    "í˜„ì¬ ì¡°ì§ì˜ ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì‹œìŠ¤í…œì´ ì™„ì „í•˜ì§€ ì•ŠìŒì„ ì¸ì‹í•˜ê³ , ì´ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆëŠ” ë‹¤ì¸µì  ê²€í†  ì²´ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤. íŒ€ì¥ì˜ ì§ì ‘ì ì¸ ê´€ì°°ê³¼ íŒë‹¨ì„ í†µí•œ ì •ì„±ì  í‰ê°€ì™€ ì‹œìŠ¤í…œ ë¶„ì„ì„ ê²°í•©í•˜ì—¬ ë³´ë‹¤ ê· í˜•ì¡íŒ ì¡°ì§ ìš´ì˜ì´ ê°€ëŠ¥í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "**[í–¥í›„ ìš´ì˜ ì „ëµ]**  \n",
    "ì°¨ë…„ë„ì—ëŠ” ì‹œìŠ¤í…œ ì˜ì¡´ë„ë¥¼ ì¤„ì´ê³  íŒ€ì¥ ì£¼ë„ì˜ ëŠ¥ë™ì  íŒ€ ê´€ë¦¬ ì²´ê³„ë¥¼ ê°•í™”í•˜ëŠ” ê²ƒì´ ìš°ì„ ìˆœìœ„ì…ë‹ˆë‹¤. ì •ê¸°ì ì¸ ê°œë³„ ë©´ë‹´, íŒ€ ë‚´ ì†Œí†µ í™œì„±í™”, ê·¸ë¦¬ê³  êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•œ ëª©í‘œ ì„¤ì •ì„ í†µí•´ íŒ€ ì„±ê³¼ë¥¼ ì§€ì†ì ìœ¼ë¡œ í–¥ìƒì‹œì¼œ ë‚˜ê°€ì•¼ í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    def _create_fallback_quarterly_comment_text(self) -> str:\n",
    "        \"\"\"ê°œì„ ëœ í´ë°± ë¶„ê¸° ì´í‰\"\"\"\n",
    "        return \"\"\"**[ì „ë¶„ê¸° ëŒ€ë¹„ ë³€í™”]**\n",
    "ì‹œìŠ¤í…œ ë¶„ì„ í•œê³„ë¡œ ì¸í•´ ì •í™•í•œ ì „ë¶„ê¸° ëŒ€ë¹„ ë³€í™”ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ íŒŒì•…í•˜ê¸° ì–´ë ¤ìš°ë‚˜, ì§€ì†ì ì¸ ì„±ê³¼ ê´€ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” íŒ€ì¥ì˜ ì§ì ‘ì ì¸ ê´€ì°°ê³¼ í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "**[ìœ ì‚¬ì¡°ì§ ëŒ€ë¹„ í˜„í™©]**\n",
    "ë¹„êµ ë°ì´í„°ì˜ í•œê³„ë¡œ ìœ ì‚¬ì¡°ì§ê³¼ì˜ ì •í™•í•œ ë²¤ì¹˜ë§ˆí‚¹ì´ ì œí•œì ì´ì§€ë§Œ, íŒ€ ê³ ìœ ì˜ ê°•ì ì„ í™œìš©í•œ ì°¨ë³„í™”ëœ ì„±ê³¼ ì°½ì¶œì— ì§‘ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "**[ì¢…í•© í‰ê°€]**\n",
    "ë‹¤ìŒ ë¶„ê¸°ì—ëŠ” ì‹œìŠ¤í…œì— ì˜ì¡´í•˜ì§€ ì•ŠëŠ” ë…ë¦½ì ì¸ ì„±ê³¼ ëª¨ë‹ˆí„°ë§ ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ê³ , íŒ€ì›ë“¤ê³¼ì˜ ì§ì ‘ì ì¸ ì†Œí†µì„ í†µí•´ ì‹¤ì§ˆì ì¸ ì„±ê³¼ ê°œì„  ë°©ì•ˆì„ ë„ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    # ====================================\n",
    "    # 10. ì €ì¥ ë©”ì„œë“œë“¤\n",
    "    # ====================================\n",
    "\n",
    "    def _save_results(self, state) -> None:\n",
    "        \"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ (ìˆ˜ì •ëœ ë²„ì „)\"\"\"\n",
    "        logger.info(f\"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹œì‘: team_evaluation_id={state.team_evaluation_id}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. ì €ì¥í•  ë°ì´í„° ì¤€ë¹„\n",
    "            save_data = self._prepare_save_data(state)\n",
    "            \n",
    "            if not save_data:\n",
    "                logger.warning(\"ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return\n",
    "            \n",
    "            # 2. ì €ì¥ ì „ ê²€ì¦ (ì¡´ì¬í•˜ëŠ” ë ˆì½”ë“œì¸ì§€ í™•ì¸)\n",
    "            if not self._verify_team_evaluation_exists(state.team_evaluation_id):\n",
    "                raise DatabaseError(f\"team_evaluation_id {state.team_evaluation_id}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            # 3. ì‹¤ì œ ì—…ë°ì´íŠ¸\n",
    "            affected_rows = self._update_team_evaluations(state.team_evaluation_id, save_data)\n",
    "            \n",
    "            if affected_rows == 0:\n",
    "                raise DatabaseError(f\"ì—…ë°ì´íŠ¸ëœ í–‰ì´ ì—†ìŒ: team_evaluation_id={state.team_evaluation_id}\")\n",
    "            \n",
    "            # 4. ì €ì¥ í›„ ê²€ì¦\n",
    "            self._verify_save_success(state.team_evaluation_id, save_data)\n",
    "            \n",
    "            logger.info(f\"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: team_evaluation_id={state.team_evaluation_id}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}\")\n",
    "            raise DatabaseError(f\"DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "\n",
    "    def _prepare_save_data(self, state) -> dict:\n",
    "        \"\"\"ì €ì¥ìš© ë°ì´í„° ì¤€ë¹„\"\"\"\n",
    "        save_data = {}\n",
    "        \n",
    "        # ai_riskëŠ” JSONìœ¼ë¡œ ì €ì¥\n",
    "        if state.ai_risk_result:\n",
    "            save_data['ai_risk'] = json.dumps(state.ai_risk_result, ensure_ascii=False)\n",
    "            logger.info(f\"ai_risk ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(save_data['ai_risk'])}ì\")\n",
    "        \n",
    "        # ai_planì€ JSONìœ¼ë¡œ ì €ì¥ (ì—°ë§ë§Œ)\n",
    "        if state.is_final and state.ai_plan_result:\n",
    "            save_data['ai_plan'] = json.dumps(state.ai_plan_result, ensure_ascii=False)\n",
    "            logger.info(f\"ai_plan ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(save_data['ai_plan'])}ì\")\n",
    "        \n",
    "        # overall_commentëŠ” í…ìŠ¤íŠ¸ë¡œ ì €ì¥\n",
    "        if state.overall_comment_result:\n",
    "            save_data['overall_comment'] = state.overall_comment_result\n",
    "            logger.info(f\"overall_comment ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(save_data['overall_comment'])}ì\")\n",
    "        \n",
    "        logger.info(f\"ì´ {len(save_data)}ê°œ í•„ë“œ ì¤€ë¹„ ì™„ë£Œ: {list(save_data.keys())}\")\n",
    "        return save_data\n",
    "    \n",
    "    def _verify_team_evaluation_exists(self, team_evaluation_id: int) -> bool:\n",
    "        \"\"\"team_evaluation ë ˆì½”ë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\"\"\"\n",
    "        query = \"SELECT COUNT(*) as cnt FROM team_evaluations WHERE team_evaluation_id = :team_evaluation_id\"\n",
    "        result = self.db.fetch_one(query, {'team_evaluation_id': team_evaluation_id})\n",
    "        \n",
    "        exists = result['cnt'] > 0 if result else False\n",
    "        logger.info(f\"team_evaluation_id {team_evaluation_id} ì¡´ì¬ ì—¬ë¶€: {exists}\")\n",
    "        return exists\n",
    "\n",
    "    def _update_team_evaluations(self, team_evaluation_id: int, save_data: dict) -> int:\n",
    "        \"\"\"team_evaluations í…Œì´ë¸” ì—…ë°ì´íŠ¸ (ìˆ˜ì •ëœ ë²„ì „)\"\"\"\n",
    "        \n",
    "        # UPDATE ì¿¼ë¦¬ ë™ì  ìƒì„±\n",
    "        set_clauses = []\n",
    "        params = {'team_evaluation_id': team_evaluation_id}\n",
    "        \n",
    "        for column, value in save_data.items():\n",
    "            set_clauses.append(f\"{column} = :{column}\")\n",
    "            params[column] = value\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        UPDATE team_evaluations \n",
    "        SET {', '.join(set_clauses)}\n",
    "        WHERE team_evaluation_id = :team_evaluation_id\n",
    "        \"\"\"\n",
    "        \n",
    "        logger.info(f\"ì‹¤í–‰í•  ì¿¼ë¦¬: {query}\")\n",
    "        logger.info(f\"íŒŒë¼ë¯¸í„° í‚¤: {list(params.keys())}\")\n",
    "        \n",
    "        # ì‹¤ì œ ì—…ë°ì´íŠ¸ ì‹¤í–‰\n",
    "        affected_rows = self.db.execute_update(query, params)\n",
    "        \n",
    "        return affected_rows\n",
    "    \n",
    "    def _verify_save_success(self, team_evaluation_id: int, save_data: dict) -> None:\n",
    "        \"\"\"ì €ì¥ ì„±ê³µ ì—¬ë¶€ ê²€ì¦\"\"\"\n",
    "        logger.info(\"ì €ì¥ ê²°ê³¼ ê²€ì¦ ì‹œì‘...\")\n",
    "        \n",
    "        # ì €ì¥ëœ ë°ì´í„° ë‹¤ì‹œ ì¡°íšŒ\n",
    "        columns = list(save_data.keys())\n",
    "        query = f\"\"\"\n",
    "        SELECT {', '.join(columns)}\n",
    "        FROM team_evaluations \n",
    "        WHERE team_evaluation_id = :team_evaluation_id\n",
    "        \"\"\"\n",
    "        \n",
    "        result = self.db.fetch_one(query, {'team_evaluation_id': team_evaluation_id})\n",
    "        \n",
    "        if not result:\n",
    "            raise DatabaseError(\"ì €ì¥ ê²€ì¦ ì‹¤íŒ¨: ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì¡°íšŒí•  ìˆ˜ ì—†ìŒ\")\n",
    "        \n",
    "        # ê° í•„ë“œë³„ ê²€ì¦\n",
    "        for column in columns:\n",
    "            saved_value = result.get(column)\n",
    "            if not saved_value:\n",
    "                logger.warning(f\"âš ï¸ {column} í•„ë“œê°€ ë¹„ì–´ìˆìŒ\")\n",
    "            else:\n",
    "                logger.info(f\"âœ… {column} ì €ì¥ í™•ì¸: {len(str(saved_value))}ì\")\n",
    "        \n",
    "        logger.info(\"ì €ì¥ ê²°ê³¼ ê²€ì¦ ì™„ë£Œ\")\n",
    "    \n",
    "\n",
    "\n",
    "# ====================================\n",
    "# 11. ì‹¤í–‰ í•¨ìˆ˜\n",
    "# ====================================\n",
    "\n",
    "async def run_module_11(team_id: int, period_id: int, team_evaluation_id: int) -> Module11AgentState:\n",
    "    \"\"\"Module 11 ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Agent ì´ˆê¸°í™”\n",
    "        agent = Module11TeamRiskManagementAgent(db_wrapper)\n",
    "        \n",
    "        # ì‹¤í–‰\n",
    "        result = await agent.execute(team_id, period_id, team_evaluation_id)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Module 11 ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 19:46:36,987 - __main__ - INFO - Module11 ì‹œì‘: team_id=900001, period_id=800007\n",
      "2025-06-24 19:46:37,007 - __main__ - INFO - ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: team_evaluation_id=700001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Module 11 ê°œì„  ë²„ì „ ì¢…í•© í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸\n",
      "ğŸš€ ê°œì„ ëœ Module 11 í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "================================================================================\n",
      "ğŸ“‹ í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°:\n",
      "   íŒ€ ID: 900001 (AIí•µì‹¬ê¸°ìˆ íŒ€)\n",
      "   ê¸°ê°„ ID: 800007 (2025ë…„ 4ë¶„ê¸° - ì—°ë§)\n",
      "   í‰ê°€ ID: 700001\n",
      "================================================================================\n",
      "\n",
      "ğŸ” ì‹¤í–‰ ì „ DB ìƒíƒœ í™•ì¸...\n",
      "ğŸ“Š ì‹¤í–‰ ì „ ìƒíƒœ:\n",
      "   ai_risk: ì—†ìŒ (0ì)\n",
      "   ai_plan: ì—†ìŒ (0ì)\n",
      "   overall_comment: ì—†ìŒ (0ì)\n",
      "   ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: None\n",
      "\n",
      "âš¡ ê°œì„ ëœ Module 11 ì‹¤í–‰ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 19:46:37,136 - __main__ - WARNING - ê°œì¸ í‰ê°€ ë°ì´í„° ì—†ìŒ: team_evaluation_id=700001\n",
      "2025-06-24 19:46:37,138 - __main__ - INFO - DBì—ì„œ temp_evaluations ì¡°íšŒ: team_id=900001\n",
      "2025-06-24 19:46:37,196 - __main__ - INFO - ì¤‘ê°„í‰ê°€ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: 5ê±´\n",
      "2025-06-24 19:46:37,197 - __main__ - INFO - ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: 9 ê°œ ë°ì´í„°ì…‹\n",
      "2025-06-24 19:46:37,198 - __main__ - INFO - LLM ê¸°ë°˜ ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹œì‘ (ë³‘ë ¬)\n",
      "2025-06-24 19:46:45,414 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-24 19:46:47,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-24 19:47:06,714 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-24 19:47:06,721 - __main__ - INFO - âœ… ê³ í’ˆì§ˆ ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ: 5ê°œ ë¦¬ìŠ¤í¬ ì‹ë³„\n",
      "2025-06-24 19:47:06,721 - __main__ - INFO - LLM ê¸°ë°˜ ë¦¬ìŠ¤í¬ ë¶„ì„ ì™„ë£Œ\n",
      "2025-06-24 19:47:06,722 - __main__ - INFO - ìµœì¢… ê²°ê³¼ ìƒì„± ì‹œì‘ (ë³‘ë ¬)\n",
      "2025-06-24 19:47:13,190 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-24 19:47:13,193 - __main__ - INFO - âœ… ê³ í’ˆì§ˆ ì—°ë§ ì´í‰ ìƒì„± ì™„ë£Œ: 696ì\n",
      "2025-06-24 19:47:17,093 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-06-24 19:47:17,096 - __main__ - INFO - âœ… ê³ í’ˆì§ˆ ì—°ë§ ê³„íš ìƒì„± ì™„ë£Œ\n",
      "2025-06-24 19:47:17,098 - __main__ - INFO - ìµœì¢… ê²°ê³¼ ìƒì„± ì™„ë£Œ\n",
      "2025-06-24 19:47:17,099 - __main__ - INFO - ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹œì‘: team_evaluation_id=700001\n",
      "2025-06-24 19:47:17,101 - __main__ - INFO - ai_risk ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: 2620ì\n",
      "2025-06-24 19:47:17,102 - __main__ - INFO - ai_plan ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: 1182ì\n",
      "2025-06-24 19:47:17,103 - __main__ - INFO - overall_comment ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: 696ì\n",
      "2025-06-24 19:47:17,104 - __main__ - INFO - ì´ 3ê°œ í•„ë“œ ì¤€ë¹„ ì™„ë£Œ: ['ai_risk', 'ai_plan', 'overall_comment']\n",
      "2025-06-24 19:47:17,127 - __main__ - INFO - team_evaluation_id 700001 ì¡´ì¬ ì—¬ë¶€: True\n",
      "2025-06-24 19:47:17,129 - __main__ - INFO - ì‹¤í–‰í•  ì¿¼ë¦¬: \n",
      "        UPDATE team_evaluations \n",
      "        SET ai_risk = :ai_risk, ai_plan = :ai_plan, overall_comment = :overall_comment\n",
      "        WHERE team_evaluation_id = :team_evaluation_id\n",
      "        \n",
      "2025-06-24 19:47:17,130 - __main__ - INFO - íŒŒë¼ë¯¸í„° í‚¤: ['team_evaluation_id', 'ai_risk', 'ai_plan', 'overall_comment']\n",
      "2025-06-24 19:47:17,144 - __main__ - INFO - ì—…ë°ì´íŠ¸ ì™„ë£Œ: 1í–‰ ì˜í–¥\n",
      "2025-06-24 19:47:17,158 - __main__ - INFO - ì €ì¥ ê²°ê³¼ ê²€ì¦ ì‹œì‘...\n",
      "2025-06-24 19:47:17,180 - __main__ - INFO - âœ… ai_risk ì €ì¥ í™•ì¸: 2620ì\n",
      "2025-06-24 19:47:17,182 - __main__ - INFO - âœ… ai_plan ì €ì¥ í™•ì¸: 1182ì\n",
      "2025-06-24 19:47:17,182 - __main__ - INFO - âœ… overall_comment ì €ì¥ í™•ì¸: 696ì\n",
      "2025-06-24 19:47:17,183 - __main__ - INFO - ì €ì¥ ê²°ê³¼ ê²€ì¦ ì™„ë£Œ\n",
      "2025-06-24 19:47:17,184 - __main__ - INFO - âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: team_evaluation_id=700001\n",
      "2025-06-24 19:47:17,187 - __main__ - INFO - Module11 ì™„ë£Œ: team_id=900001\n",
      "2025-06-24 19:47:17,215 - __main__ - INFO - ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: team_evaluation_id=700001\n",
      "2025-06-24 19:47:17,344 - __main__ - WARNING - ê°œì¸ í‰ê°€ ë°ì´í„° ì—†ìŒ: team_evaluation_id=700001\n",
      "2025-06-24 19:47:17,345 - __main__ - INFO - DBì—ì„œ temp_evaluations ì¡°íšŒ: team_id=900001\n",
      "2025-06-24 19:47:17,365 - __main__ - INFO - ì¤‘ê°„í‰ê°€ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: 5ê±´\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‹¤í–‰ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: 40.2ì´ˆ)\n",
      "\n",
      "ğŸ” ì‹¤í–‰ í›„ DB ìƒíƒœ í™•ì¸...\n",
      "ğŸ“Š ì‹¤í–‰ í›„ ìƒíƒœ:\n",
      "   ai_risk: ìƒì„±ë¨ (2620ì)\n",
      "   ai_plan: ìƒì„±ë¨ (1182ì)\n",
      "   overall_comment: ìƒì„±ë¨ (696ì)\n",
      "   ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: None\n",
      "\n",
      "ğŸ“Š ê²°ê³¼ ë¶„ì„...\n",
      "ğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„:\n",
      "   ì‹¤í–‰ ì‹œê°„: 40.2ì´ˆ\n",
      "   ì—°ë§ í‰ê°€ ì—¬ë¶€: True\n",
      "   ì‹ë³„ëœ ë¦¬ìŠ¤í¬ ìˆ˜: 5ê°œ\n",
      "   í˜‘ì—… í¸í–¥ ìˆ˜ì¤€: medium\n",
      "   âœ… ai_risk: ì„±ê³µ (0 â†’ 2620ì, +2620)\n",
      "   âœ… ai_plan: ì„±ê³µ (0 â†’ 1182ì, +1182)\n",
      "   âœ… overall_comment: ì„±ê³µ (0 â†’ 696ì, +696)\n",
      "\n",
      "ğŸ”¬ JSON êµ¬ì¡° ê²€ì¦...\n",
      "ğŸ”¬ JSON êµ¬ì¡° ê²€ì¦:\n",
      "   âœ… ai_risk: ì˜¬ë°”ë¥¸ JSON êµ¬ì¡° (ì£¼ìš” ë¦¬ìŠ¤í¬ 5ê°œ)\n",
      "      âœ… ë¦¬ìŠ¤í¬ í•„ë“œ ì™„ì „ì„±: ëª¨ë“  í•„ìˆ˜ í•„ë“œ ì¡´ì¬\n",
      "   âœ… ai_plan: ì˜¬ë°”ë¥¸ JSON êµ¬ì¡° (ì—°ê°„ ê³„íš 1ê°œ)\n",
      "      âœ… ê³„íš êµ¬ì„±: ì¸ì‚¬ì „ëµ 3ê°œ, í˜‘ì—…ê°œì„  3ê°œ\n",
      "\n",
      "ğŸ“ ë‚´ìš© í’ˆì§ˆ ê²€ì¦...\n",
      "ğŸ“ ë‚´ìš© í’ˆì§ˆ ê²€ì¦:\n",
      "   ğŸ“‹ ai_risk í’ˆì§ˆ:\n",
      "      âœ… êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨\n",
      "      âœ… í•œêµ­ì–´ ë¶„ì„\n",
      "      âœ… ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ\n",
      "      âœ… ì¶©ë¶„í•œ ë‚´ìš©ëŸ‰\n",
      "   ğŸ’¬ overall_comment í’ˆì§ˆ:\n",
      "      âœ… êµ¬ì¡°í™”ëœ í˜•ì‹\n",
      "      âœ… êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨\n",
      "      âœ… ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©\n",
      "      âœ… ì¶©ë¶„í•œ ë¶„ëŸ‰\n",
      "\n",
      "ğŸ“‹ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½...\n",
      "================================================================================\n",
      "ğŸ“‹ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
      "================================================================================\n",
      "ğŸ¯ ì „ì²´ ì„±ê³µë¥ : 100.0% (3/3)\n",
      "ğŸ“ˆ ê°œì„  íš¨ê³¼: ai_risk: +2620ì, ai_plan: +1182ì, overall_comment: +696ì\n",
      "ğŸ”§ êµ¬ì¡° ê°œì„ : ai_risk êµ¬ì¡°í™”, ai_plan êµ¬ì¡°í™”\n",
      "\n",
      "ğŸ’¡ ê¶Œì¥ ì‚¬í•­:\n",
      "   âœ… ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥\n",
      "   - í”„ë¡œë•ì…˜ í™˜ê²½ ì ìš© ê³ ë ¤ ê°€ëŠ¥\n",
      "================================================================================\n",
      "\n",
      "2ï¸âƒ£ ê°œë³„ êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸\n",
      "\n",
      "ğŸ§ª ê°œë³„ êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸\n",
      "--------------------------------------------------\n",
      "ğŸ“Š ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 19:47:17,367 - __main__ - INFO - ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: 9 ê°œ ë°ì´í„°ì…‹\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: 9ê°œ ë°ì´í„°ì…‹\n",
      "\n",
      "ğŸ” í˜‘ì—… ë¦¬ìŠ¤í¬ ë¶„ì„ í…ŒìŠ¤íŠ¸...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 19:47:24,916 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ê²°ê³¼: 3ê°œ í˜‘ì—… ë¦¬ìŠ¤í¬ ì‹ë³„\n",
      "\n",
      "ğŸ” ê°œì¸ ë¦¬ìŠ¤í¬ íŒ¨í„´ ë¶„ì„ í…ŒìŠ¤íŠ¸...\n",
      "   ê²°ê³¼: 0ê°œ ê°œì¸ ë¦¬ìŠ¤í¬ ì‹ë³„\n",
      "\n",
      "ğŸ” ì„±ê³¼ íŠ¸ë Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 19:47:34,339 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ê²°ê³¼: 2ê°œ ì„±ê³¼ ë¦¬ìŠ¤í¬ ì‹ë³„\n",
      "\n",
      "3ï¸âƒ£ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ vs ê°œì„ )\n",
      "\n",
      "ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Module 11 ê°œì„  ë²„ì „ í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "# ====================================\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "# ====================================\n",
    "# 1. í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„° (ì‹¤ì œ ë°ì´í„°)\n",
    "# ====================================\n",
    "\n",
    "# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë°ì´í„°\n",
    "TEST_TEAM_ID = 900001  # AIí•µì‹¬ê¸°ìˆ íŒ€\n",
    "TEST_PERIOD_ID = 800007  # 2025ë…„ 4ë¶„ê¸° (ì—°ë§)\n",
    "TEST_TEAM_EVALUATION_ID = 700001  # í•´ë‹¹ íŒ€ í‰ê°€\n",
    "\n",
    "# ====================================\n",
    "# 2. ê°œì„  ì „í›„ ë¹„êµ í…ŒìŠ¤íŠ¸\n",
    "# ====================================\n",
    "\n",
    "async def test_improved_module11():\n",
    "    \"\"\"ê°œì„ ëœ Module 11 ì „ì²´ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ ê°œì„ ëœ Module 11 í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ğŸ“‹ í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°:\")\n",
    "    print(f\"   íŒ€ ID: {TEST_TEAM_ID} (AIí•µì‹¬ê¸°ìˆ íŒ€)\")\n",
    "    print(f\"   ê¸°ê°„ ID: {TEST_PERIOD_ID} (2025ë…„ 4ë¶„ê¸° - ì—°ë§)\")\n",
    "    print(f\"   í‰ê°€ ID: {TEST_TEAM_EVALUATION_ID}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # ì‹¤í–‰ ì „ DB ìƒíƒœ í™•ì¸\n",
    "        print(\"\\nğŸ” ì‹¤í–‰ ì „ DB ìƒíƒœ í™•ì¸...\")\n",
    "        before_data = check_db_before_test(TEST_TEAM_EVALUATION_ID)\n",
    "        \n",
    "        # ê°œì„ ëœ Module 11 ì‹¤í–‰\n",
    "        print(\"\\nâš¡ ê°œì„ ëœ Module 11 ì‹¤í–‰ ì¤‘...\")\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        result = await run_module_11(TEST_TEAM_ID, TEST_PERIOD_ID, TEST_TEAM_EVALUATION_ID)\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        execution_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        print(f\"âœ… ì‹¤í–‰ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {execution_time:.1f}ì´ˆ)\")\n",
    "        \n",
    "        # ì‹¤í–‰ í›„ DB ìƒíƒœ í™•ì¸\n",
    "        print(\"\\nğŸ” ì‹¤í–‰ í›„ DB ìƒíƒœ í™•ì¸...\")\n",
    "        after_data = check_db_after_test(TEST_TEAM_EVALUATION_ID)\n",
    "        \n",
    "        # ê²°ê³¼ ë¶„ì„\n",
    "        print(\"\\nğŸ“Š ê²°ê³¼ ë¶„ì„...\")\n",
    "        analyze_test_results(result, before_data, after_data, execution_time)\n",
    "        \n",
    "        # JSON êµ¬ì¡° ê²€ì¦\n",
    "        print(\"\\nğŸ”¬ JSON êµ¬ì¡° ê²€ì¦...\")\n",
    "        validate_json_structures(after_data)\n",
    "        \n",
    "        # ë‚´ìš© í’ˆì§ˆ ê²€ì¦\n",
    "        print(\"\\nğŸ“ ë‚´ìš© í’ˆì§ˆ ê²€ì¦...\")\n",
    "        validate_content_quality(after_data)\n",
    "        \n",
    "        # ìµœì¢… ê²°ê³¼ ìš”ì•½\n",
    "        print(\"\\nğŸ“‹ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½...\")\n",
    "        summarize_test_results(result, before_data, after_data)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ====================================\n",
    "# 3. DB ìƒíƒœ í™•ì¸ í•¨ìˆ˜ë“¤\n",
    "# ====================================\n",
    "\n",
    "def check_db_before_test(team_evaluation_id: int) -> Dict[str, Any]:\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì „ DB ìƒíƒœ í™•ì¸\"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT ai_risk, ai_plan, overall_comment,\n",
    "           ai_collaboration_matrix, ai_team_coaching, ai_team_comparison,\n",
    "           updated_at\n",
    "    FROM team_evaluations \n",
    "    WHERE team_evaluation_id = :team_evaluation_id\n",
    "    \"\"\"\n",
    "    \n",
    "    result = db_wrapper.fetch_one(query, {'team_evaluation_id': team_evaluation_id})\n",
    "    \n",
    "    if result:\n",
    "        print(\"ğŸ“Š ì‹¤í–‰ ì „ ìƒíƒœ:\")\n",
    "        print(f\"   ai_risk: {'ìˆìŒ' if result['ai_risk'] else 'ì—†ìŒ'} ({len(str(result['ai_risk'])) if result['ai_risk'] else 0}ì)\")\n",
    "        print(f\"   ai_plan: {'ìˆìŒ' if result['ai_plan'] else 'ì—†ìŒ'} ({len(str(result['ai_plan'])) if result['ai_plan'] else 0}ì)\")\n",
    "        print(f\"   overall_comment: {'ìˆìŒ' if result['overall_comment'] else 'ì—†ìŒ'} ({len(str(result['overall_comment'])) if result['overall_comment'] else 0}ì)\")\n",
    "        print(f\"   ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {result.get('updated_at', 'Unknown')}\")\n",
    "        \n",
    "        return dict(result)\n",
    "    else:\n",
    "        print(\"âŒ í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "        return {}\n",
    "\n",
    "def check_db_after_test(team_evaluation_id: int) -> Dict[str, Any]:\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í›„ DB ìƒíƒœ í™•ì¸\"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT ai_risk, ai_plan, overall_comment,\n",
    "           ai_collaboration_matrix, ai_team_coaching, ai_team_comparison,\n",
    "           updated_at\n",
    "    FROM team_evaluations \n",
    "    WHERE team_evaluation_id = :team_evaluation_id\n",
    "    \"\"\"\n",
    "    \n",
    "    result = db_wrapper.fetch_one(query, {'team_evaluation_id': team_evaluation_id})\n",
    "    \n",
    "    if result:\n",
    "        print(\"ğŸ“Š ì‹¤í–‰ í›„ ìƒíƒœ:\")\n",
    "        print(f\"   ai_risk: {'ìƒì„±ë¨' if result['ai_risk'] else 'ìƒì„± ì‹¤íŒ¨'} ({len(str(result['ai_risk'])) if result['ai_risk'] else 0}ì)\")\n",
    "        print(f\"   ai_plan: {'ìƒì„±ë¨' if result['ai_plan'] else 'ìƒì„± ì‹¤íŒ¨'} ({len(str(result['ai_plan'])) if result['ai_plan'] else 0}ì)\")\n",
    "        print(f\"   overall_comment: {'ìƒì„±ë¨' if result['overall_comment'] else 'ìƒì„± ì‹¤íŒ¨'} ({len(str(result['overall_comment'])) if result['overall_comment'] else 0}ì)\")\n",
    "        print(f\"   ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {result.get('updated_at', 'Unknown')}\")\n",
    "        \n",
    "        return dict(result)\n",
    "    else:\n",
    "        print(\"âŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "        return {}\n",
    "\n",
    "# ====================================\n",
    "# 4. ê²°ê³¼ ë¶„ì„ í•¨ìˆ˜ë“¤\n",
    "# ====================================\n",
    "\n",
    "def analyze_test_results(result: Any, before_data: Dict, after_data: Dict, execution_time: float):\n",
    "    \"\"\"í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¢…í•© ë¶„ì„\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„:\")\n",
    "    print(f\"   ì‹¤í–‰ ì‹œê°„: {execution_time:.1f}ì´ˆ\")\n",
    "    print(f\"   ì—°ë§ í‰ê°€ ì—¬ë¶€: {result.is_final if result else 'Unknown'}\")\n",
    "    print(f\"   ì‹ë³„ëœ ë¦¬ìŠ¤í¬ ìˆ˜: {len(result.key_risks) if result and result.key_risks else 0}ê°œ\")\n",
    "    print(f\"   í˜‘ì—… í¸í–¥ ìˆ˜ì¤€: {result.collaboration_bias_level if result else 'Unknown'}\")\n",
    "    \n",
    "    # ë°ì´í„° ìƒì„± ì—¬ë¶€ í™•ì¸\n",
    "    module11_fields = ['ai_risk', 'ai_plan', 'overall_comment']\n",
    "    \n",
    "    for field in module11_fields:\n",
    "        before_len = len(str(before_data.get(field, ''))) if before_data.get(field) else 0\n",
    "        after_len = len(str(after_data.get(field, ''))) if after_data.get(field) else 0\n",
    "        \n",
    "        if after_len > before_len:\n",
    "            print(f\"   âœ… {field}: ì„±ê³µ ({before_len} â†’ {after_len}ì, +{after_len - before_len})\")\n",
    "        elif after_len == before_len and after_len > 0:\n",
    "            print(f\"   âš ï¸ {field}: ë³€ê²½ ì—†ìŒ ({after_len}ì)\")\n",
    "        else:\n",
    "            print(f\"   âŒ {field}: ìƒì„± ì‹¤íŒ¨ ({before_len} â†’ {after_len}ì)\")\n",
    "\n",
    "def validate_json_structures(after_data: Dict[str, Any]):\n",
    "    \"\"\"JSON êµ¬ì¡° ê²€ì¦\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”¬ JSON êµ¬ì¡° ê²€ì¦:\")\n",
    "    \n",
    "    # ai_risk JSON êµ¬ì¡° ê²€ì¦\n",
    "    if after_data.get('ai_risk'):\n",
    "        try:\n",
    "            risk_data = json.loads(after_data['ai_risk'])\n",
    "            \n",
    "            # í•„ìˆ˜ êµ¬ì¡° í™•ì¸\n",
    "            if 'risk_analysis' in risk_data:\n",
    "                major_risks = risk_data['risk_analysis'].get('major_risks', [])\n",
    "                print(f\"   âœ… ai_risk: ì˜¬ë°”ë¥¸ JSON êµ¬ì¡° (ì£¼ìš” ë¦¬ìŠ¤í¬ {len(major_risks)}ê°œ)\")\n",
    "                \n",
    "                # ì²« ë²ˆì§¸ ë¦¬ìŠ¤í¬ êµ¬ì¡° í™•ì¸\n",
    "                if major_risks:\n",
    "                    first_risk = major_risks[0]\n",
    "                    required_fields = ['risk_name', 'severity', 'description', 'causes', 'impacts', 'strategies']\n",
    "                    missing_fields = [f for f in required_fields if f not in first_risk]\n",
    "                    \n",
    "                    if not missing_fields:\n",
    "                        print(f\"      âœ… ë¦¬ìŠ¤í¬ í•„ë“œ ì™„ì „ì„±: ëª¨ë“  í•„ìˆ˜ í•„ë“œ ì¡´ì¬\")\n",
    "                    else:\n",
    "                        print(f\"      âš ï¸ ë¦¬ìŠ¤í¬ í•„ë“œ ëˆ„ë½: {missing_fields}\")\n",
    "                else:\n",
    "                    print(f\"      âš ï¸ ì£¼ìš” ë¦¬ìŠ¤í¬ê°€ ë¹„ì–´ìˆìŒ\")\n",
    "            else:\n",
    "                print(f\"   âŒ ai_risk: ì˜ëª»ëœ JSON êµ¬ì¡° (risk_analysis í‚¤ ì—†ìŒ)\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"   âŒ ai_risk: JSON íŒŒì‹± ì‹¤íŒ¨ - {str(e)}\")\n",
    "    else:\n",
    "        print(f\"   âŒ ai_risk: ë°ì´í„° ì—†ìŒ\")\n",
    "    \n",
    "    # ai_plan JSON êµ¬ì¡° ê²€ì¦\n",
    "    if after_data.get('ai_plan'):\n",
    "        try:\n",
    "            plan_data = json.loads(after_data['ai_plan'])\n",
    "            \n",
    "            if 'annual_plans' in plan_data:\n",
    "                annual_plans = plan_data['annual_plans']\n",
    "                print(f\"   âœ… ai_plan: ì˜¬ë°”ë¥¸ JSON êµ¬ì¡° (ì—°ê°„ ê³„íš {len(annual_plans)}ê°œ)\")\n",
    "                \n",
    "                # ê³„íš êµ¬ì¡° í™•ì¸\n",
    "                if annual_plans:\n",
    "                    first_plan = annual_plans[0]\n",
    "                    if 'personnel_strategies' in first_plan and 'collaboration_improvements' in first_plan:\n",
    "                        personnel_count = len(first_plan['personnel_strategies'])\n",
    "                        collaboration_count = len(first_plan['collaboration_improvements'])\n",
    "                        print(f\"      âœ… ê³„íš êµ¬ì„±: ì¸ì‚¬ì „ëµ {personnel_count}ê°œ, í˜‘ì—…ê°œì„  {collaboration_count}ê°œ\")\n",
    "                    else:\n",
    "                        print(f\"      âš ï¸ ê³„íš êµ¬ì¡° ë¶ˆì™„ì „\")\n",
    "                else:\n",
    "                    print(f\"      âš ï¸ ì—°ê°„ ê³„íšì´ ë¹„ì–´ìˆìŒ\")\n",
    "            else:\n",
    "                print(f\"   âŒ ai_plan: ì˜ëª»ëœ JSON êµ¬ì¡° (annual_plans í‚¤ ì—†ìŒ)\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"   âŒ ai_plan: JSON íŒŒì‹± ì‹¤íŒ¨ - {str(e)}\")\n",
    "    else:\n",
    "        print(f\"   âŒ ai_plan: ë°ì´í„° ì—†ìŒ\")\n",
    "\n",
    "def validate_content_quality(after_data: Dict[str, Any]):\n",
    "    \"\"\"ë‚´ìš© í’ˆì§ˆ ê²€ì¦\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“ ë‚´ìš© í’ˆì§ˆ ê²€ì¦:\")\n",
    "    \n",
    "    # ai_risk ë‚´ìš© í’ˆì§ˆ í™•ì¸\n",
    "    if after_data.get('ai_risk'):\n",
    "        risk_content = after_data['ai_risk']\n",
    "        \n",
    "        # ê¸°ë³¸ í’ˆì§ˆ ì§€í‘œ\n",
    "        quality_indicators = {\n",
    "            'êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨': any(char.isdigit() for char in risk_content),\n",
    "            'í•œêµ­ì–´ ë¶„ì„': 'íŒ€' in risk_content or 'ì„±ê³¼' in risk_content,\n",
    "            'ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ': 'ì „ëµ' in risk_content or 'ê°œì„ ' in risk_content,\n",
    "            'ì¶©ë¶„í•œ ë‚´ìš©ëŸ‰': len(risk_content) > 500\n",
    "        }\n",
    "        \n",
    "        print(\"   ğŸ“‹ ai_risk í’ˆì§ˆ:\")\n",
    "        for indicator, passed in quality_indicators.items():\n",
    "            status = \"âœ…\" if passed else \"âŒ\"\n",
    "            print(f\"      {status} {indicator}\")\n",
    "    \n",
    "    # overall_comment ë‚´ìš© í’ˆì§ˆ í™•ì¸\n",
    "    if after_data.get('overall_comment'):\n",
    "        comment_content = after_data['overall_comment']\n",
    "        \n",
    "        quality_indicators = {\n",
    "            'êµ¬ì¡°í™”ëœ í˜•ì‹': '[' in comment_content and ']' in comment_content,\n",
    "            'êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨': any(char.isdigit() for char in comment_content),\n",
    "            'ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©': 'ì „ëµ' in comment_content or 'ê³„íš' in comment_content,\n",
    "            'ì¶©ë¶„í•œ ë¶„ëŸ‰': len(comment_content) > 300\n",
    "        }\n",
    "        \n",
    "        print(\"   ğŸ’¬ overall_comment í’ˆì§ˆ:\")\n",
    "        for indicator, passed in quality_indicators.items():\n",
    "            status = \"âœ…\" if passed else \"âŒ\"\n",
    "            print(f\"      {status} {indicator}\")\n",
    "\n",
    "def summarize_test_results(result: Any, before_data: Dict, after_data: Dict):\n",
    "    \"\"\"ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“‹ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ì „ì²´ ì„±ê³µë¥  ê³„ì‚°\n",
    "    total_fields = 3  # ai_risk, ai_plan, overall_comment\n",
    "    successful_fields = 0\n",
    "    \n",
    "    if after_data.get('ai_risk'):\n",
    "        successful_fields += 1\n",
    "    if after_data.get('ai_plan'):\n",
    "        successful_fields += 1\n",
    "    if after_data.get('overall_comment'):\n",
    "        successful_fields += 1\n",
    "    \n",
    "    success_rate = (successful_fields / total_fields) * 100\n",
    "    \n",
    "    print(f\"ğŸ¯ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({successful_fields}/{total_fields})\")\n",
    "    \n",
    "    # ê°œì„  íš¨ê³¼ ë¶„ì„\n",
    "    improvements = []\n",
    "    \n",
    "    # ë‚´ìš© ê¸¸ì´ ê°œì„ \n",
    "    for field in ['ai_risk', 'ai_plan', 'overall_comment']:\n",
    "        before_len = len(str(before_data.get(field, ''))) if before_data.get(field) else 0\n",
    "        after_len = len(str(after_data.get(field, ''))) if after_data.get(field) else 0\n",
    "        \n",
    "        if after_len > before_len:\n",
    "            improvement = after_len - before_len\n",
    "            improvements.append(f\"{field}: +{improvement}ì\")\n",
    "    \n",
    "    if improvements:\n",
    "        print(f\"ğŸ“ˆ ê°œì„  íš¨ê³¼: {', '.join(improvements)}\")\n",
    "    \n",
    "    # JSON êµ¬ì¡° ê°œì„  ì—¬ë¶€\n",
    "    json_improvements = []\n",
    "    \n",
    "    if after_data.get('ai_risk'):\n",
    "        try:\n",
    "            risk_data = json.loads(after_data['ai_risk'])\n",
    "            if 'risk_analysis' in risk_data:\n",
    "                json_improvements.append(\"ai_risk êµ¬ì¡°í™”\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if after_data.get('ai_plan'):\n",
    "        try:\n",
    "            plan_data = json.loads(after_data['ai_plan'])\n",
    "            if 'annual_plans' in plan_data:\n",
    "                json_improvements.append(\"ai_plan êµ¬ì¡°í™”\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if json_improvements:\n",
    "        print(f\"ğŸ”§ êµ¬ì¡° ê°œì„ : {', '.join(json_improvements)}\")\n",
    "    \n",
    "    # ê¶Œì¥ ì‚¬í•­\n",
    "    print(\"\\nğŸ’¡ ê¶Œì¥ ì‚¬í•­:\")\n",
    "    if success_rate < 100:\n",
    "        print(\"   - ì‹¤íŒ¨í•œ í•„ë“œì— ëŒ€í•œ ì˜¤ë¥˜ ë¡œê·¸ í™•ì¸ í•„ìš”\")\n",
    "        print(\"   - LLM í”„ë¡¬í”„íŠ¸ ì¶”ê°€ ìµœì í™” ê³ ë ¤\")\n",
    "    \n",
    "    if success_rate >= 80:\n",
    "        print(\"   âœ… ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥\")\n",
    "        print(\"   - í”„ë¡œë•ì…˜ í™˜ê²½ ì ìš© ê³ ë ¤ ê°€ëŠ¥\")\n",
    "    elif success_rate >= 60:\n",
    "        print(\"   âš ï¸ ë¶€ë¶„ì  ì„±ê³µ - ì¶”ê°€ ê°œì„  í•„ìš”\")\n",
    "        print(\"   - ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ í›„ ì¬í…ŒìŠ¤íŠ¸ ê¶Œì¥\")\n",
    "    else:\n",
    "        print(\"   âŒ ì„±ëŠ¥ ê°œì„  í•„ìš”\")\n",
    "        print(\"   - ê¸°ë³¸ ì„¤ì • ë° í™˜ê²½ ì¬ì ê²€ í•„ìš”\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# ====================================\n",
    "# 5. ê°œë³„ êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸\n",
    "# ====================================\n",
    "\n",
    "async def test_individual_components():\n",
    "    \"\"\"ê°œë³„ êµ¬ì„±ìš”ì†Œë³„ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ§ª ê°œë³„ êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Agent ì´ˆê¸°í™”\n",
    "    agent = Module11TeamRiskManagementAgent(db_wrapper)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ìš© State ìƒì„±\n",
    "    from dataclasses import dataclass\n",
    "    \n",
    "    @dataclass\n",
    "    class TestState:\n",
    "        team_id: int = TEST_TEAM_ID\n",
    "        period_id: int = TEST_PERIOD_ID\n",
    "        team_evaluation_id: int = TEST_TEAM_EVALUATION_ID\n",
    "        is_final: bool = True\n",
    "        key_risks: list = None\n",
    "        collaboration_bias_level: str = None\n",
    "        ai_risk_result: dict = None\n",
    "    \n",
    "    state = TestState()\n",
    "    \n",
    "    # ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘\n",
    "    print(\"ğŸ“Š ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
    "    try:\n",
    "        data = agent._collect_all_data_sequential(state)\n",
    "        print(f\"   âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(data)}ê°œ ë°ì´í„°ì…‹\")\n",
    "        \n",
    "        # ê° êµ¬ì„±ìš”ì†Œë³„ í…ŒìŠ¤íŠ¸\n",
    "        print(\"\\nğŸ” í˜‘ì—… ë¦¬ìŠ¤í¬ ë¶„ì„ í…ŒìŠ¤íŠ¸...\")\n",
    "        collaboration_result = await agent._analyze_collaboration_risks_with_llm_async(\n",
    "            data.get('collaboration_matrix'), \n",
    "            data.get('team_members', [])\n",
    "        )\n",
    "        print(f\"   ê²°ê³¼: {len(collaboration_result.get('risks', []))}ê°œ í˜‘ì—… ë¦¬ìŠ¤í¬ ì‹ë³„\")\n",
    "        \n",
    "        print(\"\\nğŸ” ê°œì¸ ë¦¬ìŠ¤í¬ íŒ¨í„´ ë¶„ì„ í…ŒìŠ¤íŠ¸...\")\n",
    "        individual_result = await agent._analyze_individual_risk_patterns_with_llm_async(\n",
    "            data.get('individual_risks', []), \n",
    "            data.get('team_members', [])\n",
    "        )\n",
    "        print(f\"   ê²°ê³¼: {len(individual_result.get('risks', []))}ê°œ ê°œì¸ ë¦¬ìŠ¤í¬ ì‹ë³„\")\n",
    "        \n",
    "        print(\"\\nğŸ” ì„±ê³¼ íŠ¸ë Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸...\")\n",
    "        performance_result = await agent._analyze_performance_trends_with_llm_async(\n",
    "            data.get('team_performance', {}), \n",
    "            data.get('team_kpis', [])\n",
    "        )\n",
    "        print(f\"   ê²°ê³¼: {len(performance_result.get('risks', []))}ê°œ ì„±ê³¼ ë¦¬ìŠ¤í¬ ì‹ë³„\")\n",
    "        \n",
    "        return {\n",
    "            'collaboration': collaboration_result,\n",
    "            'individual': individual_result,\n",
    "            'performance': performance_result\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ê°œë³„ êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ====================================\n",
    "# 6. ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# ====================================\n",
    "\n",
    "async def run_all_tests():\n",
    "    \"\"\"ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Module 11 ê°œì„  ë²„ì „ ì¢…í•© í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 1. ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\n1ï¸âƒ£ ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸\")\n",
    "    integration_result = await test_improved_module11()\n",
    "    \n",
    "    # 2. ê°œë³„ êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸\n",
    "    print(\"\\n2ï¸âƒ£ ê°œë³„ êµ¬ì„±ìš”ì†Œ í…ŒìŠ¤íŠ¸\")\n",
    "    component_results = await test_individual_components()\n",
    "    \n",
    "    # 3. ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ (ì˜µì…˜)\n",
    "    print(\"\\n3ï¸âƒ£ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ vs ê°œì„ )\")\n",
    "    # ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì—¬ í‰ê·  ì„±ëŠ¥ ì¸¡ì • ê°€ëŠ¥\n",
    "    \n",
    "    print(\"\\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "    \n",
    "    return {\n",
    "        'integration': integration_result,\n",
    "        'components': component_results\n",
    "    }\n",
    "\n",
    "# ====================================\n",
    "# 7. ì‹¤í–‰ ë°©ë²•\n",
    "# ====================================\n",
    "\n",
    "\n",
    "test_results = await run_all_tests()\n",
    "\n",
    "# # ë˜ëŠ” ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# result = await test_improved_module11()\n",
    "\n",
    "# # ë˜ëŠ” êµ¬ì„±ìš”ì†Œë³„ í…ŒìŠ¤íŠ¸\n",
    "# components = await test_individual_components()\n",
    "\n",
    "\n",
    "# # Jupyter í™˜ê²½ì—ì„œ ì§ì ‘ ì‹¤í–‰\n",
    "# print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "# test_results = await run_all_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-m2V9dUhn-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
