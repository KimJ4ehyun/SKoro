{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9042665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Client initialized: gpt-4o-mini\n",
      "🚀 팀 단위 모듈 7 + 달성률 기반 CL별 정규화 준비 완료!\n",
      "\n",
      "주요 변경사항:\n",
      "✅ 기여도 → 달성률 변경 (ai_annual_achievement_rate 사용)\n",
      "✅ CL별 정규화: 4명 이상일 때만 적용, 3명 이하는 원시점수 유지\n",
      "✅ DB 저장: raw_score(원시점수) + score(정규화점수) 별도 저장\n",
      "✅ 달성률:4P 가중치 유지 (CL3:6:4, CL2:5:5, CL1:4:6)\n",
      "\n",
      "실행 명령어:\n",
      "1. run_team_module7_evaluation('TEAM001', 4)     # 단일 팀 실행\n",
      "2. run_multiple_teams_module7(['TEAM001', 'TEAM002'], 4)  # 다중 팀 실행\n",
      "3. run_module7_evaluation('E002', 4)             # 개별 실행 (호환성)\n",
      "4. test_team_module7()                           # 테스트 실행\n",
      "🧪 테스트 팀 자동 선택: 1\n",
      "🚀 팀 단위 모듈 7 + 달성률 기반 CL 정규화 실행 시작: 1 (period_id: 4)\n",
      "🔍 팀 데이터 수집 시작: 1\n",
      "   팀원 수: 4명\n",
      "   달성률 데이터: 3건\n",
      "   4P 데이터: 3건\n",
      "   분기별 데이터: 3명\n",
      "📊 달성률 통계: 평균 90.7%, 표준편차 6.4%\n",
      "🧮 개별 하이브리드 점수 계산 시작...\n",
      "   E002: 4.55점 (달성률 4.42, 4P 4.75)\n",
      "   E003: 3.72점 (달성률 3.04, 4P 4.75)\n",
      "   E004: 3.42점 (달성률 3.04, 4P 4.0)\n",
      "🔄 팀 내 CL별 정규화 시작...\n",
      "   CL별 분포: CL3(3명), CL2(0명), CL1(0명)\n",
      "\n",
      "📊 CL3 정규화 처리:\n",
      "   CL3 그룹 (3명) 정규화 처리:\n",
      "     E002: 4.55점 (원시점수 유지)\n",
      "     E003: 3.72점 (원시점수 유지)\n",
      "     E004: 3.42점 (원시점수 유지)\n",
      "\n",
      "📈 정규화 결과:\n",
      "   원시점수: 평균 3.90, 표준편차 0.59\n",
      "   정규화점수: 평균 3.90, 표준편차 0.59\n",
      "💬 정규화 후 평가 코멘트 생성 시작...\n",
      "LLM Call: E002 정규화 후 종합평가 근거 생성\n",
      "   E002: 정규화 후 코멘트 생성 완료\n",
      "LLM Call: E003 정규화 후 종합평가 근거 생성\n",
      "   E003: 정규화 후 코멘트 생성 완료\n",
      "LLM Call: E004 정규화 후 종합평가 근거 생성\n",
      "   E004: 정규화 후 코멘트 생성 완료\n",
      "💾 배치 저장 시작...\n",
      "DB 업데이트 성공: E002 (원시: 4.55, 정규화: 4.55)\n",
      "DB 업데이트 성공: E003 (원시: 3.72, 정규화: 3.72)\n",
      "DB 업데이트 성공: E004 (원시: 3.42, 정규화: 3.42)\n",
      "배치 업데이트 완료: 성공 3건, 실패 0건\n",
      "✅ 팀 단위 모듈 7 + 달성률 기반 CL 정규화 실행 완료!\n",
      "📊 결과:\n",
      "  - 팀 1: 종합평가 + CL 정규화 시작\n",
      "  - 데이터 수집 완료\n",
      "  - 통계 계산 완료\n",
      "  - 하이브리드 점수 계산 완료: 3명\n",
      "  - CL별 정규화 완료: 3명\n",
      "  - 코멘트 생성 완료: 3명\n",
      "  - 배치 저장 완료: 성공 3건\n",
      "🎯 처리 완료: 3명\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 모듈 7: 종합평가 점수 산정 모듈 + CL별 정규화 (연말 팀 단위 처리) - 수정본\n",
    "# ================================================================\n",
    "\n",
    "from typing import Annotated, List, Literal, TypedDict, Dict, Optional\n",
    "from langchain_core.messages import HumanMessage \n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import statistics\n",
    "\n",
    "# 기존 imports\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Row\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# DB 설정\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../..')))\n",
    "from config.settings import DatabaseConfig\n",
    "\n",
    "db_config = DatabaseConfig()\n",
    "DATABASE_URL = db_config.DATABASE_URL\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# LLM 클라이언트 설정\n",
    "llm_client = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(f\"LLM Client initialized: {llm_client.model_name}\")\n",
    "\n",
    "def row_to_dict(row: Row) -> Dict:\n",
    "    \"\"\"SQLAlchemy Row 객체를 딕셔너리로 변환\"\"\"\n",
    "    if row is None:\n",
    "        return {}\n",
    "    return row._asdict()\n",
    "\n",
    "def _extract_json_from_llm_response(text: str) -> str:\n",
    "    \"\"\"LLM 응답에서 JSON 블록 추출\"\"\"\n",
    "    match = re.search(r\"```(?:json)?\\s*(.*?)\\s*```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return text.strip()\n",
    "\n",
    "# ================================================================\n",
    "# TeamModule7AgentState 정의 - 팀 단위 처리\n",
    "# ================================================================\n",
    "\n",
    "class TeamModule7AgentState(TypedDict):\n",
    "    \"\"\"모듈 7 (종합평가 점수 산정) 상태 - 팀 단위 처리\"\"\"\n",
    "    messages: Annotated[List[HumanMessage], operator.add]\n",
    "    \n",
    "    # 팀 기본 정보\n",
    "    team_id: str\n",
    "    period_id: int  # 연말: 4\n",
    "    \n",
    "    # 팀 전체 데이터 (한 번에 조회)\n",
    "    team_members: List[Dict]  # 팀원 기본 정보\n",
    "    team_achievement_data: List[Dict]  # 팀 전체 달성률 데이터\n",
    "    team_fourp_data: List[Dict]  # 팀 전체 4P 데이터\n",
    "    team_quarterly_data: Dict  # 팀원별 분기 데이터\n",
    "    \n",
    "    # 통계 계산 결과 (팀 공통)\n",
    "    achievement_stats: Dict  # 평균, 표준편차 등\n",
    "    weights_by_cl: Dict  # CL별 가중치\n",
    "    \n",
    "    # 개별 계산 결과\n",
    "    individual_scores: List[Dict]  # 각 팀원별 점수\n",
    "    evaluation_comments: List[Dict]  # 각 팀원별 코멘트\n",
    "    \n",
    "    # 처리 결과\n",
    "    processed_count: int\n",
    "    failed_members: List[str]\n",
    "\n",
    "# ================================================================\n",
    "# 가중치 계산 함수\n",
    "# ================================================================\n",
    "\n",
    "def get_evaluation_weights_by_cl(cl) -> Dict[str, float]:\n",
    "    \"\"\"CL별 디폴트 가중치 반환\"\"\"\n",
    "    # CL 값을 문자열로 변환 (숫자든 문자열이든 처리)\n",
    "    if isinstance(cl, (int, float)):\n",
    "        cl_key = f\"CL{int(cl)}\"\n",
    "    else:\n",
    "        cl_key = str(cl).upper()\n",
    "        if not cl_key.startswith(\"CL\"):\n",
    "            cl_key = f\"CL{cl_key}\"\n",
    "    \n",
    "    cl_weights = {\n",
    "        \"CL3\": {\"achievement\": 0.6, \"fourp\": 0.4},\n",
    "        \"CL2\": {\"achievement\": 0.5, \"fourp\": 0.5}, \n",
    "        \"CL1\": {\"achievement\": 0.4, \"fourp\": 0.6}\n",
    "    }\n",
    "    return cl_weights.get(cl_key, {\"achievement\": 0.5, \"fourp\": 0.5})  # 기본값\n",
    "\n",
    "# ================================================================\n",
    "# CL별 정규화 관련 함수들\n",
    "# ================================================================\n",
    "\n",
    "def get_cl_normalization_params(cl) -> Dict[str, float]:\n",
    "    \"\"\"CL별 정규화 파라미터 반환 (SK 표준)\"\"\"\n",
    "    # CL 값을 문자열로 변환 (숫자든 문자열이든 처리)\n",
    "    if isinstance(cl, (int, float)):\n",
    "        cl_key = f\"CL{int(cl)}\"\n",
    "    else:\n",
    "        cl_key = str(cl).upper()\n",
    "        if not cl_key.startswith(\"CL\"):\n",
    "            cl_key = f\"CL{cl_key}\"\n",
    "    \n",
    "    params = {\n",
    "        \"CL3\": {\"target_mean\": 3.5, \"target_stdev\": 1.7},\n",
    "        \"CL2\": {\"target_mean\": 3.5, \"target_stdev\": 1.5}, \n",
    "        \"CL1\": {\"target_mean\": 3.5, \"target_stdev\": 1.4}\n",
    "    }\n",
    "    return params.get(cl_key, {\"target_mean\": 3.5, \"target_stdev\": 1.5})\n",
    "\n",
    "def normalize_cl_group(members: List[Dict], cl: str) -> List[Dict]:\n",
    "    \"\"\"CL 그룹 내 정규화 실행 (4명 이상일 때만 적용)\"\"\"\n",
    "    \n",
    "    if len(members) == 0:\n",
    "        return members\n",
    "    \n",
    "    print(f\"   {cl} 그룹 ({len(members)}명) 정규화 처리:\")\n",
    "    \n",
    "    # 3명 이하인 경우 원시점수 유지\n",
    "    if len(members) <= 3:\n",
    "        for member in members:\n",
    "            member[\"normalized_score\"] = member[\"hybrid_score\"]  # 원시점수 그대로\n",
    "            member[\"normalization_reason\"] = f\"팀 내 {cl} {len(members)}명 (원시점수 유지)\"\n",
    "            member[\"raw_hybrid_score\"] = member[\"hybrid_score\"]  # 원시점수 보관\n",
    "            print(f\"     {member['emp_no']}: {member['hybrid_score']:.2f}점 (원시점수 유지)\")\n",
    "        return members\n",
    "    \n",
    "    # 4명 이상인 경우 정규화 적용\n",
    "    # CL별 목표 파라미터\n",
    "    params = get_cl_normalization_params(cl)\n",
    "    target_mean = params[\"target_mean\"]\n",
    "    target_stdev = params[\"target_stdev\"]\n",
    "    \n",
    "    # 원시점수 수집 (하이브리드 점수)\n",
    "    raw_scores = [m[\"hybrid_score\"] for m in members]\n",
    "    \n",
    "    # 현재 통계\n",
    "    current_mean = statistics.mean(raw_scores)\n",
    "    current_stdev = statistics.stdev(raw_scores)\n",
    "    \n",
    "    print(f\"     정규화 적용: 평균 {current_mean:.2f} → {target_mean}, 표준편차 {current_stdev:.2f} → {target_stdev}\")\n",
    "    \n",
    "    # 정규화 적용\n",
    "    for member in members:\n",
    "        raw_score = member[\"hybrid_score\"]\n",
    "        \n",
    "        if current_stdev == 0:\n",
    "            # 모든 점수가 동일한 경우\n",
    "            normalized_score = target_mean\n",
    "            reason = f\"{cl} 동일점수 → 평균 {target_mean}점\"\n",
    "        else:\n",
    "            # Z-score 계산 후 목표 분포로 변환\n",
    "            z_score = (raw_score - current_mean) / current_stdev\n",
    "            normalized_score = target_mean + (z_score * target_stdev)\n",
    "            \n",
    "            # 0.0-5.0 범위 제한 (SK 기준)\n",
    "            normalized_score = max(0.0, min(5.0, normalized_score))\n",
    "            \n",
    "            reason = f\"{cl} 정규화 (Z-Score: {z_score:.2f})\"\n",
    "        \n",
    "        member[\"normalized_score\"] = round(normalized_score, 2)\n",
    "        member[\"normalization_reason\"] = reason\n",
    "        member[\"raw_hybrid_score\"] = raw_score  # 원시점수 보관\n",
    "        \n",
    "        print(f\"     {member['emp_no']}: {raw_score:.2f} → {normalized_score:.2f} ({reason})\")\n",
    "    \n",
    "    return members\n",
    "\n",
    "# ================================================================\n",
    "# 팀 단위 DB 조회 함수들\n",
    "# ================================================================\n",
    "\n",
    "def fetch_team_members(team_id: str) -> List[Dict]:\n",
    "    \"\"\"팀원 기본 정보 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT emp_no, emp_name, cl, position, team_id\n",
    "            FROM employees \n",
    "            WHERE team_id = :team_id\n",
    "            ORDER BY cl DESC, position DESC\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "def fetch_team_achievement_data(team_id: str, period_id: int) -> List[Dict]:\n",
    "    \"\"\"팀 전체 달성률 데이터 한 번에 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT fer.emp_no, fer.contribution_rate, \n",
    "                   fer.ai_annual_achievement_rate,\n",
    "                   fer.ai_annual_performance_summary_comment, \n",
    "                   fer.ai_peer_talk_summary,\n",
    "                   e.emp_name, e.cl, e.position\n",
    "            FROM final_evaluation_reports fer\n",
    "            JOIN team_evaluations te ON fer.team_evaluation_id = te.team_evaluation_id\n",
    "            JOIN employees e ON fer.emp_no = e.emp_no\n",
    "            WHERE e.team_id = :team_id AND te.period_id = :period_id\n",
    "            ORDER BY fer.ai_annual_achievement_rate DESC\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "def fetch_team_fourp_data(team_id: str, period_id: int) -> List[Dict]:\n",
    "    \"\"\"팀 전체 4P 데이터 한 번에 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT fer.emp_no, fer.ai_4p_evaluation, e.emp_name\n",
    "            FROM final_evaluation_reports fer\n",
    "            JOIN team_evaluations te ON fer.team_evaluation_id = te.team_evaluation_id\n",
    "            JOIN employees e ON fer.emp_no = e.emp_no\n",
    "            WHERE e.team_id = :team_id AND te.period_id = :period_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).fetchall()\n",
    "        \n",
    "        fourp_data = []\n",
    "        for row in results:\n",
    "            try:\n",
    "                fourp_evaluation = json.loads(row.ai_4p_evaluation) if row.ai_4p_evaluation else {}\n",
    "                fourp_data.append({\n",
    "                    \"emp_no\": row.emp_no,\n",
    "                    \"emp_name\": row.emp_name,\n",
    "                    \"fourp_results\": fourp_evaluation\n",
    "                })\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"4P JSON 파싱 실패: {row.emp_no}\")\n",
    "                fourp_data.append({\n",
    "                    \"emp_no\": row.emp_no,\n",
    "                    \"emp_name\": row.emp_name,\n",
    "                    \"fourp_results\": {}\n",
    "                })\n",
    "        \n",
    "        return fourp_data\n",
    "\n",
    "def fetch_team_quarterly_data(team_id: str, period_id: int) -> Dict:\n",
    "    \"\"\"팀 전체 분기별 Task 데이터 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT t.emp_no, ts.period_id, ts.task_id, t.task_name,\n",
    "                   ts.ai_contribution_score, ts.ai_analysis_comment_task, ts.task_performance\n",
    "            FROM task_summaries ts\n",
    "            JOIN tasks t ON ts.task_id = t.task_id\n",
    "            JOIN employees e ON t.emp_no = e.emp_no\n",
    "            WHERE e.team_id = :team_id AND ts.period_id <= :period_id\n",
    "            ORDER BY t.emp_no, ts.period_id, ts.task_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).fetchall()\n",
    "        \n",
    "        # emp_no별로 그룹화\n",
    "        quarterly_data = {}\n",
    "        for row in results:\n",
    "            emp_no = row.emp_no\n",
    "            if emp_no not in quarterly_data:\n",
    "                quarterly_data[emp_no] = []\n",
    "            quarterly_data[emp_no].append(row_to_dict(row))\n",
    "        \n",
    "        return quarterly_data\n",
    "\n",
    "def batch_update_temp_evaluations(score_data: List[Dict]) -> Dict:\n",
    "    \"\"\"팀 전체 temp_evaluations 배치 업데이트 (raw_score, score 모두 저장)\"\"\"\n",
    "    success_count = 0\n",
    "    failed_members = []\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            for data in score_data:\n",
    "                try:\n",
    "                    query = text(\"\"\"\n",
    "                        UPDATE temp_evaluations \n",
    "                        SET ai_reason = :ai_reason,\n",
    "                            raw_score = :raw_score,\n",
    "                            score = :score,\n",
    "                            comment = :comment\n",
    "                        WHERE TempEvaluation_empNo = :emp_no\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    result = connection.execute(query, {\n",
    "                        \"emp_no\": data[\"emp_no\"],\n",
    "                        \"ai_reason\": data[\"ai_reason\"],\n",
    "                        \"raw_score\": data[\"raw_score\"],  # 원시점수 저장\n",
    "                        \"score\": data[\"score\"],  # 정규화된 점수 저장\n",
    "                        \"comment\": data[\"comment\"]\n",
    "                    })\n",
    "                    \n",
    "                    if result.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                        print(f\"DB 업데이트 성공: {data['emp_no']} (원시: {data['raw_score']}, 정규화: {data['score']})\")\n",
    "                    else:\n",
    "                        failed_members.append(data[\"emp_no\"])\n",
    "                        print(f\"DB 업데이트 실패: {data['emp_no']} (행 없음)\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    failed_members.append(data[\"emp_no\"])\n",
    "                    print(f\"DB 업데이트 실패: {data['emp_no']} - {e}\")\n",
    "            \n",
    "            connection.commit()\n",
    "            print(f\"배치 업데이트 완료: 성공 {success_count}건, 실패 {len(failed_members)}건\")\n",
    "            \n",
    "            return {\n",
    "                \"success_count\": success_count,\n",
    "                \"failed_members\": failed_members\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"배치 업데이트 실패: {e}\")\n",
    "            connection.rollback()\n",
    "            return {\n",
    "                \"success_count\": 0,\n",
    "                \"failed_members\": [data[\"emp_no\"] for data in score_data]\n",
    "            }\n",
    "\n",
    "# ================================================================\n",
    "# Z-Score 달성률 점수 계산 함수\n",
    "# ================================================================\n",
    "\n",
    "def calculate_team_achievement_stats(achievement_data: List[Dict]) -> Dict:\n",
    "    \"\"\"팀 달성률 통계 계산 (Z-Score용)\"\"\"\n",
    "    achievement_rates = [data[\"ai_annual_achievement_rate\"] for data in achievement_data if data.get(\"ai_annual_achievement_rate\") is not None]\n",
    "    \n",
    "    if len(achievement_rates) <= 1:\n",
    "        return {\n",
    "            \"mean\": achievement_rates[0] if achievement_rates else 0,\n",
    "            \"stdev\": 0,\n",
    "            \"count\": len(achievement_rates),\n",
    "            \"min\": min(achievement_rates) if achievement_rates else 0,\n",
    "            \"max\": max(achievement_rates) if achievement_rates else 0\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"mean\": statistics.mean(achievement_rates),\n",
    "        \"stdev\": statistics.stdev(achievement_rates),\n",
    "        \"count\": len(achievement_rates),\n",
    "        \"min\": min(achievement_rates),\n",
    "        \"max\": max(achievement_rates)\n",
    "    }\n",
    "\n",
    "def calculate_zscore_achievement_score(achievement_rate: float, team_stats: Dict) -> tuple[float, str]:\n",
    "    \"\"\"Z-Score 방식으로 달성률 점수 계산\"\"\"\n",
    "    \n",
    "    if team_stats[\"count\"] <= 1:\n",
    "        return 3.5, \"팀원 1명 (기본 3.5점)\"\n",
    "    \n",
    "    if team_stats[\"stdev\"] == 0:\n",
    "        return 3.5, f\"팀 내 달성률 동일 ({achievement_rate:.1f}%, 기본 3.5점)\"\n",
    "    \n",
    "    # Z-Score 계산\n",
    "    z_score = (achievement_rate - team_stats[\"mean\"]) / team_stats[\"stdev\"]\n",
    "    \n",
    "    # Z-Score를 1-5점으로 변환 (평균 3.5점, 표준편차 1당 ±0.8점)\n",
    "    base_score = 3.5\n",
    "    score_range = 0.8\n",
    "    calculated_score = base_score + (z_score * score_range)\n",
    "    \n",
    "    # 1-5점 범위로 제한\n",
    "    final_score = max(1.0, min(5.0, calculated_score))\n",
    "    \n",
    "    # 성과 레벨 판정\n",
    "    if z_score > 1.5:\n",
    "        performance_level = \"매우 우수\"\n",
    "    elif z_score > 0.5:\n",
    "        performance_level = \"우수\"\n",
    "    elif z_score > -0.5:\n",
    "        performance_level = \"평균\"\n",
    "    elif z_score > -1.5:\n",
    "        performance_level = \"개선 필요\"\n",
    "    else:\n",
    "        performance_level = \"크게 개선 필요\"\n",
    "    \n",
    "    reason = f\"팀 평균 {team_stats['mean']:.1f}% 대비 Z-Score {z_score:.2f} ({performance_level})\"\n",
    "    \n",
    "    return round(final_score, 2), reason\n",
    "\n",
    "# ================================================================\n",
    "# LLM 호출 함수\n",
    "# ================================================================\n",
    "\n",
    "def call_llm_for_normalized_evaluation_comments(\n",
    "    emp_data: Dict,\n",
    "    normalized_score: float,\n",
    "    raw_hybrid_score: float,\n",
    "    achievement_score: float,\n",
    "    fourp_score: float,\n",
    "    quarterly_tasks: List[Dict],\n",
    "    fourp_results: Dict,\n",
    "    achievement_reason: str,\n",
    "    normalization_reason: str\n",
    ") -> Dict:\n",
    "    \"\"\"정규화된 점수로 ai_reason과 comment 생성\"\"\"\n",
    "    \n",
    "    emp_no = emp_data[\"emp_no\"]\n",
    "    emp_name = emp_data.get(\"emp_name\", emp_no)\n",
    "    position = emp_data.get(\"position\", \"직책 정보 없음\")\n",
    "    cl = emp_data.get(\"cl\", \"CL 정보 없음\")\n",
    "    \n",
    "    print(f\"LLM Call: {emp_no} 정규화 후 종합평가 근거 생성\")\n",
    "    \n",
    "    # 분기별 Task 요약\n",
    "    quarterly_summary = \"\"\n",
    "    for i, task in enumerate(quarterly_tasks[:8]):  # 최대 8개만 표시\n",
    "        quarterly_summary += f\"Q{task.get('period_id')}: {task.get('task_name')} - 달성률 {task.get('ai_contribution_score', 0)}점\\n\"\n",
    "        if task.get('ai_analysis_comment_task'):\n",
    "            quarterly_summary += f\"  → {task.get('ai_analysis_comment_task')}\\n\"\n",
    "    \n",
    "    if not quarterly_summary:\n",
    "        quarterly_summary = \"분기별 Task 데이터 없음\"\n",
    "    \n",
    "    # 4P 요약\n",
    "    fourp_summary = f\"\"\"\n",
    "    - Passionate: {fourp_results.get('passionate', {}).get('score', 3.0)}점\n",
    "    - Proactive: {fourp_results.get('proactive', {}).get('score', 3.0)}점  \n",
    "    - Professional: {fourp_results.get('professional', {}).get('score', 3.0)}점\n",
    "    - People: {fourp_results.get('people', {}).get('score', 3.0)}점\n",
    "    - 평균: {fourp_results.get('overall', {}).get('average_score', 3.0)}점\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    당신은 SK 조직의 종합 평가 전문가입니다.\n",
    "    정량평가(달성률)와 정성평가(4P BARS)를 종합하고 CL별 정규화를 거친 최종 점수를 바탕으로 \n",
    "    두 가지 관점의 평가 근거를 생성해주세요.\n",
    "\n",
    "    평가 기준 (SK 표준):\n",
    "    - 5.0점: 탁월한 성과 (상위 5%)\n",
    "    - 4.0-4.9점: 우수한 성과 (상위 20%)  \n",
    "    - 3.5점: 기대 수준 (평균)\n",
    "    - 3.0-3.4점: 기대 부합 (중간 60%)\n",
    "    - 2.0-2.9점: 개선 필요 (하위 15%)\n",
    "\n",
    "    두 가지 관점의 근거를 생성하세요:\n",
    "    1. ai_reason: 팀장이 보는 AI 평가 근거 (객관적, 분석적, CL별 정규화 과정 포함)\n",
    "    2. comment: 팀원이 보는 평가 근거 초안 (개인 친화적, 발전지향적, 격려 포함)\n",
    "\n",
    "    결과는 JSON 형식으로만 응답하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    human_prompt = f\"\"\"\n",
    "    <직원 정보>\n",
    "    이름: {emp_name}\n",
    "    사번: {emp_no}\n",
    "    직책: {position}\n",
    "    CL: {cl}\n",
    "    </직원 정보>\n",
    "\n",
    "    <점수 산출 과정>\n",
    "    최종 정규화 점수: {normalized_score}점\n",
    "    ├── 원시 하이브리드 점수: {raw_hybrid_score:.2f}점\n",
    "    │   ├── 달성률 점수: {achievement_score}점 ({achievement_reason})\n",
    "    │   └── 4P 점수: {fourp_score}점\n",
    "    └── CL별 정규화: {normalization_reason}\n",
    "    </점수 산출 과정>\n",
    "\n",
    "    <상세 근거 데이터>\n",
    "    연간 달성률: {emp_data.get('ai_annual_achievement_rate', 0)}%\n",
    "    성과 요약: {emp_data.get('ai_annual_performance_summary_comment', '성과 요약 없음')}\n",
    "    동료평가: {emp_data.get('ai_peer_talk_summary', '동료평가 없음')}\n",
    "    \n",
    "    4P 평가 결과:\n",
    "    {fourp_summary}\n",
    "    \n",
    "    분기별 Task 성과:\n",
    "    {quarterly_summary}\n",
    "    </상세 근거 데이터>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "        \"ai_reason\": \"[팀장용: {emp_name}({emp_no})님에 대한 객관적이고 구체적인 AI 평가 근거. 팀 내 Z-Score 결과와 CL별 정규화 과정을 포함하여 분석적 관점으로 설명]\",\n",
    "        \"comment\": \"[팀원용: {emp_name}님께 드리는 개인 친화적이고 발전지향적인 평가 근거 초안. 최종 점수 {normalized_score}점에 대한 격려와 성장 방향 포함]\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({})\n",
    "        json_output_raw = response.content\n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "        \n",
    "        ai_reason = llm_parsed_data.get(\"ai_reason\", \"\")\n",
    "        comment = llm_parsed_data.get(\"comment\", \"\")\n",
    "\n",
    "        if not ai_reason or not comment:\n",
    "            raise ValueError(\"LLM 응답에서 ai_reason 또는 comment가 누락됨\")\n",
    "\n",
    "        return {\n",
    "            \"ai_reason\": ai_reason,\n",
    "            \"comment\": comment\n",
    "        }\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}\")\n",
    "        return {\n",
    "            \"ai_reason\": f\"{emp_name}님의 정규화 후 종합 평가 근거 생성 중 오류 발생\",\n",
    "            \"comment\": f\"{emp_name}님께 드리는 정규화 후 평가 근거 생성 중 오류 발생\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 오류: {e}\")\n",
    "        return {\n",
    "            \"ai_reason\": f\"{emp_name}님의 정규화 후 종합 평가 근거 생성 중 오류 발생\",\n",
    "            \"comment\": f\"{emp_name}님께 드리는 정규화 후 평가 근거 생성 중 오류 발생\"\n",
    "        }\n",
    "\n",
    "# ================================================================\n",
    "# 팀 단위 서브모듈 함수들\n",
    "# ================================================================\n",
    "\n",
    "def team_data_collection_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"1. 팀 데이터 수집 서브모듈\"\"\"\n",
    "    \n",
    "    team_id = state[\"team_id\"]\n",
    "    period_id = state[\"period_id\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"🔍 팀 데이터 수집 시작: {team_id}\")\n",
    "        \n",
    "        # 1. 팀원 기본 정보 조회\n",
    "        team_members = fetch_team_members(team_id)\n",
    "        print(f\"   팀원 수: {len(team_members)}명\")\n",
    "        \n",
    "        # 2. 팀 전체 달성률 데이터 조회\n",
    "        team_achievement_data = fetch_team_achievement_data(team_id, period_id)\n",
    "        print(f\"   달성률 데이터: {len(team_achievement_data)}건\")\n",
    "        \n",
    "        # 3. 팀 전체 4P 데이터 조회\n",
    "        team_fourp_data = fetch_team_fourp_data(team_id, period_id)\n",
    "        print(f\"   4P 데이터: {len(team_fourp_data)}건\")\n",
    "        \n",
    "        # 4. 팀 전체 분기별 데이터 조회\n",
    "        team_quarterly_data = fetch_team_quarterly_data(team_id, period_id)\n",
    "        print(f\"   분기별 데이터: {len(team_quarterly_data)}명\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"데이터 수집 완료\")],\n",
    "            \"team_members\": team_members,\n",
    "            \"team_achievement_data\": team_achievement_data,\n",
    "            \"team_fourp_data\": team_fourp_data,\n",
    "            \"team_quarterly_data\": team_quarterly_data\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"데이터 수집 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_statistics_calculation_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"2. 팀 통계 계산 서브모듈\"\"\"\n",
    "    \n",
    "    try:\n",
    "        team_achievement_data = state[\"team_achievement_data\"]\n",
    "        team_members = state[\"team_members\"]\n",
    "        \n",
    "        # 달성률 통계 계산\n",
    "        achievement_stats = calculate_team_achievement_stats(team_achievement_data)\n",
    "        print(f\"📊 달성률 통계: 평균 {achievement_stats['mean']:.1f}%, 표준편차 {achievement_stats['stdev']:.1f}%\")\n",
    "        \n",
    "        # CL별 가중치 계산\n",
    "        weights_by_cl = {}\n",
    "        for member in team_members:\n",
    "            cl = member.get(\"cl\", \"CL2\")\n",
    "            if cl not in weights_by_cl:\n",
    "                weights_by_cl[cl] = get_evaluation_weights_by_cl(cl)\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=\"통계 계산 완료\")],\n",
    "            \"achievement_stats\": achievement_stats,\n",
    "            \"weights_by_cl\": weights_by_cl\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"통계 계산 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_score_calculation_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"3. 팀 전체 점수 계산 서브모듈 (하이브리드 원시점수)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        team_achievement_data = state[\"team_achievement_data\"]\n",
    "        team_fourp_data = state[\"team_fourp_data\"]\n",
    "        achievement_stats = state[\"achievement_stats\"]\n",
    "        weights_by_cl = state[\"weights_by_cl\"]\n",
    "        \n",
    "        individual_scores = []\n",
    "        \n",
    "        print(\"🧮 개별 하이브리드 점수 계산 시작...\")\n",
    "        \n",
    "        for achievement_data in team_achievement_data:\n",
    "            emp_no = achievement_data[\"emp_no\"]\n",
    "            cl = achievement_data.get(\"cl\", \"CL2\")\n",
    "            \n",
    "            # 가중치 조회\n",
    "            weights = weights_by_cl.get(cl, {\"achievement\": 0.5, \"fourp\": 0.5})\n",
    "            \n",
    "            # Z-Score 달성률 점수 계산\n",
    "            achievement_score, achievement_reason = calculate_zscore_achievement_score(\n",
    "                achievement_data[\"ai_annual_achievement_rate\"], \n",
    "                achievement_stats\n",
    "            )\n",
    "            \n",
    "            # 4P 점수 조회\n",
    "            fourp_data = next((fp for fp in team_fourp_data if fp[\"emp_no\"] == emp_no), {})\n",
    "            fourp_results = fourp_data.get(\"fourp_results\", {})\n",
    "            fourp_score = fourp_results.get(\"overall\", {}).get(\"average_score\", 3.0)\n",
    "            \n",
    "            # 하이브리드 점수 계산 (정규화 전 원시점수)\n",
    "            hybrid_score = (achievement_score * weights[\"achievement\"]) + (fourp_score * weights[\"fourp\"])\n",
    "            final_score = round(hybrid_score, 2)\n",
    "            \n",
    "            individual_scores.append({\n",
    "                \"emp_no\": emp_no,\n",
    "                \"emp_name\": achievement_data.get(\"emp_name\"),\n",
    "                \"cl\": cl,\n",
    "                \"achievement_score\": achievement_score,\n",
    "                \"achievement_reason\": achievement_reason,\n",
    "                \"fourp_score\": fourp_score,\n",
    "                \"hybrid_score\": final_score,  # 정규화 전 원시점수\n",
    "                \"weights\": weights,\n",
    "                \"emp_data\": achievement_data,\n",
    "                \"fourp_results\": fourp_results\n",
    "            })\n",
    "            \n",
    "            print(f\"   {emp_no}: {final_score}점 (달성률 {achievement_score}, 4P {fourp_score})\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"하이브리드 점수 계산 완료: {len(individual_scores)}명\")],\n",
    "            \"individual_scores\": individual_scores\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"점수 계산 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_normalization_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"4. 팀 내 CL별 정규화 서브모듈\"\"\"\n",
    "    \n",
    "    try:\n",
    "        individual_scores = state[\"individual_scores\"]\n",
    "        \n",
    "        print(\"🔄 팀 내 CL별 정규화 시작...\")\n",
    "        \n",
    "        # 1. CL별 그룹화 (숫자/문자열 모두 처리)\n",
    "        cl_groups = {\n",
    "            \"CL1\": [],\n",
    "            \"CL2\": [], \n",
    "            \"CL3\": []\n",
    "        }\n",
    "        \n",
    "        for score in individual_scores:\n",
    "            cl_raw = score.get(\"cl\", 2)  # 기본값 2\n",
    "            \n",
    "            # CL 값 정규화\n",
    "            if isinstance(cl_raw, (int, float)):\n",
    "                cl = f\"CL{int(cl_raw)}\"\n",
    "            else:\n",
    "                cl = str(cl_raw).upper()\n",
    "                if not cl.startswith(\"CL\"):\n",
    "                    cl = f\"CL{cl}\"\n",
    "            \n",
    "            # 유효한 CL인지 확인\n",
    "            if cl in cl_groups:\n",
    "                cl_groups[cl].append(score)\n",
    "                score[\"cl\"] = cl  # 정규화된 CL 값으로 업데이트\n",
    "            else:\n",
    "                print(f\"⚠️ 알 수 없는 CL: {cl_raw} → CL2로 처리\")\n",
    "                cl_groups[\"CL2\"].append(score)\n",
    "                score[\"cl\"] = \"CL2\"\n",
    "        \n",
    "        print(f\"   CL별 분포: CL3({len(cl_groups['CL3'])}명), CL2({len(cl_groups['CL2'])}명), CL1({len(cl_groups['CL1'])}명)\")\n",
    "        \n",
    "        # 2. CL별 정규화 실행 (4명 이상일 때만)\n",
    "        normalized_scores = []\n",
    "        \n",
    "        for cl, members in cl_groups.items():\n",
    "            if len(members) > 0:\n",
    "                print(f\"\\n📊 {cl} 정규화 처리:\")\n",
    "                normalized_members = normalize_cl_group(members, cl)\n",
    "                normalized_scores.extend(normalized_members)\n",
    "        \n",
    "        # 3. 정규화 통계 출력\n",
    "        raw_scores = [s[\"hybrid_score\"] for s in individual_scores]\n",
    "        norm_scores = [s[\"normalized_score\"] for s in normalized_scores]\n",
    "        \n",
    "        print(f\"\\n📈 정규화 결과:\")\n",
    "        print(f\"   원시점수: 평균 {statistics.mean(raw_scores):.2f}, 표준편차 {statistics.stdev(raw_scores) if len(raw_scores) > 1 else 0:.2f}\")\n",
    "        print(f\"   정규화점수: 평균 {statistics.mean(norm_scores):.2f}, 표준편차 {statistics.stdev(norm_scores) if len(norm_scores) > 1 else 0:.2f}\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"CL별 정규화 완료: {len(normalized_scores)}명\")],\n",
    "            \"individual_scores\": normalized_scores\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"정규화 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_comment_generation_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"5. 팀 전체 코멘트 생성 서브모듈 (정규화된 점수 기준)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        individual_scores = state[\"individual_scores\"]\n",
    "        team_quarterly_data = state[\"team_quarterly_data\"]\n",
    "        \n",
    "        evaluation_comments = []\n",
    "        \n",
    "        print(\"💬 정규화 후 평가 코멘트 생성 시작...\")\n",
    "        \n",
    "        for score_data in individual_scores:\n",
    "            emp_no = score_data[\"emp_no\"]\n",
    "            quarterly_tasks = team_quarterly_data.get(emp_no, [])\n",
    "            \n",
    "            # LLM을 통한 정규화 후 코멘트 생성\n",
    "            llm_result = call_llm_for_normalized_evaluation_comments(\n",
    "                emp_data=score_data[\"emp_data\"],\n",
    "                normalized_score=score_data[\"normalized_score\"],\n",
    "                raw_hybrid_score=score_data[\"raw_hybrid_score\"],\n",
    "                achievement_score=score_data[\"achievement_score\"],\n",
    "                fourp_score=score_data[\"fourp_score\"],\n",
    "                quarterly_tasks=quarterly_tasks,\n",
    "                fourp_results=score_data[\"fourp_results\"],\n",
    "                achievement_reason=score_data[\"achievement_reason\"],\n",
    "                normalization_reason=score_data[\"normalization_reason\"]\n",
    "            )\n",
    "            \n",
    "            evaluation_comments.append({\n",
    "                \"emp_no\": emp_no,\n",
    "                \"emp_name\": score_data.get(\"emp_name\"),\n",
    "                \"raw_score\": score_data[\"raw_hybrid_score\"],  # 원시점수\n",
    "                \"score\": score_data[\"normalized_score\"],  # 정규화된 점수\n",
    "                \"ai_reason\": llm_result[\"ai_reason\"],\n",
    "                \"comment\": llm_result[\"comment\"]\n",
    "            })\n",
    "            \n",
    "            print(f\"   {emp_no}: 정규화 후 코멘트 생성 완료\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"코멘트 생성 완료: {len(evaluation_comments)}명\")],\n",
    "            \"evaluation_comments\": evaluation_comments\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"코멘트 생성 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_batch_storage_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"6. 팀 배치 저장 서브모듈\"\"\"\n",
    "    \n",
    "    try:\n",
    "        evaluation_comments = state[\"evaluation_comments\"]\n",
    "        \n",
    "        print(\"💾 배치 저장 시작...\")\n",
    "        \n",
    "        # 배치 업데이트 실행\n",
    "        update_result = batch_update_temp_evaluations(evaluation_comments)\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"배치 저장 완료: 성공 {update_result['success_count']}건\")],\n",
    "            \"processed_count\": update_result[\"success_count\"],\n",
    "            \"failed_members\": update_result[\"failed_members\"]\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"배치 저장 실패: {str(e)}\")],\n",
    "            \"processed_count\": 0,\n",
    "            \"failed_members\": []\n",
    "        })\n",
    "        raise e\n",
    "\n",
    "# ================================================================\n",
    "# 팀 단위 워크플로우 생성\n",
    "# ================================================================\n",
    "\n",
    "def create_team_module7_graph():\n",
    "    \"\"\"팀 단위 모듈 7 그래프 생성 및 반환 (CL 정규화 포함)\"\"\"\n",
    "    team_module7_workflow = StateGraph(TeamModule7AgentState)\n",
    "    \n",
    "    # 노드 추가\n",
    "    team_module7_workflow.add_node(\"team_data_collection\", team_data_collection_submodule)\n",
    "    team_module7_workflow.add_node(\"team_statistics\", team_statistics_calculation_submodule)\n",
    "    team_module7_workflow.add_node(\"team_score_calculation\", team_score_calculation_submodule)\n",
    "    team_module7_workflow.add_node(\"team_normalization\", team_normalization_submodule)\n",
    "    team_module7_workflow.add_node(\"team_comment_generation\", team_comment_generation_submodule)\n",
    "    team_module7_workflow.add_node(\"team_batch_storage\", team_batch_storage_submodule)\n",
    "    \n",
    "    # 엣지 정의 (순차 실행)\n",
    "    team_module7_workflow.add_edge(START, \"team_data_collection\")\n",
    "    team_module7_workflow.add_edge(\"team_data_collection\", \"team_statistics\")\n",
    "    team_module7_workflow.add_edge(\"team_statistics\", \"team_score_calculation\")\n",
    "    team_module7_workflow.add_edge(\"team_score_calculation\", \"team_normalization\")\n",
    "    team_module7_workflow.add_edge(\"team_normalization\", \"team_comment_generation\")\n",
    "    team_module7_workflow.add_edge(\"team_comment_generation\", \"team_batch_storage\")\n",
    "    team_module7_workflow.add_edge(\"team_batch_storage\", END)\n",
    "    \n",
    "    return team_module7_workflow.compile()\n",
    "\n",
    "# ================================================================\n",
    "# 실행 함수들\n",
    "# ================================================================\n",
    "\n",
    "def run_team_module7_evaluation(team_id: str, period_id: int = 4):\n",
    "    \"\"\"팀 단위 모듈 7 연말 종합평가 실행 (달성률 기반 + CL 정규화 포함)\"\"\"\n",
    "    \n",
    "    print(f\"🚀 팀 단위 모듈 7 + 달성률 기반 CL 정규화 실행 시작: {team_id} (period_id: {period_id})\")\n",
    "    \n",
    "    # State 정의\n",
    "    state = TeamModule7AgentState(\n",
    "        messages=[HumanMessage(content=f\"팀 {team_id}: 종합평가 + CL 정규화 시작\")],\n",
    "        team_id=team_id,\n",
    "        period_id=period_id,\n",
    "        team_members=[],\n",
    "        team_achievement_data=[],\n",
    "        team_fourp_data=[],\n",
    "        team_quarterly_data={},\n",
    "        achievement_stats={},\n",
    "        weights_by_cl={},\n",
    "        individual_scores=[],\n",
    "        evaluation_comments=[],\n",
    "        processed_count=0,\n",
    "        failed_members=[]\n",
    "    )\n",
    "    \n",
    "    # 그래프 생성 및 실행\n",
    "    team_module7_graph = create_team_module7_graph()\n",
    "    \n",
    "    try:\n",
    "        result = team_module7_graph.invoke(state)\n",
    "        \n",
    "        print(\"✅ 팀 단위 모듈 7 + 달성률 기반 CL 정규화 실행 완료!\")\n",
    "        print(f\"📊 결과:\")\n",
    "        for message in result['messages']:\n",
    "            print(f\"  - {message.content}\")\n",
    "        \n",
    "        if result.get('processed_count'):\n",
    "            print(f\"🎯 처리 완료: {result['processed_count']}명\")\n",
    "            if result.get('failed_members'):\n",
    "                print(f\"❌ 실패한 팀원: {result['failed_members']}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 팀 단위 모듈 7 + 달성률 기반 CL 정규화 실행 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_multiple_teams_module7(team_ids: List[str], period_id: int = 4):\n",
    "    \"\"\"여러 팀 일괄 실행\"\"\"\n",
    "    print(f\"🚀 다중 팀 모듈 7 + 달성률 기반 CL 정규화 실행: {len(team_ids)}개 팀\")\n",
    "    \n",
    "    results = {}\n",
    "    total_processed = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    for team_id in team_ids:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"팀 {team_id} 처리 중...\")\n",
    "        \n",
    "        result = run_team_module7_evaluation(team_id, period_id)\n",
    "        results[team_id] = result\n",
    "        \n",
    "        if result:\n",
    "            total_processed += result.get('processed_count', 0)\n",
    "            total_failed += len(result.get('failed_members', []))\n",
    "    \n",
    "    print(f\"\\n🎯 전체 결과:\")\n",
    "    print(f\"   처리된 팀: {len([r for r in results.values() if r is not None])}/{len(team_ids)}\")\n",
    "    print(f\"   처리된 인원: {total_processed}명\")\n",
    "    print(f\"   실패한 인원: {total_failed}명\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================\n",
    "# 개별 실행 호환 함수 (기존 코드 호환성)\n",
    "# ================================================================\n",
    "\n",
    "def run_module7_evaluation(emp_no: str, period_id: int = 4):\n",
    "    \"\"\"개별 실행 (기존 호환성을 위한 래퍼 함수)\"\"\"\n",
    "    # 직원의 팀 ID 조회\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT team_id FROM employees WHERE emp_no = :emp_no\")\n",
    "        result = connection.execute(query, {\"emp_no\": emp_no}).fetchone()\n",
    "        \n",
    "        if not result:\n",
    "            print(f\"❌ 직원 정보 없음: {emp_no}\")\n",
    "            return None\n",
    "        \n",
    "        team_id = result.team_id\n",
    "    \n",
    "    print(f\"🔄 개별 실행을 팀 단위로 변환: {emp_no} → 팀 {team_id}\")\n",
    "    \n",
    "    # 팀 단위로 실행\n",
    "    return run_team_module7_evaluation(team_id, period_id)\n",
    "\n",
    "# ================================================================\n",
    "# 테스트 및 디버깅 함수들\n",
    "# ================================================================\n",
    "\n",
    "def get_all_teams_with_data(period_id: int = 4) -> List[str]:\n",
    "    \"\"\"평가 데이터가 있는 모든 팀 ID 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT DISTINCT e.team_id\n",
    "            FROM employees e\n",
    "            JOIN final_evaluation_reports fer ON e.emp_no = fer.emp_no\n",
    "            JOIN team_evaluations te ON fer.team_evaluation_id = te.team_evaluation_id\n",
    "            WHERE te.period_id = :period_id\n",
    "            ORDER BY e.team_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"period_id\": period_id}).fetchall()\n",
    "        return [row.team_id for row in results]\n",
    "\n",
    "def test_team_module7(team_id: str = None, period_id: int = 4):\n",
    "    \"\"\"팀 모듈 7 + 달성률 기반 CL 정규화 테스트\"\"\"\n",
    "    if not team_id:\n",
    "        teams = get_all_teams_with_data(period_id)\n",
    "        if teams:\n",
    "            team_id = teams[0]\n",
    "            print(f\"🧪 테스트 팀 자동 선택: {team_id}\")\n",
    "        else:\n",
    "            print(\"❌ 테스트할 팀이 없습니다\")\n",
    "            return\n",
    "    \n",
    "    return run_team_module7_evaluation(team_id, period_id)\n",
    "\n",
    "# ================================================================\n",
    "# 실행 예시\n",
    "# ================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 팀 단위 모듈 7 + 달성률 기반 CL별 정규화 준비 완료!\")\n",
    "    print(\"\\n주요 변경사항:\")\n",
    "    print(\"✅ 기여도 → 달성률 변경 (ai_annual_achievement_rate 사용)\")\n",
    "    print(\"✅ CL별 정규화: 4명 이상일 때만 적용, 3명 이하는 원시점수 유지\")\n",
    "    print(\"✅ DB 저장: raw_score(원시점수) + score(정규화점수) 별도 저장\")\n",
    "    print(\"✅ 달성률:4P 가중치 유지 (CL3:6:4, CL2:5:5, CL1:4:6)\")\n",
    "    \n",
    "    print(\"\\n실행 명령어:\")\n",
    "    print(\"1. run_team_module7_evaluation('TEAM001', 4)     # 단일 팀 실행\")\n",
    "    print(\"2. run_multiple_teams_module7(['TEAM001', 'TEAM002'], 4)  # 다중 팀 실행\")\n",
    "    print(\"3. run_module7_evaluation('E002', 4)             # 개별 실행 (호환성)\")\n",
    "    print(\"4. test_team_module7()                           # 테스트 실행\")\n",
    "    \n",
    "    # 자동 테스트 (필요시 주석 해제)\n",
    "    test_team_module7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62117047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e1a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513a663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3699f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Client initialized: gpt-4o-mini\n",
      "🚀 팀 단위 모듈 7 + SK 등급 기반 절대평가 + CL별 정규화 준비 완료!\n",
      "\\n🔥 주요 변경사항:\n",
      "✅ SK 등급 체계 기반 절대평가 (S/A/B/C/D → 1-5점)\n",
      "✅ 달성률 100% = 3.5점, 120% = 5.0점 명확한 기준\n",
      "✅ CL별 정규화: 4명 이상일 때만 적용, 3명 이하는 원시점수 유지\n",
      "✅ DB 저장: raw_score(원시점수) + score(정규화점수) 별도 저장\n",
      "✅ 달성률:4P 가중치 유지 (CL3:6:4, CL2:5:5, CL1:4:6)\n",
      "\\n실행 명령어:\n",
      "1. run_team_module7_evaluation('TEAM001', 4)     # 단일 팀 실행\n",
      "2. run_multiple_teams_module7(['TEAM001', 'TEAM002'], 4)  # 다중 팀 실행\n",
      "3. run_module7_evaluation('E002', 4)             # 개별 실행 (호환성)\n",
      "4. test_team_module7()                           # 테스트 실행\n",
      "5. preview_achievement_scoring()                 # 점수 체계 미리보기\n",
      "📋 SK 등급 기반 절대평가 점수 체계:\n",
      "============================================================\n",
      "달성률   0% → 1.00점 (D등급)\n",
      "달성률  30% → 1.25점 (D등급)\n",
      "달성률  50% → 1.42점 (D등급)\n",
      "달성률  70% → 2.00점 (C등급)\n",
      "달성률  85% → 2.75점 (B등급)\n",
      "달성률  95% → 3.25점 (B등급)\n",
      "달성률 100% → 3.50점 (A등급)\n",
      "달성률 105% → 3.75점 (A등급)\n",
      "달성률 115% → 4.50점 (S등급)\n",
      "달성률 125% → 5.00점 (S+등급)\n",
      "달성률 150% → 5.00점 (S+등급)\n",
      "달성률 200% → 5.00점 (S+등급)\n",
      "============================================================\n",
      "🧪 테스트 팀 자동 선택: 1\n",
      "🚀 팀 단위 모듈 7 + SK 등급 기반 절대평가 + CL 정규화 실행 시작: 1 (period_id: 4)\n",
      "🔍 팀 데이터 수집 시작: 1\n",
      "   팀원 수: 4명\n",
      "   달성률 데이터: 3건\n",
      "   4P 데이터: 3건\n",
      "   분기별 데이터: 3명\n",
      "📊 CL별 가중치 설정 완료: [4, 3]\n",
      "🧮 SK 등급 기반 절대평가 점수 계산 시작...\n",
      "   E002: 3.24점 (달성률 3.4, 4P 3.0) - 달성률 98.0% (B등급, 목표 근접)\n",
      "   E003: 2.91점 (달성률 2.85, 4P 3.0) - 달성률 87.0% (B등급, 목표 근접)\n",
      "   E004: 2.91점 (달성률 2.85, 4P 3.0) - 달성률 87.0% (B등급, 목표 근접)\n",
      "🔄 팀 내 CL별 정규화 시작...\n",
      "   CL별 분포: CL3(3명), CL2(0명), CL1(0명)\n",
      "\\n📊 CL3 정규화 처리:\n",
      "   CL3 그룹 (3명) 정규화 처리:\n",
      "     E002: 3.24점 (원시점수 유지)\n",
      "     E003: 2.91점 (원시점수 유지)\n",
      "     E004: 2.91점 (원시점수 유지)\n",
      "\\n📈 정규화 결과:\n",
      "   원시점수: 평균 3.02, 표준편차 0.19\n",
      "   정규화점수: 평균 3.02, 표준편차 0.19\n",
      "💬 정규화 후 평가 코멘트 생성 시작...\n",
      "LLM Call: E002 정규화 후 종합평가 근거 생성\n",
      "LLM 응답 JSON 파싱 오류: Expecting value: line 1 column 1 (char 0)\n",
      "   E002: 정규화 후 코멘트 생성 완료\n",
      "LLM Call: E003 정규화 후 종합평가 근거 생성\n",
      "LLM 응답 JSON 파싱 오류: Expecting value: line 1 column 1 (char 0)\n",
      "   E003: 정규화 후 코멘트 생성 완료\n",
      "LLM Call: E004 정규화 후 종합평가 근거 생성\n",
      "LLM 응답 JSON 파싱 오류: Expecting value: line 1 column 1 (char 0)\n",
      "   E004: 정규화 후 코멘트 생성 완료\n",
      "💾 배치 저장 시작...\n",
      "DB 업데이트 성공: E002 (원시: 3.24, 정규화: 3.24)\n",
      "DB 업데이트 성공: E003 (원시: 2.91, 정규화: 2.91)\n",
      "DB 업데이트 성공: E004 (원시: 2.91, 정규화: 2.91)\n",
      "배치 업데이트 완료: 성공 3건, 실패 0건\n",
      "✅ 팀 단위 모듈 7 + SK 등급 기반 절대평가 + CL 정규화 실행 완료!\n",
      "📊 결과:\n",
      "  - 팀 1: SK 등급 기반 종합평가 + CL 정규화 시작\n",
      "  - 데이터 수집 완료\n",
      "  - 가중치 계산 완료\n",
      "  - 절대평가 점수 계산 완료: 3명\n",
      "  - CL별 정규화 완료: 3명\n",
      "  - 코멘트 생성 완료: 3명\n",
      "  - 배치 저장 완료: 성공 3건\n",
      "🎯 처리 완료: 3명\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 모듈 7: 종합평가 점수 산정 모듈 + CL별 정규화 (연말 팀 단위 처리) - SK 등급 기반 절대평가\n",
    "# ================================================================\n",
    "\n",
    "from typing import Annotated, List, Literal, TypedDict, Dict, Optional\n",
    "from langchain_core.messages import HumanMessage \n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import statistics\n",
    "\n",
    "# 기존 imports\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Row\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# DB 설정\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../../..')))\n",
    "from config.settings import DatabaseConfig\n",
    "\n",
    "db_config = DatabaseConfig()\n",
    "DATABASE_URL = db_config.DATABASE_URL\n",
    "engine = create_engine(DATABASE_URL, pool_pre_ping=True)\n",
    "\n",
    "# LLM 클라이언트 설정\n",
    "llm_client = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(f\"LLM Client initialized: {llm_client.model_name}\")\n",
    "\n",
    "def row_to_dict(row: Row) -> Dict:\n",
    "    \"\"\"SQLAlchemy Row 객체를 딕셔너리로 변환\"\"\"\n",
    "    if row is None:\n",
    "        return {}\n",
    "    return row._asdict()\n",
    "\n",
    "def _extract_json_from_llm_response(text: str) -> str:\n",
    "    \"\"\"LLM 응답에서 JSON 블록 추출\"\"\"\n",
    "    match = re.search(r\"```(?:json)?\\\\s*(.*?)\\\\s*```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return text.strip()\n",
    "\n",
    "# ================================================================\n",
    "# TeamModule7AgentState 정의 - 팀 단위 처리\n",
    "# ================================================================\n",
    "\n",
    "class TeamModule7AgentState(TypedDict):\n",
    "    \"\"\"모듈 7 (종합평가 점수 산정) 상태 - 팀 단위 처리\"\"\"\n",
    "    messages: Annotated[List[HumanMessage], operator.add]\n",
    "    \n",
    "    # 팀 기본 정보\n",
    "    team_id: str\n",
    "    period_id: int  # 연말: 4\n",
    "    \n",
    "    # 팀 전체 데이터 (한 번에 조회)\n",
    "    team_members: List[Dict]  # 팀원 기본 정보\n",
    "    team_achievement_data: List[Dict]  # 팀 전체 달성률 데이터\n",
    "    team_fourp_data: List[Dict]  # 팀 전체 4P 데이터\n",
    "    team_quarterly_data: Dict  # 팀원별 분기 데이터\n",
    "    \n",
    "    # 통계 계산 결과 (팀 공통)\n",
    "    weights_by_cl: Dict  # CL별 가중치\n",
    "    \n",
    "    # 개별 계산 결과\n",
    "    individual_scores: List[Dict]  # 각 팀원별 점수\n",
    "    evaluation_comments: List[Dict]  # 각 팀원별 코멘트\n",
    "    \n",
    "    # 처리 결과\n",
    "    processed_count: int\n",
    "    failed_members: List[str]\n",
    "\n",
    "# ================================================================\n",
    "# 가중치 계산 함수\n",
    "# ================================================================\n",
    "\n",
    "def get_evaluation_weights_by_cl(cl) -> Dict[str, float]:\n",
    "    \"\"\"CL별 디폴트 가중치 반환\"\"\"\n",
    "    # CL 값을 문자열로 변환 (숫자든 문자열이든 처리)\n",
    "    if isinstance(cl, (int, float)):\n",
    "        cl_key = f\"CL{int(cl)}\"\n",
    "    else:\n",
    "        cl_key = str(cl).upper()\n",
    "        if not cl_key.startswith(\"CL\"):\n",
    "            cl_key = f\"CL{cl_key}\"\n",
    "    \n",
    "    cl_weights = {\n",
    "        \"CL3\": {\"achievement\": 0.6, \"fourp\": 0.4},\n",
    "        \"CL2\": {\"achievement\": 0.5, \"fourp\": 0.5}, \n",
    "        \"CL1\": {\"achievement\": 0.4, \"fourp\": 0.6}\n",
    "    }\n",
    "    return cl_weights.get(cl_key, {\"achievement\": 0.5, \"fourp\": 0.5})  # 기본값\n",
    "\n",
    "# ================================================================\n",
    "# SK 등급 기반 절대평가 달성률 점수 계산 함수\n",
    "# ================================================================\n",
    "\n",
    "def calculate_achievement_score_by_grade(achievement_rate: float) -> tuple[float, str]:\n",
    "    \"\"\"SK 등급 체계 기반 절대평가 점수 계산\"\"\"\n",
    "    \n",
    "    if achievement_rate >= 120:\n",
    "        # S등급 상한 (120% 이상) → 5.0점\n",
    "        score = 5.0\n",
    "        grade = \"S+\"\n",
    "        reason = f\"달성률 {achievement_rate:.1f}% (S+등급, 탁월한 성과)\"\n",
    "        \n",
    "    elif achievement_rate >= 110:\n",
    "        # S등급 (110-120%) → 4.0-5.0점 선형 배치\n",
    "        progress = (achievement_rate - 110) / 10  # 0~1 사이 값\n",
    "        score = 4.0 + (progress * 1.0)  # 4.0 ~ 5.0\n",
    "        grade = \"S\"\n",
    "        reason = f\"달성률 {achievement_rate:.1f}% (S등급, 매우 우수한 성과)\"\n",
    "        \n",
    "    elif achievement_rate >= 100:\n",
    "        # A등급 (100-110%) → 3.5-4.0점 선형 배치  \n",
    "        progress = (achievement_rate - 100) / 10  # 0~1 사이 값\n",
    "        score = 3.5 + (progress * 0.5)  # 3.5 ~ 4.0\n",
    "        grade = \"A\"\n",
    "        reason = f\"달성률 {achievement_rate:.1f}% (A등급, 목표 달성)\"\n",
    "        \n",
    "    elif achievement_rate >= 80:\n",
    "        # B등급 (80-100%) → 2.5-3.5점 선형 배치\n",
    "        progress = (achievement_rate - 80) / 20  # 0~1 사이 값  \n",
    "        score = 2.5 + (progress * 1.0)  # 2.5 ~ 3.5\n",
    "        grade = \"B\"\n",
    "        reason = f\"달성률 {achievement_rate:.1f}% (B등급, 목표 근접)\"\n",
    "        \n",
    "    elif achievement_rate >= 60:\n",
    "        # C등급 (60-80%) → 1.5-2.5점 선형 배치\n",
    "        progress = (achievement_rate - 60) / 20  # 0~1 사이 값\n",
    "        score = 1.5 + (progress * 1.0)  # 1.5 ~ 2.5\n",
    "        grade = \"C\"\n",
    "        reason = f\"달성률 {achievement_rate:.1f}% (C등급, 목표 미달)\"\n",
    "        \n",
    "    else:\n",
    "        # D등급 (60% 미만) → 1.0-1.5점 선형 배치\n",
    "        if achievement_rate <= 0:\n",
    "            score = 1.0\n",
    "        else:\n",
    "            progress = achievement_rate / 60  # 0~1 사이 값\n",
    "            score = 1.0 + (progress * 0.5)  # 1.0 ~ 1.5\n",
    "        grade = \"D\"\n",
    "        reason = f\"달성률 {achievement_rate:.1f}% (D등급, 크게 미달)\"\n",
    "    \n",
    "    return round(score, 2), reason\n",
    "\n",
    "# ================================================================\n",
    "# CL별 정규화 관련 함수들\n",
    "# ================================================================\n",
    "\n",
    "def get_cl_normalization_params(cl) -> Dict[str, float]:\n",
    "    \"\"\"CL별 정규화 파라미터 반환 (SK 표준)\"\"\"\n",
    "    # CL 값을 문자열로 변환 (숫자든 문자열이든 처리)\n",
    "    if isinstance(cl, (int, float)):\n",
    "        cl_key = f\"CL{int(cl)}\"\n",
    "    else:\n",
    "        cl_key = str(cl).upper()\n",
    "        if not cl_key.startswith(\"CL\"):\n",
    "            cl_key = f\"CL{cl_key}\"\n",
    "    \n",
    "    params = {\n",
    "        \"CL3\": {\"target_mean\": 3.5, \"target_stdev\": 1.7},\n",
    "        \"CL2\": {\"target_mean\": 3.5, \"target_stdev\": 1.5}, \n",
    "        \"CL1\": {\"target_mean\": 3.5, \"target_stdev\": 1.4}\n",
    "    }\n",
    "    return params.get(cl_key, {\"target_mean\": 3.5, \"target_stdev\": 1.5})\n",
    "\n",
    "def normalize_cl_group(members: List[Dict], cl: str) -> List[Dict]:\n",
    "    \"\"\"CL 그룹 내 정규화 실행 (4명 이상일 때만 적용)\"\"\"\n",
    "    \n",
    "    if len(members) == 0:\n",
    "        return members\n",
    "    \n",
    "    print(f\"   {cl} 그룹 ({len(members)}명) 정규화 처리:\")\n",
    "    \n",
    "    # 3명 이하인 경우 원시점수 유지\n",
    "    if len(members) <= 3:\n",
    "        for member in members:\n",
    "            member[\"normalized_score\"] = member[\"hybrid_score\"]  # 원시점수 그대로\n",
    "            member[\"normalization_reason\"] = f\"팀 내 {cl} {len(members)}명 (원시점수 유지)\"\n",
    "            member[\"raw_hybrid_score\"] = member[\"hybrid_score\"]  # 원시점수 보관\n",
    "            print(f\"     {member['emp_no']}: {member['hybrid_score']:.2f}점 (원시점수 유지)\")\n",
    "        return members\n",
    "    \n",
    "    # 4명 이상인 경우 정규화 적용\n",
    "    # CL별 목표 파라미터\n",
    "    params = get_cl_normalization_params(cl)\n",
    "    target_mean = params[\"target_mean\"]\n",
    "    target_stdev = params[\"target_stdev\"]\n",
    "    \n",
    "    # 원시점수 수집 (하이브리드 점수)\n",
    "    raw_scores = [m[\"hybrid_score\"] for m in members]\n",
    "    \n",
    "    # 현재 통계\n",
    "    current_mean = statistics.mean(raw_scores)\n",
    "    current_stdev = statistics.stdev(raw_scores)\n",
    "    \n",
    "    print(f\"     정규화 적용: 평균 {current_mean:.2f} → {target_mean}, 표준편차 {current_stdev:.2f} → {target_stdev}\")\n",
    "    \n",
    "    # 정규화 적용\n",
    "    for member in members:\n",
    "        raw_score = member[\"hybrid_score\"]\n",
    "        \n",
    "        if current_stdev == 0:\n",
    "            # 모든 점수가 동일한 경우\n",
    "            normalized_score = target_mean\n",
    "            reason = f\"{cl} 동일점수 → 평균 {target_mean}점\"\n",
    "        else:\n",
    "            # Z-score 계산 후 목표 분포로 변환\n",
    "            z_score = (raw_score - current_mean) / current_stdev\n",
    "            normalized_score = target_mean + (z_score * target_stdev)\n",
    "            \n",
    "            # 0.0-5.0 범위 제한 (SK 기준)\n",
    "            normalized_score = max(0.0, min(5.0, normalized_score))\n",
    "            \n",
    "            reason = f\"{cl} 정규화 (Z-Score: {z_score:.2f})\"\n",
    "        \n",
    "        member[\"normalized_score\"] = round(normalized_score, 2)\n",
    "        member[\"normalization_reason\"] = reason\n",
    "        member[\"raw_hybrid_score\"] = raw_score  # 원시점수 보관\n",
    "        \n",
    "        print(f\"     {member['emp_no']}: {raw_score:.2f} → {normalized_score:.2f} ({reason})\")\n",
    "    \n",
    "    return members\n",
    "\n",
    "# ================================================================\n",
    "# 팀 단위 DB 조회 함수들\n",
    "# ================================================================\n",
    "\n",
    "def fetch_team_members(team_id: str) -> List[Dict]:\n",
    "    \"\"\"팀원 기본 정보 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT emp_no, emp_name, cl, position, team_id\n",
    "            FROM employees \n",
    "            WHERE team_id = :team_id\n",
    "            ORDER BY cl DESC, position DESC\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "def fetch_team_achievement_data(team_id: str, period_id: int) -> List[Dict]:\n",
    "    \"\"\"팀 전체 달성률 데이터 한 번에 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT fer.emp_no, fer.contribution_rate, \n",
    "                   fer.ai_annual_achievement_rate,\n",
    "                   fer.ai_annual_performance_summary_comment, \n",
    "                   fer.ai_peer_talk_summary,\n",
    "                   e.emp_name, e.cl, e.position\n",
    "            FROM final_evaluation_reports fer\n",
    "            JOIN team_evaluations te ON fer.team_evaluation_id = te.team_evaluation_id\n",
    "            JOIN employees e ON fer.emp_no = e.emp_no\n",
    "            WHERE e.team_id = :team_id AND te.period_id = :period_id\n",
    "            ORDER BY fer.ai_annual_achievement_rate DESC\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).fetchall()\n",
    "        return [row_to_dict(row) for row in results]\n",
    "\n",
    "def fetch_team_fourp_data(team_id: str, period_id: int) -> List[Dict]:\n",
    "    \"\"\"팀 전체 4P 데이터 한 번에 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT fer.emp_no, fer.ai_4p_evaluation, e.emp_name\n",
    "            FROM final_evaluation_reports fer\n",
    "            JOIN team_evaluations te ON fer.team_evaluation_id = te.team_evaluation_id\n",
    "            JOIN employees e ON fer.emp_no = e.emp_no\n",
    "            WHERE e.team_id = :team_id AND te.period_id = :period_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).fetchall()\n",
    "        \n",
    "        fourp_data = []\n",
    "        for row in results:\n",
    "            try:\n",
    "                fourp_evaluation = json.loads(row.ai_4p_evaluation) if row.ai_4p_evaluation else {}\n",
    "                fourp_data.append({\n",
    "                    \"emp_no\": row.emp_no,\n",
    "                    \"emp_name\": row.emp_name,\n",
    "                    \"fourp_results\": fourp_evaluation\n",
    "                })\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"4P JSON 파싱 실패: {row.emp_no}\")\n",
    "                fourp_data.append({\n",
    "                    \"emp_no\": row.emp_no,\n",
    "                    \"emp_name\": row.emp_name,\n",
    "                    \"fourp_results\": {}\n",
    "                })\n",
    "        \n",
    "        return fourp_data\n",
    "\n",
    "def fetch_team_quarterly_data(team_id: str, period_id: int) -> Dict:\n",
    "    \"\"\"팀 전체 분기별 Task 데이터 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT t.emp_no, ts.period_id, ts.task_id, t.task_name,\n",
    "                   ts.ai_contribution_score, ts.ai_analysis_comment_task, ts.task_performance\n",
    "            FROM task_summaries ts\n",
    "            JOIN tasks t ON ts.task_id = t.task_id\n",
    "            JOIN employees e ON t.emp_no = e.emp_no\n",
    "            WHERE e.team_id = :team_id AND ts.period_id <= :period_id\n",
    "            ORDER BY t.emp_no, ts.period_id, ts.task_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"team_id\": team_id, \"period_id\": period_id}).fetchall()\n",
    "        \n",
    "        # emp_no별로 그룹화\n",
    "        quarterly_data = {}\n",
    "        for row in results:\n",
    "            emp_no = row.emp_no\n",
    "            if emp_no not in quarterly_data:\n",
    "                quarterly_data[emp_no] = []\n",
    "            quarterly_data[emp_no].append(row_to_dict(row))\n",
    "        \n",
    "        return quarterly_data\n",
    "\n",
    "def batch_update_temp_evaluations(score_data: List[Dict]) -> Dict:\n",
    "    \"\"\"팀 전체 temp_evaluations 배치 업데이트 (raw_score, score 모두 저장)\"\"\"\n",
    "    success_count = 0\n",
    "    failed_members = []\n",
    "    \n",
    "    with engine.connect() as connection:\n",
    "        try:\n",
    "            for data in score_data:\n",
    "                try:\n",
    "                    raw_score_val = data[\"raw_score\"]\n",
    "                    try:\n",
    "                        # raw_score가 json 문자열일 경우 dict로 파싱, 아니면 그대로 사용\n",
    "                        raw_score_dict = json.loads(raw_score_val)\n",
    "                        display_raw_score = raw_score_dict.get('raw_hybrid_score', raw_score_val)\n",
    "                    except (json.JSONDecodeError, TypeError):\n",
    "                        display_raw_score = raw_score_val\n",
    "\n",
    "                    query = text(\"\"\"\n",
    "                        UPDATE temp_evaluations \n",
    "                        SET ai_reason = :ai_reason,\n",
    "                            raw_score = :raw_score,\n",
    "                            score = :score,\n",
    "                            comment = :comment\n",
    "                        WHERE TempEvaluation_empNo = :emp_no\n",
    "                    \"\"\")\n",
    "                    \n",
    "                    result = connection.execute(query, {\n",
    "                        \"emp_no\": data[\"emp_no\"],\n",
    "                        \"ai_reason\": data[\"ai_reason\"],\n",
    "                        \"raw_score\": raw_score_val,  # JSON 문자열 저장\n",
    "                        \"score\": data[\"score\"],  # 정규화된 점수 저장\n",
    "                        \"comment\": data[\"comment\"]\n",
    "                    })\n",
    "                    \n",
    "                    if result.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                        print(f\"DB 업데이트 성공: {data['emp_no']} (원시: {display_raw_score}, 정규화: {data['score']})\")\n",
    "                    else:\n",
    "                        failed_members.append(data[\"emp_no\"])\n",
    "                        print(f\"DB 업데이트 실패: {data['emp_no']} (행 없음)\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    failed_members.append(data[\"emp_no\"])\n",
    "                    print(f\"DB 업데이트 실패: {data['emp_no']} - {e}\")\n",
    "            \n",
    "            connection.commit()\n",
    "            print(f\"배치 업데이트 완료: 성공 {success_count}건, 실패 {len(failed_members)}건\")\n",
    "            \n",
    "            return {\n",
    "                \"success_count\": success_count,\n",
    "                \"failed_members\": failed_members\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"배치 업데이트 실패: {e}\")\n",
    "            connection.rollback()\n",
    "            return {\n",
    "                \"success_count\": 0,\n",
    "                \"failed_members\": [data[\"emp_no\"] for data in score_data]\n",
    "            }\n",
    "\n",
    "# ================================================================\n",
    "# LLM 호출 함수\n",
    "# ================================================================\n",
    "\n",
    "def call_llm_for_normalized_evaluation_comments(\n",
    "    emp_data: Dict,\n",
    "    normalized_score: float,\n",
    "    raw_hybrid_score: float,\n",
    "    achievement_score: float,\n",
    "    fourp_score: float,\n",
    "    quarterly_tasks: List[Dict],\n",
    "    fourp_results: Dict,\n",
    "    achievement_reason: str,\n",
    "    normalization_reason: str\n",
    ") -> Dict:\n",
    "    \"\"\"정규화된 점수로 ai_reason과 comment 생성\"\"\"\n",
    "    \n",
    "    emp_no = emp_data[\"emp_no\"]\n",
    "    emp_name = emp_data.get(\"emp_name\", emp_no)\n",
    "    position = emp_data.get(\"position\", \"직책 정보 없음\")\n",
    "    cl = emp_data.get(\"cl\", \"CL 정보 없음\")\n",
    "    \n",
    "    print(f\"LLM Call: {emp_no} 정규화 후 종합평가 근거 생성\")\n",
    "    \n",
    "    # 분기별 Task 요약\n",
    "    quarterly_summary = \"\"\n",
    "    for i, task in enumerate(quarterly_tasks[:8]):  # 최대 8개만 표시\n",
    "        quarterly_summary += f\"Q{task.get('period_id')}: {task.get('task_name')} - 달성률 {task.get('ai_contribution_score', 0)}점\\\\n\"\n",
    "        if task.get('ai_analysis_comment_task'):\n",
    "            quarterly_summary += f\"  → {task.get('ai_analysis_comment_task')}\\\\n\"\n",
    "    \n",
    "    if not quarterly_summary:\n",
    "        quarterly_summary = \"분기별 Task 데이터 없음\"\n",
    "    \n",
    "    # 4P 요약\n",
    "    fourp_summary = f\"\"\"\n",
    "    - Passionate: {fourp_results.get('passionate', {}).get('score', 3.0)}점\n",
    "    - Proactive: {fourp_results.get('proactive', {}).get('score', 3.0)}점  \n",
    "    - Professional: {fourp_results.get('professional', {}).get('score', 3.0)}점\n",
    "    - People: {fourp_results.get('people', {}).get('score', 3.0)}점\n",
    "    - 평균: {fourp_results.get('overall', {}).get('average_score', 3.0)}점\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "    당신은 SK 조직의 종합 평가 전문가입니다.\n",
    "    SK 등급 체계 기반 절대평가(달성률)와 정성평가(4P BARS)를 종합하고 CL별 정규화를 거친 최종 점수를 바탕으로 \n",
    "    두 가지 관점의 평가 근거를 생성해주세요.\n",
    "\n",
    "    SK 등급 체계 (절대평가):\n",
    "    - S+등급(120% 이상): 5.0점 (탁월한 성과)\n",
    "    - S등급(110-120%): 4.0-5.0점 (매우 우수한 성과)\n",
    "    - A등급(100-110%): 3.5-4.0점 (목표 달성)\n",
    "    - B등급(80-100%): 2.5-3.5점 (목표 근접)\n",
    "    - C등급(60-80%): 1.5-2.5점 (목표 미달)\n",
    "    - D등급(60% 미만): 1.0-1.5점 (크게 미달)\n",
    "\n",
    "    두 가지 관점의 근거를 생성하세요:\n",
    "    1. ai_reason: 팀장이 보는 AI 평가 근거 (객관적, 분석적, 절대평가+CL별 정규화 과정 포함)\n",
    "    2. comment: 팀원이 보는 평가 근거 초안 (개인 친화적, 발전지향적, 격려 포함)\n",
    "\n",
    "    결과는 JSON 형식으로만 응답하세요.\n",
    "    \"\"\"\n",
    "    \n",
    "    human_prompt = f\"\"\"\n",
    "    <직원 정보>\n",
    "    이름: {emp_name}\n",
    "    사번: {emp_no}\n",
    "    직책: {position}\n",
    "    CL: {cl}\n",
    "    </직원 정보>\n",
    "\n",
    "    <점수 산출 과정>\n",
    "    최종 정규화 점수: {normalized_score}점\n",
    "    ├── 원시 하이브리드 점수: {raw_hybrid_score:.2f}점\n",
    "    │   ├── 달성률 점수: {achievement_score}점 ({achievement_reason})\n",
    "    │   └── 4P 점수: {fourp_score}점\n",
    "    └── CL별 정규화: {normalization_reason}\n",
    "    </점수 산출 과정>\n",
    "\n",
    "    <상세 근거 데이터>\n",
    "    연간 달성률: {emp_data.get('ai_annual_achievement_rate', 0)}%\n",
    "    성과 요약: {emp_data.get('ai_annual_performance_summary_comment', '성과 요약 없음')}\n",
    "    동료평가: {emp_data.get('ai_peer_talk_summary', '동료평가 없음')}\n",
    "    \n",
    "    4P 평가 결과:\n",
    "    {fourp_summary}\n",
    "    \n",
    "    분기별 Task 성과:\n",
    "    {quarterly_summary}\n",
    "    </상세 근거 데이터>\n",
    "\n",
    "    JSON 응답:\n",
    "    {{\n",
    "        \"ai_reason\": \"[팀장용: {emp_name}({emp_no})님에 대한 객관적이고 구체적인 AI 평가 근거. SK 등급 체계 기반 절대평가 결과와 CL별 정규화 과정을 포함하여 분석적 관점으로 설명]\",\n",
    "        \"comment\": \"[팀원용: {emp_name}님께 드리는 개인 친화적이고 발전지향적인 평가 근거 초안. 최종 점수 {normalized_score}점에 대한 격려와 성장 방향 포함]\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm_client\n",
    "\n",
    "    try:\n",
    "        response: AIMessage = chain.invoke({})\n",
    "        json_output_raw = response.content\n",
    "        json_output = _extract_json_from_llm_response(json_output_raw)\n",
    "        llm_parsed_data = json.loads(json_output)\n",
    "        \n",
    "        ai_reason = llm_parsed_data.get(\"ai_reason\", \"\")\n",
    "        comment = llm_parsed_data.get(\"comment\", \"\")\n",
    "\n",
    "        if not ai_reason or not comment:\n",
    "            raise ValueError(\"LLM 응답에서 ai_reason 또는 comment가 누락됨\")\n",
    "\n",
    "        return {\n",
    "            \"ai_reason\": ai_reason,\n",
    "            \"comment\": comment\n",
    "        }\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"LLM 응답 JSON 파싱 오류: {e}\")\n",
    "        return {\n",
    "            \"ai_reason\": f\"{emp_name}님의 정규화 후 종합 평가 근거 생성 중 오류 발생\",\n",
    "            \"comment\": f\"{emp_name}님께 드리는 정규화 후 평가 근거 생성 중 오류 발생\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"LLM 호출 중 오류: {e}\")\n",
    "        return {\n",
    "            \"ai_reason\": f\"{emp_name}님의 정규화 후 종합 평가 근거 생성 중 오류 발생\",\n",
    "            \"comment\": f\"{emp_name}님께 드리는 정규화 후 평가 근거 생성 중 오류 발생\"\n",
    "        }\n",
    "\n",
    "# ================================================================\n",
    "# 팀 단위 서브모듈 함수들\n",
    "# ================================================================\n",
    "\n",
    "def team_data_collection_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"1. 팀 데이터 수집 서브모듈\"\"\"\n",
    "    \n",
    "    team_id = state[\"team_id\"]\n",
    "    period_id = state[\"period_id\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"🔍 팀 데이터 수집 시작: {team_id}\")\n",
    "        \n",
    "        # 1. 팀원 기본 정보 조회\n",
    "        team_members = fetch_team_members(team_id)\n",
    "        print(f\"   팀원 수: {len(team_members)}명\")\n",
    "        \n",
    "        # 2. 팀 전체 달성률 데이터 조회\n",
    "        team_achievement_data = fetch_team_achievement_data(team_id, period_id)\n",
    "        print(f\"   달성률 데이터: {len(team_achievement_data)}건\")\n",
    "        \n",
    "        # 3. 팀 전체 4P 데이터 조회\n",
    "        team_fourp_data = fetch_team_fourp_data(team_id, period_id)\n",
    "        print(f\"   4P 데이터: {len(team_fourp_data)}건\")\n",
    "        \n",
    "        # 4. 팀 전체 분기별 데이터 조회\n",
    "        team_quarterly_data = fetch_team_quarterly_data(team_id, period_id)\n",
    "        print(f\"   분기별 데이터: {len(team_quarterly_data)}명\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"데이터 수집 완료\")],\n",
    "            \"team_members\": team_members,\n",
    "            \"team_achievement_data\": team_achievement_data,\n",
    "            \"team_fourp_data\": team_fourp_data,\n",
    "            \"team_quarterly_data\": team_quarterly_data\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"데이터 수집 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_weights_calculation_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"2. CL별 가중치 계산 서브모듈\"\"\"\n",
    "    \n",
    "    try:\n",
    "        team_members = state[\"team_members\"]\n",
    "        \n",
    "        # CL별 가중치 계산\n",
    "        weights_by_cl = {}\n",
    "        for member in team_members:\n",
    "            cl = member.get(\"cl\", \"CL2\")\n",
    "            if cl not in weights_by_cl:\n",
    "                weights_by_cl[cl] = get_evaluation_weights_by_cl(cl)\n",
    "        \n",
    "        print(f\"📊 CL별 가중치 설정 완료: {list(weights_by_cl.keys())}\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=\"가중치 계산 완료\")],\n",
    "            \"weights_by_cl\": weights_by_cl\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"가중치 계산 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_score_calculation_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"3. 팀 전체 점수 계산 서브모듈 (SK 등급 기반 절대평가)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        team_achievement_data = state[\"team_achievement_data\"]\n",
    "        team_fourp_data = state[\"team_fourp_data\"]\n",
    "        weights_by_cl = state[\"weights_by_cl\"]\n",
    "        \n",
    "        individual_scores = []\n",
    "        \n",
    "        print(\"🧮 SK 등급 기반 절대평가 점수 계산 시작...\")\n",
    "        \n",
    "        for achievement_data in team_achievement_data:\n",
    "            emp_no = achievement_data[\"emp_no\"]\n",
    "            cl = achievement_data.get(\"cl\", \"CL2\")\n",
    "            \n",
    "            # 가중치 조회\n",
    "            weights = weights_by_cl.get(cl, {\"achievement\": 0.5, \"fourp\": 0.5})\n",
    "            \n",
    "            # SK 등급 기반 절대평가 달성률 점수 계산\n",
    "            achievement_score, achievement_reason = calculate_achievement_score_by_grade(\n",
    "                achievement_data[\"ai_annual_achievement_rate\"]\n",
    "            )\n",
    "            \n",
    "            # 4P 점수 조회\n",
    "            fourp_data = next((fp for fp in team_fourp_data if fp[\"emp_no\"] == emp_no), {})\n",
    "            fourp_results = fourp_data.get(\"fourp_results\", {})\n",
    "            fourp_score = fourp_results.get(\"overall\", {}).get(\"average_score\", 3.0)\n",
    "            \n",
    "            # 하이브리드 점수 계산 (정규화 전 원시점수)\n",
    "            hybrid_score = (achievement_score * weights[\"achievement\"]) + (fourp_score * weights[\"fourp\"])\n",
    "            final_score = round(hybrid_score, 2)\n",
    "            \n",
    "            individual_scores.append({\n",
    "                \"emp_no\": emp_no,\n",
    "                \"emp_name\": achievement_data.get(\"emp_name\"),\n",
    "                \"cl\": cl,\n",
    "                \"achievement_score\": achievement_score,\n",
    "                \"achievement_reason\": achievement_reason,\n",
    "                \"fourp_score\": fourp_score,\n",
    "                \"hybrid_score\": final_score,  # 정규화 전 원시점수\n",
    "                \"weights\": weights,\n",
    "                \"emp_data\": achievement_data,\n",
    "                \"fourp_results\": fourp_results\n",
    "            })\n",
    "            \n",
    "            print(f\"   {emp_no}: {final_score}점 (달성률 {achievement_score}, 4P {fourp_score}) - {achievement_reason}\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"절대평가 점수 계산 완료: {len(individual_scores)}명\")],\n",
    "            \"individual_scores\": individual_scores\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"점수 계산 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_normalization_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"4. 팀 내 CL별 정규화 서브모듈\"\"\"\n",
    "    \n",
    "    try:\n",
    "        individual_scores = state[\"individual_scores\"]\n",
    "        \n",
    "        print(\"🔄 팀 내 CL별 정규화 시작...\")\n",
    "        \n",
    "        # 1. CL별 그룹화 (숫자/문자열 모두 처리)\n",
    "        cl_groups = {\n",
    "            \"CL1\": [],\n",
    "            \"CL2\": [], \n",
    "            \"CL3\": []\n",
    "        }\n",
    "        \n",
    "        for score in individual_scores:\n",
    "            cl_raw = score.get(\"cl\", 2)  # 기본값 2\n",
    "            \n",
    "            # CL 값 정규화\n",
    "            if isinstance(cl_raw, (int, float)):\n",
    "                cl = f\"CL{int(cl_raw)}\"\n",
    "            else:\n",
    "                cl = str(cl_raw).upper()\n",
    "                if not cl.startswith(\"CL\"):\n",
    "                    cl = f\"CL{cl}\"\n",
    "            \n",
    "            # 유효한 CL인지 확인\n",
    "            if cl in cl_groups:\n",
    "                cl_groups[cl].append(score)\n",
    "                score[\"cl\"] = cl  # 정규화된 CL 값으로 업데이트\n",
    "            else:\n",
    "                print(f\"⚠️ 알 수 없는 CL: {cl_raw} → CL2로 처리\")\n",
    "                cl_groups[\"CL2\"].append(score)\n",
    "                score[\"cl\"] = \"CL2\"\n",
    "        \n",
    "        print(f\"   CL별 분포: CL3({len(cl_groups['CL3'])}명), CL2({len(cl_groups['CL2'])}명), CL1({len(cl_groups['CL1'])}명)\")\n",
    "        \n",
    "        # 2. CL별 정규화 실행 (4명 이상일 때만)\n",
    "        normalized_scores = []\n",
    "        \n",
    "        for cl, members in cl_groups.items():\n",
    "            if len(members) > 0:\n",
    "                print(f\"\\\\n📊 {cl} 정규화 처리:\")\n",
    "                normalized_members = normalize_cl_group(members, cl)\n",
    "                normalized_scores.extend(normalized_members)\n",
    "        \n",
    "        # 3. 정규화 통계 출력\n",
    "        raw_scores = [s[\"hybrid_score\"] for s in individual_scores]\n",
    "        norm_scores = [s[\"normalized_score\"] for s in normalized_scores]\n",
    "        \n",
    "        print(f\"\\\\n📈 정규화 결과:\")\n",
    "        print(f\"   원시점수: 평균 {statistics.mean(raw_scores):.2f}, 표준편차 {statistics.stdev(raw_scores) if len(raw_scores) > 1 else 0:.2f}\")\n",
    "        print(f\"   정규화점수: 평균 {statistics.mean(norm_scores):.2f}, 표준편차 {statistics.stdev(norm_scores) if len(norm_scores) > 1 else 0:.2f}\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"CL별 정규화 완료: {len(normalized_scores)}명\")],\n",
    "            \"individual_scores\": normalized_scores\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"정규화 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_comment_generation_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"5. 팀 전체 코멘트 생성 서브모듈 (정규화된 점수 기준)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        individual_scores = state[\"individual_scores\"]\n",
    "        team_quarterly_data = state[\"team_quarterly_data\"]\n",
    "        \n",
    "        evaluation_comments = []\n",
    "        \n",
    "        print(\"💬 정규화 후 평가 코멘트 생성 시작...\")\n",
    "        \n",
    "        for score_data in individual_scores:\n",
    "            emp_no = score_data[\"emp_no\"]\n",
    "            quarterly_tasks = team_quarterly_data.get(emp_no, [])\n",
    "            \n",
    "            # LLM을 통한 정규화 후 코멘트 생성\n",
    "            llm_result = call_llm_for_normalized_evaluation_comments(\n",
    "                emp_data=score_data[\"emp_data\"],\n",
    "                normalized_score=score_data[\"normalized_score\"],\n",
    "                raw_hybrid_score=score_data[\"raw_hybrid_score\"],\n",
    "                achievement_score=score_data[\"achievement_score\"],\n",
    "                fourp_score=score_data[\"fourp_score\"],\n",
    "                quarterly_tasks=quarterly_tasks,\n",
    "                fourp_results=score_data[\"fourp_results\"],\n",
    "                achievement_reason=score_data[\"achievement_reason\"],\n",
    "                normalization_reason=score_data[\"normalization_reason\"]\n",
    "            )\n",
    "            \n",
    "            # raw_score에 저장할 JSON 데이터 구성\n",
    "            fourp_results = score_data.get(\"fourp_results\", {})\n",
    "            raw_score_details = {\n",
    "                \"achievement_score\": score_data.get(\"achievement_score\"),\n",
    "                \"passionate_score\": fourp_results.get(\"passionate\", {}).get(\"score\", 3.0),\n",
    "                \"proactive_score\": fourp_results.get(\"proactive\", {}).get(\"score\", 3.0),\n",
    "                \"professional_score\": fourp_results.get(\"professional\", {}).get(\"score\", 3.0),\n",
    "                \"people_score\": fourp_results.get(\"people\", {}).get(\"score\", 3.0),\n",
    "                \"raw_hybrid_score\": score_data.get(\"raw_hybrid_score\")\n",
    "            }\n",
    "            raw_score_json = json.dumps(raw_score_details, ensure_ascii=False)\n",
    "\n",
    "            evaluation_comments.append({\n",
    "                \"emp_no\": emp_no,\n",
    "                \"emp_name\": score_data.get(\"emp_name\"),\n",
    "                \"raw_score\": raw_score_json,  # 원시점수를 JSON 문자열로 저장\n",
    "                \"score\": score_data[\"normalized_score\"],  # 정규화된 점수\n",
    "                \"ai_reason\": llm_result[\"ai_reason\"],\n",
    "                \"comment\": llm_result[\"comment\"]\n",
    "            })\n",
    "            \n",
    "            print(f\"   {emp_no}: 정규화 후 코멘트 생성 완료\")\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"코멘트 생성 완료: {len(evaluation_comments)}명\")],\n",
    "            \"evaluation_comments\": evaluation_comments\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"messages\"] = [HumanMessage(content=f\"코멘트 생성 실패: {str(e)}\")]\n",
    "        raise e\n",
    "\n",
    "def team_batch_storage_submodule(state: TeamModule7AgentState) -> TeamModule7AgentState:\n",
    "    \"\"\"6. 팀 배치 저장 서브모듈\"\"\"\n",
    "    \n",
    "    try:\n",
    "        evaluation_comments = state[\"evaluation_comments\"]\n",
    "        \n",
    "        print(\"💾 배치 저장 시작...\")\n",
    "        \n",
    "        # 배치 업데이트 실행\n",
    "        update_result = batch_update_temp_evaluations(evaluation_comments)\n",
    "        \n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"배치 저장 완료: 성공 {update_result['success_count']}건\")],\n",
    "            \"processed_count\": update_result[\"success_count\"],\n",
    "            \"failed_members\": update_result[\"failed_members\"]\n",
    "        })\n",
    "        return updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        updated_state = state.copy()\n",
    "        updated_state.update({\n",
    "            \"messages\": [HumanMessage(content=f\"배치 저장 실패: {str(e)}\")],\n",
    "            \"processed_count\": 0,\n",
    "            \"failed_members\": []\n",
    "        })\n",
    "        raise e\n",
    "\n",
    "# ================================================================\n",
    "# 팀 단위 워크플로우 생성\n",
    "# ================================================================\n",
    "\n",
    "def create_team_module7_graph():\n",
    "    \"\"\"팀 단위 모듈 7 그래프 생성 및 반환 (SK 등급 기반 절대평가 + CL 정규화 포함)\"\"\"\n",
    "    team_module7_workflow = StateGraph(TeamModule7AgentState)\n",
    "    \n",
    "    # 노드 추가\n",
    "    team_module7_workflow.add_node(\"team_data_collection\", team_data_collection_submodule)\n",
    "    team_module7_workflow.add_node(\"team_weights_calculation\", team_weights_calculation_submodule)\n",
    "    team_module7_workflow.add_node(\"team_score_calculation\", team_score_calculation_submodule)\n",
    "    team_module7_workflow.add_node(\"team_normalization\", team_normalization_submodule)\n",
    "    team_module7_workflow.add_node(\"team_comment_generation\", team_comment_generation_submodule)\n",
    "    team_module7_workflow.add_node(\"team_batch_storage\", team_batch_storage_submodule)\n",
    "    \n",
    "    # 엣지 정의 (순차 실행)\n",
    "    team_module7_workflow.add_edge(START, \"team_data_collection\")\n",
    "    team_module7_workflow.add_edge(\"team_data_collection\", \"team_weights_calculation\")\n",
    "    team_module7_workflow.add_edge(\"team_weights_calculation\", \"team_score_calculation\")\n",
    "    team_module7_workflow.add_edge(\"team_score_calculation\", \"team_normalization\")\n",
    "    team_module7_workflow.add_edge(\"team_normalization\", \"team_comment_generation\")\n",
    "    team_module7_workflow.add_edge(\"team_comment_generation\", \"team_batch_storage\")\n",
    "    team_module7_workflow.add_edge(\"team_batch_storage\", END)\n",
    "    \n",
    "    return team_module7_workflow.compile()\n",
    "\n",
    "# ================================================================\n",
    "# 실행 함수들\n",
    "# ================================================================\n",
    "\n",
    "def run_team_module7_evaluation(team_id: str, period_id: int = 4):\n",
    "    \"\"\"팀 단위 모듈 7 연말 종합평가 실행 (SK 등급 기반 절대평가 + CL 정규화 포함)\"\"\"\n",
    "    \n",
    "    print(f\"🚀 팀 단위 모듈 7 + SK 등급 기반 절대평가 + CL 정규화 실행 시작: {team_id} (period_id: {period_id})\")\n",
    "    \n",
    "    # State 정의\n",
    "    state = TeamModule7AgentState(\n",
    "        messages=[HumanMessage(content=f\"팀 {team_id}: SK 등급 기반 종합평가 + CL 정규화 시작\")],\n",
    "        team_id=team_id,\n",
    "        period_id=period_id,\n",
    "        team_members=[],\n",
    "        team_achievement_data=[],\n",
    "        team_fourp_data=[],\n",
    "        team_quarterly_data={},\n",
    "        weights_by_cl={},\n",
    "        individual_scores=[],\n",
    "        evaluation_comments=[],\n",
    "        processed_count=0,\n",
    "        failed_members=[]\n",
    "    )\n",
    "    \n",
    "    # 그래프 생성 및 실행\n",
    "    team_module7_graph = create_team_module7_graph()\n",
    "    \n",
    "    try:\n",
    "        result = team_module7_graph.invoke(state)\n",
    "        \n",
    "        print(\"✅ 팀 단위 모듈 7 + SK 등급 기반 절대평가 + CL 정규화 실행 완료!\")\n",
    "        print(f\"📊 결과:\")\n",
    "        for message in result['messages']:\n",
    "            print(f\"  - {message.content}\")\n",
    "        \n",
    "        if result.get('processed_count'):\n",
    "            print(f\"🎯 처리 완료: {result['processed_count']}명\")\n",
    "            if result.get('failed_members'):\n",
    "                print(f\"❌ 실패한 팀원: {result['failed_members']}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 팀 단위 모듈 7 + SK 등급 기반 절대평가 + CL 정규화 실행 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_multiple_teams_module7(team_ids: List[str], period_id: int = 4):\n",
    "    \"\"\"여러 팀 일괄 실행\"\"\"\n",
    "    print(f\"🚀 다중 팀 모듈 7 + SK 등급 기반 절대평가 + CL 정규화 실행: {len(team_ids)}개 팀\")\n",
    "    \n",
    "    results = {}\n",
    "    total_processed = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    for team_id in team_ids:\n",
    "        print(f\"\\\\n{'='*50}\")\n",
    "        print(f\"팀 {team_id} 처리 중...\")\n",
    "        \n",
    "        result = run_team_module7_evaluation(team_id, period_id)\n",
    "        results[team_id] = result\n",
    "        \n",
    "        if result:\n",
    "            total_processed += result.get('processed_count', 0)\n",
    "            total_failed += len(result.get('failed_members', []))\n",
    "    \n",
    "    print(f\"\\\\n🎯 전체 결과:\")\n",
    "    print(f\"   처리된 팀: {len([r for r in results.values() if r is not None])}/{len(team_ids)}\")\n",
    "    print(f\"   처리된 인원: {total_processed}명\")\n",
    "    print(f\"   실패한 인원: {total_failed}명\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ================================================================\n",
    "# 개별 실행 호환 함수 (기존 코드 호환성)\n",
    "# ================================================================\n",
    "\n",
    "def run_module7_evaluation(emp_no: str, period_id: int = 4):\n",
    "    \"\"\"개별 실행 (기존 호환성을 위한 래퍼 함수)\"\"\"\n",
    "    # 직원의 팀 ID 조회\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"SELECT team_id FROM employees WHERE emp_no = :emp_no\")\n",
    "        result = connection.execute(query, {\"emp_no\": emp_no}).fetchone()\n",
    "        \n",
    "        if not result:\n",
    "            print(f\"❌ 직원 정보 없음: {emp_no}\")\n",
    "            return None\n",
    "        \n",
    "        team_id = result.team_id\n",
    "    \n",
    "    print(f\"🔄 개별 실행을 팀 단위로 변환: {emp_no} → 팀 {team_id}\")\n",
    "    \n",
    "    # 팀 단위로 실행\n",
    "    return run_team_module7_evaluation(team_id, period_id)\n",
    "\n",
    "# ================================================================\n",
    "# 테스트 및 디버깅 함수들\n",
    "# ================================================================\n",
    "\n",
    "def get_all_teams_with_data(period_id: int = 4) -> List[str]:\n",
    "    \"\"\"평가 데이터가 있는 모든 팀 ID 조회\"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(\"\"\"\n",
    "            SELECT DISTINCT e.team_id\n",
    "            FROM employees e\n",
    "            JOIN final_evaluation_reports fer ON e.emp_no = fer.emp_no\n",
    "            JOIN team_evaluations te ON fer.team_evaluation_id = te.team_evaluation_id\n",
    "            WHERE te.period_id = :period_id\n",
    "            ORDER BY e.team_id\n",
    "        \"\"\")\n",
    "        results = connection.execute(query, {\"period_id\": period_id}).fetchall()\n",
    "        return [row.team_id for row in results]\n",
    "\n",
    "def test_team_module7(team_id: str = None, period_id: int = 4):\n",
    "    \"\"\"팀 모듈 7 + SK 등급 기반 절대평가 + CL 정규화 테스트\"\"\"\n",
    "    if not team_id:\n",
    "        teams = get_all_teams_with_data(period_id)\n",
    "        if teams:\n",
    "            team_id = teams[0]\n",
    "            print(f\"🧪 테스트 팀 자동 선택: {team_id}\")\n",
    "        else:\n",
    "            print(\"❌ 테스트할 팀이 없습니다\")\n",
    "            return\n",
    "    \n",
    "    return run_team_module7_evaluation(team_id, period_id)\n",
    "\n",
    "def preview_achievement_scoring():\n",
    "    \"\"\"SK 등급 기반 절대평가 점수 미리보기\"\"\"\n",
    "    print(\"📋 SK 등급 기반 절대평가 점수 체계:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_rates = [0, 30, 50, 70, 85, 95, 100, 105, 115, 125, 150, 200]\n",
    "    \n",
    "    for rate in test_rates:\n",
    "        score, reason = calculate_achievement_score_by_grade(rate)\n",
    "        print(f\"달성률 {rate:3d}% → {score:4.2f}점 ({reason.split('(')[1].split(',')[0]})\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# ================================================================\n",
    "# 실행 예시\n",
    "# ================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 팀 단위 모듈 7 + SK 등급 기반 절대평가 + CL별 정규화 준비 완료!\")\n",
    "    print(\"\\\\n🔥 주요 변경사항:\")\n",
    "    print(\"✅ SK 등급 체계 기반 절대평가 (S/A/B/C/D → 1-5점)\")\n",
    "    print(\"✅ 달성률 100% = 3.5점, 120% = 5.0점 명확한 기준\")\n",
    "    print(\"✅ CL별 정규화: 4명 이상일 때만 적용, 3명 이하는 원시점수 유지\")\n",
    "    print(\"✅ DB 저장: raw_score(원시점수) + score(정규화점수) 별도 저장\")\n",
    "    print(\"✅ 달성률:4P 가중치 유지 (CL3:6:4, CL2:5:5, CL1:4:6)\")\n",
    "    \n",
    "    print(\"\\\\n실행 명령어:\")\n",
    "    print(\"1. run_team_module7_evaluation('TEAM001', 4)     # 단일 팀 실행\")\n",
    "    print(\"2. run_multiple_teams_module7(['TEAM001', 'TEAM002'], 4)  # 다중 팀 실행\")\n",
    "    print(\"3. run_module7_evaluation('E002', 4)             # 개별 실행 (호환성)\")\n",
    "    print(\"4. test_team_module7()                           # 테스트 실행\")\n",
    "    print(\"5. preview_achievement_scoring()                 # 점수 체계 미리보기\")\n",
    "    \n",
    "    # 점수 체계 미리보기 실행\n",
    "    preview_achievement_scoring()\n",
    "    \n",
    "    # 자동 테스트 (필요시 주석 해제)\n",
    "    test_team_module7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33163dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-WTM_qa1c-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
