# -*- coding: utf-8 -*-
"""
ëª¨ë“ˆ8: íŒ€ ì„±ê³¼ ë¹„êµ ë¶„ì„ ëª¨ë“ˆ - ì™„ì „ êµ¬í˜„

ê¸°ëŠ¥:
1. í´ëŸ¬ìŠ¤í„° í†µê³„ ì¡´ì¬ í™•ì¸ ë° ê³„ì‚°
2. ìš°ë¦¬íŒ€ + ìœ ì‚¬íŒ€ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘  
3. KPIë³„ ìœ ì‚¬ë„ ë§¤ì¹­ + ë¹„êµ ë¶„ì„
4. LLM ê¸°ë°˜ íŒ€ ì„±ê³¼ ì½”ë©˜íŠ¸ ìƒì„±
5. JSON ê²°ê³¼ DB ì €ì¥
6. LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì¡°
"""

import sys
import os
import json
import re
import statistics
import time
import logging
from typing import Dict, List, Optional, Any, Literal, TypedDict
from dataclasses import dataclass
from datetime import datetime

# í™˜ê²½ ì„¤ì •
current_file_dir = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.abspath(os.path.join(current_file_dir, '../../../../'))
CACHE_DIR = os.path.join(ROOT_DIR, 'data', 'cache')

# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
os.makedirs(CACHE_DIR, exist_ok=True)

sys.path.append(ROOT_DIR)

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, START, END
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Row

# DB ì—°ê²°
from config.settings import DatabaseConfig

# LLM ê´€ë ¨
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, AIMessage

# ìœ ì‚¬ë„ ë¶„ì„
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# íŒ€ ì„±ê³¼ ë¹„êµ ë¶„ì„ê¸° ì„í¬íŠ¸
from shared.team_performance_comparator import TeamPerformanceComparator

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# httpx ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ ì¡°ì • (HTTP ìš”ì²­ ë¡œê·¸ ìˆ¨ê¹€)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("langchain").setLevel(logging.WARNING)
logging.getLogger("langchain_openai").setLevel(logging.WARNING)

# DB ì„¤ì • ë° LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
db_config = DatabaseConfig()
DATABASE_URL = db_config.DATABASE_URL
engine = create_engine(DATABASE_URL, pool_pre_ping=True)

llm_client = ChatOpenAI(model="gpt-4o-mini", temperature=0)
logger.info(f"LLM Client initialized: {llm_client.model_name}")

# ===== ìƒíƒœ ì •ì˜ =====
class Module8AgentState(TypedDict):
    """
    ëª¨ë“ˆ 8 (íŒ€ ì„±ê³¼ ë¹„êµ ëª¨ë“ˆ)ì˜ ë‚´ë¶€ ìƒíƒœë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    """
    messages: List[HumanMessage]
    
    # ê¸°ë³¸ ì •ë³´
    team_id: int
    period_id: int
    report_type: Literal["quarterly", "annual_manager"]
    
    # í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼
    our_team_cluster_id: int
    similar_teams: List[int]
    cluster_stats: Dict
    
    # ì„±ê³¼ ë°ì´í„°
    our_team_kpis: List[Dict]
    our_team_overall_rate: float
    similar_teams_performance: List[Dict]
    
    # ë¹„êµ ë¶„ì„ ê²°ê³¼
    kpi_comparison_results: List[Dict]
    team_performance_summary: Dict
    
    # ìµœì¢… ê²°ê³¼
    team_performance_comment: str
    final_comparison_json: Dict
    
    # ì—…ë°ì´íŠ¸ëœ ID
    updated_team_evaluation_id: Optional[int]

# ===== ì—ëŸ¬ ì²˜ë¦¬ í´ë˜ìŠ¤ =====
class Module8ValidationError(Exception):
    pass

class Module8DataIntegrityError(Exception):
    pass

# ===== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ =====
def row_to_dict(row: Row) -> Dict[str, Any]:
    """SQLAlchemy Row ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
    if row is None:
        return {}
    return row._asdict()

def _extract_json_from_llm_response(text: str) -> str:
    """LLM ì‘ë‹µì—ì„œ JSON ë¸”ë¡ ì¶”ì¶œ"""
    match = re.search(r"```(?:json)?\s*(.*?)\s*```", text, re.DOTALL)
    if match:
        return match.group(1).strip()
    return text.strip()

def robust_llm_call(prompt: str, validation_func, max_retries: int = 3, context: str = ""):
    """ê²¬ê³ í•œ LLM í˜¸ì¶œ"""
    last_error = None
    
    for attempt in range(max_retries):
        try:
            response = llm_client.invoke(prompt)
            content = str(response.content)
            validated_result = validation_func(content)
            return validated_result
            
        except Exception as e:
            last_error = e
            logger.warning(f"LLM call attempt {attempt + 1} failed for {context}: {e}")
            
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
    
    logger.error(f"All LLM attempts failed for {context}: {last_error}")
    raise Module8ValidationError(f"Failed after {max_retries} attempts: {last_error}")

def get_year_from_period(period_id: int) -> int:
    """period_idë¡œ ì—°ë„ ì¡°íšŒ"""
    with engine.connect() as connection:
        query = text("SELECT year FROM periods WHERE period_id = :period_id")
        result = connection.execute(query, {"period_id": period_id}).scalar_one_or_none()
        return result if result else 2024  # fallback

# ===== ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜ë“¤ =====

def fetch_team_kpis_data(team_id: int, period_id: int) -> Optional[Dict]:
    """íŒ€ KPI ë°ì´í„°ì™€ ì¢…í•© ë‹¬ì„±ë¥  ì¡°íšŒ"""
    with engine.connect() as connection:
        # period_idë¡œ ì—°ë„ ê³„ì‚°
        year = get_year_from_period(period_id)
        
        # team_evaluations.average_achievement_rate ì¡°íšŒ
        overall_query = text("""
            SELECT te.average_achievement_rate as overall_rate
            FROM team_evaluations te
            WHERE te.team_id = :team_id AND te.period_id = :period_id
        """)
        
        overall_result = connection.execute(overall_query, {
            "team_id": team_id, 
            "period_id": period_id
        }).fetchone()
        
        if not overall_result:
            return None
        
        # KPI ëª©ë¡ ì¡°íšŒ - team_kpi_id ì¶”ê°€
        kpi_query = text("""
            SELECT 
                tk.team_kpi_id,
                tk.kpi_name,
                tk.kpi_description,
                tk.ai_kpi_progress_rate as rate,
                tk.weight
            FROM team_kpis tk
            WHERE tk.team_id = :team_id AND tk.year = :year
            ORDER BY tk.team_kpi_id
        """)
        
        kpi_results = connection.execute(kpi_query, {"team_id": team_id, "year": year}).fetchall()
        
        kpis = []
        for row in kpi_results:
            kpis.append({
                "team_kpi_id": row.team_kpi_id,
                "kpi_name": row.kpi_name,
                "kpi_description": row.kpi_description or "",
                "rate": row.rate or 0,
                "weight": row.weight or 0
            })
        
        return {
            "team_id": team_id,
            "overall_rate": overall_result.overall_rate or 0,
            "kpis": kpis
        }

def fetch_multiple_teams_kpis(team_ids: List[int], period_id: int) -> List[Dict]:
    """ì—¬ëŸ¬ íŒ€ì˜ KPI ë°ì´í„° ë°°ì¹˜ ì¡°íšŒ"""
    if not team_ids:
        return []
    
    # period_idë¡œ ì—°ë„ ê³„ì‚°
    year = get_year_from_period(period_id)
    
    with engine.connect() as connection:
        team_ids_str = ','.join(map(str, team_ids))
        query = text(f"""
            SELECT 
                tk.team_id,
                tk.team_kpi_id,
                tk.kpi_name,
                tk.kpi_description,
                tk.ai_kpi_progress_rate as rate,
                tk.weight
            FROM team_kpis tk
            WHERE tk.team_id IN ({team_ids_str}) AND tk.year = :year
            ORDER BY tk.team_id, tk.team_kpi_id
        """)
        
        results = connection.execute(query, {"year": year}).fetchall()
        
        # íŒ€ë³„ë¡œ ê·¸ë£¹í™”
        teams_kpis = {}
        for row in results:
            team_id = row.team_id
            if team_id not in teams_kpis:
                teams_kpis[team_id] = []
            
            teams_kpis[team_id].append({
                "team_id": team_id,
                "team_kpi_id": row.team_kpi_id,
                "kpi_name": row.kpi_name,
                "kpi_description": row.kpi_description or "",
                "rate": row.rate or 0,
                "weight": row.weight or 0
            })
        
        # ë¦¬ìŠ¤íŠ¸ë¡œ í‰íƒ„í™”
        all_kpis = []
        for team_kpis in teams_kpis.values():
            all_kpis.extend(team_kpis)
        
        return all_kpis

def fetch_team_evaluation_id(team_id: int, period_id: int) -> Optional[int]:
    """team_evaluation_id ì¡°íšŒ"""
    with engine.connect() as connection:
        query = text("""
            SELECT team_evaluation_id 
            FROM team_evaluations 
            WHERE team_id = :team_id AND period_id = :period_id
        """)
        result = connection.execute(query, {
            "team_id": team_id, 
            "period_id": period_id
        }).scalar_one_or_none()
        return result

# ===== KPI ë¹„êµ ë¶„ì„ í•¨ìˆ˜ë“¤ =====

def find_similar_kpis_by_text_similarity(our_kpi: Dict, similar_teams_kpis: List[Dict], 
                                       threshold: float = 0.3) -> List[Dict]:
    """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê¸°ë°˜ KPI ë§¤ì¹­"""
    our_kpi_text = f"{our_kpi['kpi_name']} {our_kpi['kpi_description']}"
    
    matched_kpis = []
    
    for kpi in similar_teams_kpis:
        kpi_text = f"{kpi['kpi_name']} {kpi['kpi_description']}"
        
        # TF-IDF ìœ ì‚¬ë„ ê³„ì‚°
        vectorizer = TfidfVectorizer(stop_words=None)
        try:
            tfidf_matrix = vectorizer.fit_transform([our_kpi_text, kpi_text])
            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
            
            if similarity >= threshold:
                matched_kpis.append({
                    "kpi": kpi,
                    "similarity": similarity
                })
        except:
            # ë²¡í„°í™” ì‹¤íŒ¨ ì‹œ ê±´ë„ˆë›°ê¸°
            continue
    
    return matched_kpis

def get_comparison_result_detailed(our_rate: float, stats: Dict) -> str:
    """í†µê³„ì  ê¸°ì¤€ìœ¼ë¡œ ìƒì„¸í•œ ë¹„êµ ê²°ê³¼ íŒì •"""
    avg = stats["avg_rate"]
    std = stats["std_rate"]
    
    if std == 0:  # í‘œì¤€í¸ì°¨ê°€ 0ì¸ ê²½ìš°
        if our_rate > avg:
            return "ìš°ìˆ˜"
        elif our_rate == avg:
            return "í‰ê· "
        else:
            return "ê°œì„  í•„ìš”"
    
    if our_rate >= avg + 1.5 * std:
        return "ë§¤ìš° ìš°ìˆ˜"
    elif our_rate >= avg + 0.5 * std:
        return "ìš°ìˆ˜"
    elif our_rate >= avg - 0.5 * std:
        return "í‰ê· "
    elif our_rate >= avg - 1.5 * std:
        return "ê°œì„  í•„ìš”"
    else:
        return "í¬ê²Œ ê°œì„  í•„ìš”"

def compare_kpis_with_similar_teams(our_kpis: List[Dict], similar_teams_kpis: List[Dict]) -> List[Dict]:
    """KPIë³„ ìœ ì‚¬ë„ ë§¤ì¹­ ë° ë¹„êµ"""
    comparison_results = []
    min_sample_size = 3
    
    for our_kpi in our_kpis:
        # ìœ ì‚¬ KPI ì°¾ê¸°
        similar_kpis = find_similar_kpis_by_text_similarity(our_kpi, similar_teams_kpis)
        
        if len(similar_kpis) >= min_sample_size:
            # ì¶©ë¶„í•œ ìƒ˜í”Œ â†’ í‰ê·  ê³„ì‚°
            similar_rates = [matched["kpi"]["rate"] for matched in similar_kpis]
            similar_avg = statistics.mean(similar_rates)
            similar_std = statistics.stdev(similar_rates) if len(similar_rates) > 1 else 0
            
            # í†µê³„ì  ë¹„êµ
            comparison_result = get_comparison_result_detailed(
                our_kpi["rate"], {"avg_rate": similar_avg, "std_rate": similar_std}
            )
            
            comparison_results.append({
                "team_kpi_id": our_kpi["team_kpi_id"],
                "kpi_name": our_kpi["kpi_name"],
                "our_rate": our_kpi["rate"],
                "similar_avg_rate": round(similar_avg, 1),
                "similar_kpis_count": len(similar_kpis),
                "comparison_result": comparison_result
            })
        else:
            # ìƒ˜í”Œ ë¶€ì¡± â†’ ë¹„êµ ë¶ˆê°€
            comparison_results.append({
                "team_kpi_id": our_kpi["team_kpi_id"],
                "kpi_name": our_kpi["kpi_name"],
                "our_rate": our_kpi["rate"],
                "similar_avg_rate": None,
                "similar_kpis_count": len(similar_kpis),
                "comparison_result": "-"
            })
    
    return comparison_results

# ===== LLM í•¨ìˆ˜ =====

def call_llm_for_team_performance_comment(our_overall_rate: float, cluster_stats: Dict, 
                                        kpi_comparison_results: List[Dict], 
                                        similar_teams_count: int) -> str:
    """íŒ€ ì„±ê³¼ ë¹„êµ ì½”ë©˜íŠ¸ ìƒì„±"""
    
    # KPIë³„ ìƒì„¸ ë¶„ì„ ë¬¸ìì—´ ìƒì„±
    kpi_details = ""
    for kpi in kpi_comparison_results:
        if kpi["similar_avg_rate"] is not None:
            kpi_details += f"- {kpi['kpi_name']}: {kpi['our_rate']}% vs {kpi['similar_avg_rate']}% (ìœ ì‚¬íŒ€ í‰ê· ) â†’ {kpi['comparison_result']}\n"
        else:
            kpi_details += f"- {kpi['kpi_name']}: {kpi['our_rate']}% (ìœ ì‚¬ KPI ì—†ìŒ) â†’ -\n"
    
    system_prompt = """
    ë‹¹ì‹ ì€ SKì˜ íŒ€ ì„±ê³¼ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒ€ì¥ì—ê²Œ ì œê³µí•  ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ ì„±ê³¼ ë¶„ì„ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    ë‹¤ìŒ êµ¬ì„±ìœ¼ë¡œ 250-300ì ë¶„ëŸ‰ì˜ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
    1. ì¢…í•© ë‹¬ì„±ë¥  í‰ê°€ (ìœ ì‚¬íŒ€ ëŒ€ë¹„)
    2. KPIë³„ ê°•ì /íŠ¹ì§• ë¶„ì„
    3. íŒ€ ì„±ê³¼ì˜ ì „ë°˜ì  íŠ¹ì„±
    4. ê°„ë‹¨í•œ ê°œì„  ë°©í–¥ (í•„ìš”ì‹œ)
    
    ê²°ê³¼ëŠ” ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
    {
      "comment": "[250-300ì ë¶„ëŸ‰ì˜ íŒ€ ì„±ê³¼ ë¶„ì„ ì½”ë©˜íŠ¸]"
    }
    """
    
    human_prompt = f"""
    <íŒ€ ì„±ê³¼ ì •ë³´>
    ì¢…í•© ë‹¬ì„±ë¥ : {our_overall_rate}% (ìœ ì‚¬íŒ€ í‰ê· : {cluster_stats['avg_rate']}%)
    í´ëŸ¬ìŠ¤í„° ë‚´ ìœ„ì¹˜: {similar_teams_count}ê°œ ìœ ì‚¬íŒ€ê³¼ ë¹„êµ
    </íŒ€ ì„±ê³¼ ì •ë³´>
    
    <KPIë³„ ìƒì„¸ ë¶„ì„>
    {kpi_details}
    </KPIë³„ ìƒì„¸ ë¶„ì„>
    """
    
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content=system_prompt),
        HumanMessage(content=human_prompt)
    ])
    
    def validate_comment_response(response: str) -> str:
        try:
            json_output_raw = response
            json_output = _extract_json_from_llm_response(json_output_raw)
            llm_parsed_data = json.loads(json_output)
            
            comment = llm_parsed_data.get("comment", "")
            if not comment:
                raise ValueError("LLMì´ ë¹ˆ ì½”ë©˜íŠ¸ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
            
            return comment
            
        except Exception as e:
            logger.error(f"Comment validation failed: {e}")
            # í´ë°± ì½”ë©˜íŠ¸
            overall_comparison = get_comparison_result_detailed(
                our_overall_rate, cluster_stats
            )
            return f"ê·€í•˜ì˜ íŒ€ì€ ì¢…í•© ë‹¬ì„±ë¥  {our_overall_rate}%ë¡œ ìœ ì‚¬íŒ€ í‰ê· ({cluster_stats['avg_rate']}%) ëŒ€ë¹„ {overall_comparison} ì„±ê³¼ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ìœ ì‚¬íŒ€ {similar_teams_count}ê°œì™€ì˜ ë¹„êµ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•œ ì „ëµ ìˆ˜ë¦½ì´ í•„ìš”í•©ë‹ˆë‹¤."
    
    chain = prompt | llm_client
    
    try:
        response: AIMessage = chain.invoke({})
        content = str(response.content)
        return validate_comment_response(content)
        
    except Exception as e:
        logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        # í´ë°± ì½”ë©˜íŠ¸
        overall_comparison = get_comparison_result_detailed(
            our_overall_rate, cluster_stats
        )
        return f"ê·€í•˜ì˜ íŒ€ì€ ì¢…í•© ë‹¬ì„±ë¥  {our_overall_rate}%ë¡œ ìœ ì‚¬íŒ€ í‰ê· ({cluster_stats['avg_rate']}%) ëŒ€ë¹„ {overall_comparison} ì„±ê³¼ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ìœ ì‚¬íŒ€ {similar_teams_count}ê°œì™€ì˜ ë¹„êµ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì†ì ì¸ ì„±ì¥ì„ ìœ„í•œ ì „ëµ ìˆ˜ë¦½ì´ í•„ìš”í•©ë‹ˆë‹¤."

# ===== DB ì €ì¥ í•¨ìˆ˜ =====

def save_team_comparison_results(team_evaluation_id: int, comparison_json: Dict) -> bool:
    """íŒ€ ë¹„êµ ê²°ê³¼ DB ì €ì¥"""
    with engine.connect() as connection:
        # comparison_result ì¶”ì¶œ
        comparison_result = comparison_json.get("overall", {}).get("comparison_result", "")
        
        query = text("""
            UPDATE team_evaluations
            SET 
                ai_team_comparison = :comparison_json,
                relative_performance = :comparison_result
            WHERE team_evaluation_id = :team_evaluation_id
        """)
        
        result = connection.execute(query, {
            "team_evaluation_id": team_evaluation_id,
            "comparison_json": json.dumps(comparison_json, ensure_ascii=False),
            "comparison_result": comparison_result
        })
        connection.commit()
        return result.rowcount > 0

# ===== ì„œë¸Œëª¨ë“ˆ í•¨ìˆ˜ ì •ì˜ =====

def check_cluster_stats_submodule(state: Module8AgentState) -> Module8AgentState:
    """1. í´ëŸ¬ìŠ¤í„° í†µê³„ ì¡´ì¬ í™•ì¸"""
    period_id = state["period_id"]
    
    # TeamPerformanceComparator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    comparator = TeamPerformanceComparator(cache_dir=CACHE_DIR)
    
    # í´ëŸ¬ìŠ¤í„° í†µê³„ ìƒíƒœ í™•ì¸
    status = comparator.get_cluster_status(period_id)
    
    if status["cache_file_exists"]:
        message = f"í´ëŸ¬ìŠ¤í„° í†µê³„ í™•ì¸ ì™„ë£Œ: ê¸°ì¡´ ìºì‹œ ì‚¬ìš© (Q{period_id})"
        logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° ìºì‹œ íŒŒì¼ ì¡´ì¬ - Q{period_id}")
    else:
        message = f"í´ëŸ¬ìŠ¤í„° í†µê³„ ì—†ìŒ: ìƒˆë¡œ ê³„ì‚° ì˜ˆì • (Q{period_id})"
        logger.info(f"ğŸ“Š í´ëŸ¬ìŠ¤í„° ë¶„ì„ í•„ìš” - Q{period_id}")
    
    return {
        **state,
        "messages": state.get("messages", []) + [HumanMessage(content=message)]
    }

def calculate_cluster_stats_submodule(state: Module8AgentState) -> Module8AgentState:
    """2. í•„ìš”ì‹œ ì „ì‚¬ í´ëŸ¬ìŠ¤í„°ë§ + ì„±ê³¼ í†µê³„ ê³„ì‚°"""
    team_id = state["team_id"]
    period_id = state["period_id"]
    
    logger.info(f"ğŸ”„ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì‹œì‘ - íŒ€ {team_id}")
    
    # TeamPerformanceComparatorë¡œ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì‹¤í–‰
    comparator = TeamPerformanceComparator(cache_dir=CACHE_DIR)
    result_data = comparator.analyze_team_cluster_performance(team_id, period_id)
    
    if not result_data["success"]:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì‹¤íŒ¨: {result_data['error']}")
        return {
            **state,
            "messages": state.get("messages", []) + [
                HumanMessage(content=f"í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì‹¤íŒ¨: {result_data['error']}")
            ]
        }
    
    team_cluster_info = result_data["team_cluster_info"]
    logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì™„ë£Œ - í´ëŸ¬ìŠ¤í„° {team_cluster_info['cluster_id']}, ìœ ì‚¬íŒ€ {len(team_cluster_info['similar_teams'])}ê°œ")
    
    return {
        **state,
        "messages": state.get("messages", []) + [
            HumanMessage(content=f"í´ëŸ¬ìŠ¤í„° ë¶„ì„ ì™„ë£Œ: í´ëŸ¬ìŠ¤í„° {team_cluster_info['cluster_id']}, ìœ ì‚¬íŒ€ {len(team_cluster_info['similar_teams'])}ê°œ")
        ],
        "our_team_cluster_id": team_cluster_info["cluster_id"],
        "similar_teams": team_cluster_info["similar_teams"],
        "cluster_stats": team_cluster_info["cluster_stats"]
    }

def team_performance_collection_submodule(state: Module8AgentState) -> Module8AgentState:
    """3. ìš°ë¦¬íŒ€ + ìœ ì‚¬íŒ€ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘"""
    team_id = state["team_id"]
    period_id = state["period_id"]
    similar_teams = state["similar_teams"]
    
    logger.info(f"ğŸ“‹ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ - íŒ€ {team_id} + ìœ ì‚¬íŒ€ {len(similar_teams)}ê°œ")
    
    # ìš°ë¦¬íŒ€ ë°ì´í„° ìˆ˜ì§‘
    our_team_data = fetch_team_kpis_data(team_id, period_id)
    if not our_team_data:
        logger.error(f"âŒ ìš°ë¦¬íŒ€ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ - íŒ€ {team_id}")
        return {
            **state,
            "messages": state.get("messages", []) + [
                HumanMessage(content=f"ìš°ë¦¬íŒ€ ì„±ê³¼ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: íŒ€ {team_id}")
            ]
        }
    
    # ìœ ì‚¬íŒ€ë“¤ KPI ë°ì´í„° ìˆ˜ì§‘
    similar_teams_kpis = fetch_multiple_teams_kpis(similar_teams, period_id)
    
    logger.info(f"âœ… ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ - ìš°ë¦¬íŒ€ KPI {len(our_team_data['kpis'])}ê°œ, ìœ ì‚¬íŒ€ KPI {len(similar_teams_kpis)}ê°œ")
    
    return {
        **state,
        "messages": state.get("messages", []) + [
            HumanMessage(content=f"íŒ€ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: ìš°ë¦¬íŒ€ KPI {len(our_team_data['kpis'])}ê°œ, ìœ ì‚¬íŒ€ KPI {len(similar_teams_kpis)}ê°œ")
        ],
        "our_team_kpis": our_team_data["kpis"],
        "our_team_overall_rate": our_team_data["overall_rate"],
        "similar_teams_performance": similar_teams_kpis
    }

def kpi_comparison_submodule(state: Module8AgentState) -> Module8AgentState:
    """4. KPIë³„ ìœ ì‚¬ë„ ë§¤ì¹­ + ë¹„êµ ë¶„ì„"""
    our_team_kpis = state["our_team_kpis"]
    similar_teams_performance = state["similar_teams_performance"]
    
    logger.info(f"ğŸ” KPI ë¹„êµ ë¶„ì„ ì¤‘ - {len(our_team_kpis)}ê°œ KPI")
    
    # KPIë³„ ë¹„êµ ë¶„ì„ ì‹¤í–‰
    kpi_comparison_results = compare_kpis_with_similar_teams(our_team_kpis, similar_teams_performance)
    
    # ë¹„êµ ê°€ëŠ¥í•œ KPI ê°œìˆ˜ ê³„ì‚°
    comparable_kpis = len([kpi for kpi in kpi_comparison_results if kpi["comparison_result"] != "-"])
    
    logger.info(f"âœ… KPI ë¹„êµ ë¶„ì„ ì™„ë£Œ - {len(kpi_comparison_results)}ê°œ ì¤‘ {comparable_kpis}ê°œ ë¹„êµ ê°€ëŠ¥")
    
    return {
        **state,
        "messages": state.get("messages", []) + [
            HumanMessage(content=f"KPI ë¹„êµ ë¶„ì„ ì™„ë£Œ: {len(kpi_comparison_results)}ê°œ KPI ì¤‘ {comparable_kpis}ê°œ ë¹„êµ ê°€ëŠ¥")
        ],
        "kpi_comparison_results": kpi_comparison_results
    }

def generate_team_comment_submodule(state: Module8AgentState) -> Module8AgentState:
    """5. LLM ê¸°ë°˜ íŒ€ ì„±ê³¼ ì½”ë©˜íŠ¸ ìƒì„±"""
    our_team_overall_rate = state["our_team_overall_rate"]
    cluster_stats = state["cluster_stats"]
    kpi_comparison_results = state["kpi_comparison_results"]
    similar_teams = state["similar_teams"]
    
    logger.info(f"ğŸ¤– LLM ì½”ë©˜íŠ¸ ìƒì„± ì¤‘ - ì¢…í•© ë‹¬ì„±ë¥  {our_team_overall_rate}%")
    
    # LLMìœ¼ë¡œ íŒ€ ì„±ê³¼ ì½”ë©˜íŠ¸ ìƒì„±
    team_comment = call_llm_for_team_performance_comment(
        our_team_overall_rate, cluster_stats, kpi_comparison_results, len(similar_teams)
    )
    
    # ìµœì¢… ë¹„êµ JSON êµ¬ì„±
    final_comparison_json = {
        "overall": {
            "our_rate": our_team_overall_rate,
            "similar_avg_rate": cluster_stats["avg_rate"],
            "similar_teams_count": len(similar_teams),
            "comparison_result": get_comparison_result_detailed(our_team_overall_rate, cluster_stats),
            "comment": team_comment
        },
        "kpis": kpi_comparison_results
    }
    
    logger.info(f"âœ… LLM ì½”ë©˜íŠ¸ ìƒì„± ì™„ë£Œ - {len(team_comment)}ì")
    
    return {
        **state,
        "messages": state.get("messages", []) + [
            HumanMessage(content=f"LLM ì½”ë©˜íŠ¸ ìƒì„± ì™„ë£Œ ({len(team_comment)}ì)")
        ],
        "team_performance_comment": team_comment,
        "final_comparison_json": final_comparison_json
    }

def save_results_submodule(state: Module8AgentState) -> Module8AgentState:
    """6. JSON ê²°ê³¼ DB ì €ì¥"""
    team_id = state["team_id"]
    period_id = state["period_id"]
    final_comparison_json = state["final_comparison_json"]
    
    logger.info(f"ğŸ’¾ DB ì €ì¥ ì¤‘ - íŒ€ {team_id}")
    
    # team_evaluation_id ì¡°íšŒ
    team_evaluation_id = fetch_team_evaluation_id(team_id, period_id)
    
    if not team_evaluation_id:
        logger.error(f"âŒ team_evaluation_id ì¡°íšŒ ì‹¤íŒ¨ - íŒ€ {team_id}, Q{period_id}")
        return {
            **state,
            "messages": state.get("messages", []) + [
                HumanMessage(content=f"team_evaluation_id ì¡°íšŒ ì‹¤íŒ¨: íŒ€ {team_id}, ë¶„ê¸° {period_id}")
            ]
        }
    
    # DB ì €ì¥
    success = save_team_comparison_results(team_evaluation_id, final_comparison_json)
    
    if success:
        logger.info(f"âœ… DB ì €ì¥ ì™„ë£Œ - team_evaluations[{team_evaluation_id}]")
        return {
            **state,
            "messages": state.get("messages", []) + [
                HumanMessage(content=f"DB ì €ì¥ ì™„ë£Œ: team_evaluations[{team_evaluation_id}] ì—…ë°ì´íŠ¸")
            ],
            "updated_team_evaluation_id": team_evaluation_id
        }
    else:
        logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨ - team_evaluations[{team_evaluation_id}]")
        return {
            **state,
            "messages": state.get("messages", []) + [
                HumanMessage(content=f"DB ì €ì¥ ì‹¤íŒ¨: team_evaluations[{team_evaluation_id}]")
            ]
        }

# ===== LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± =====

# ëª¨ë“ˆ 8 ì›Œí¬í”Œë¡œìš° ì •ì˜
module8_workflow = StateGraph(Module8AgentState)

# ë…¸ë“œ ì¶”ê°€
module8_workflow.add_node("check_cluster_stats", check_cluster_stats_submodule)
module8_workflow.add_node("calculate_cluster_stats", calculate_cluster_stats_submodule)
module8_workflow.add_node("team_performance_collection", team_performance_collection_submodule)
module8_workflow.add_node("kpi_comparison", kpi_comparison_submodule)
module8_workflow.add_node("generate_team_comment", generate_team_comment_submodule)
module8_workflow.add_node("save_results", save_results_submodule)

# ì—£ì§€ ì •ì˜
module8_workflow.add_edge(START, "check_cluster_stats")
module8_workflow.add_edge("check_cluster_stats", "calculate_cluster_stats")
module8_workflow.add_edge("calculate_cluster_stats", "team_performance_collection")
module8_workflow.add_edge("team_performance_collection", "kpi_comparison")
module8_workflow.add_edge("kpi_comparison", "generate_team_comment")
module8_workflow.add_edge("generate_team_comment", "save_results")
module8_workflow.add_edge("save_results", END)

# ëª¨ë“ˆ 8 ê·¸ë˜í”„ ì»´íŒŒì¼
module8_graph = module8_workflow.compile()

# ===== ë©”ì¸ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ =====

def execute_module8_pipeline(team_id: int, period_id: int, report_type: str = "quarterly") -> Dict[str, Any]:
    """ëª¨ë“ˆ 8 íŒ€ ì„±ê³¼ ë¹„êµ í‰ê°€ ì‹¤í–‰"""
    
    start_time = datetime.now()
    logger.info(f"\n{'='*60}")
    logger.info(f"ğŸš€ ëª¨ë“ˆ 8: íŒ€ ì„±ê³¼ ë¹„êµ ë¶„ì„ ì‹œì‘")
    logger.info(f"{'='*60}")
    logger.info(f"ğŸ“ ì„¤ì • ì •ë³´:")
    logger.info(f"   íŒ€ ID: {team_id}")
    logger.info(f"   ê¸°ê°„ ID: {period_id}")
    logger.info(f"   ë¦¬í¬íŠ¸ íƒ€ì…: {report_type}")
    
    try:
        initial_state = {
            "team_id": team_id,
            "period_id": period_id,
            "report_type": report_type,
            "messages": []
        }
        
        logger.info(f"ğŸš€ ëª¨ë“ˆ 8: íŒ€ ì„±ê³¼ ë¹„êµ ë¶„ì„ ì‹œì‘ (íŒ€ {team_id}, Q{period_id})")
        
        result = module8_graph.invoke(initial_state)
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        success_result = {
            "status": "success",
            "execution_time_seconds": execution_time,
            "team_id": team_id,
            "period_id": period_id,
            "report_type": report_type,
            "results": {
                "cluster_id": result.get("our_team_cluster_id"),
                "similar_teams_count": len(result.get("similar_teams", [])),
                "overall_rate": result.get("our_team_overall_rate"),
                "comment_length": len(result.get("team_performance_comment", "")),
                "kpi_comparisons": len(result.get("kpi_comparison_results", [])),
                "updated_team_evaluation_id": result.get("updated_team_evaluation_id")
            },
            "messages": [msg.content for msg in result.get("messages", [])]
        }
        
        logger.info("\nâœ… ëª¨ë“ˆ 8 ì‹¤í–‰ ì™„ë£Œ!")
        logger.info("ğŸ“‹ ì‹¤í–‰ ê³¼ì •:")
        for i, message in enumerate(result.get("messages", []), 1):
            logger.info(f"  {i}. {message.content}")
        
        logger.info(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
        logger.info(f"í´ëŸ¬ìŠ¤í„° ID: {success_result['results']['cluster_id']}")
        logger.info(f"ìœ ì‚¬íŒ€ ìˆ˜: {success_result['results']['similar_teams_count']}")
        logger.info(f"ì¢…í•© ë‹¬ì„±ë¥ : {success_result['results']['overall_rate']}%")
        logger.info(f"ì½”ë©˜íŠ¸ ê¸¸ì´: {success_result['results']['comment_length']}ì")
        logger.info(f"KPI ë¹„êµ ê²°ê³¼: {success_result['results']['kpi_comparisons']}ê°œ")
        logger.info(f"ì—…ë°ì´íŠ¸ëœ team_evaluation_id: {success_result['results']['updated_team_evaluation_id']}")
        logger.info(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
        logger.info(f"{'='*60}")
        
        return success_result
        
    except Exception as e:
        execution_time = (datetime.now() - start_time).total_seconds()
        error_result = {
            "status": "error",
            "execution_time_seconds": execution_time,
            "error_message": str(e),
            "error_type": type(e).__name__,
            "team_id": team_id,
            "period_id": period_id
        }
        
        logger.error(f"\nâŒ ëª¨ë“ˆ 8 ì‹¤í–‰ ì‹¤íŒ¨!")
        logger.error(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {execution_time:.2f}ì´ˆ")
        logger.error(f"ğŸ’¥ ì˜¤ë¥˜: {e}")
        logger.error(f"ğŸ” ì˜¤ë¥˜ ìœ í˜•: {type(e).__name__}")
        logger.error(f"{'='*60}")
        
        return error_result

# ===== í…ŒìŠ¤íŠ¸ ë° ì‹¤í–‰ í•¨ìˆ˜ =====

def test_module8() -> Optional[Dict]:
    """ëª¨ë“ˆ 8 í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("=== ëª¨ë“ˆ 8 í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # ê¸°ë³¸ í…ŒìŠ¤íŠ¸
    result = execute_module8_pipeline(team_id=1, period_id=2, report_type="quarterly")
    
    if result and result.get("status") == "success":
        logger.info(f"\nğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        logger.info(f"ìƒíƒœ: {result['status']}")
        logger.info(f"ì‹¤í–‰ ì‹œê°„: {result['execution_time_seconds']:.2f}ì´ˆ")
        logger.info(f"í´ëŸ¬ìŠ¤í„° ID: {result['results']['cluster_id']}")
        logger.info(f"ìœ ì‚¬íŒ€ ìˆ˜: {result['results']['similar_teams_count']}")
        logger.info(f"ì¢…í•© ë‹¬ì„±ë¥ : {result['results']['overall_rate']}%")
        logger.info(f"ì½”ë©˜íŠ¸ ê¸¸ì´: {result['results']['comment_length']}ì")
        logger.info(f"KPI ë¹„êµ ê²°ê³¼: {result['results']['kpi_comparisons']}ê°œ")
        logger.info(f"ì—…ë°ì´íŠ¸ëœ team_evaluation_id: {result['results']['updated_team_evaluation_id']}")
        
        return result
    else:
        logger.error("í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        if result:
            logger.error(f"ì˜¤ë¥˜: {result.get('error_message', 'Unknown error')}")
            logger.error(f"ì˜¤ë¥˜ ìœ í˜•: {result.get('error_type', 'Unknown')}")
        return None

# ===== ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ =====

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        {"team_id": 1, "period_id": 2, "report_type": "quarterly", "desc": "Q2 ë¶„ê¸°ë³„"},
        {"team_id": 1, "period_id": 4, "report_type": "annual_manager", "desc": "Q4 ì—°ë§"}
    ]

    for test_case in test_cases:
        logger.info(f"\nğŸ§ª ëª¨ë“ˆ8 í…ŒìŠ¤íŠ¸ ì‹¤í–‰ - {test_case['desc']}")
        logger.info(f"   í…ŒìŠ¤íŠ¸ íŒ€: {test_case['team_id']}")
        logger.info(f"   í…ŒìŠ¤íŠ¸ ê¸°ê°„: Q{test_case['period_id']}")
        logger.info(f"   ë¦¬í¬íŠ¸ íƒ€ì…: {test_case['report_type']}")
        
        try:
            result = execute_module8_pipeline(
                test_case['team_id'], 
                test_case['period_id'], 
                test_case['report_type']
            )
            
            if result.get('status') == 'success':
                logger.info(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                logger.info(f"ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½:")
                logger.info(f"   â€¢ ìƒíƒœ: {result['status']}")
                logger.info(f"   â€¢ ì‹¤í–‰ ì‹œê°„: {result['execution_time_seconds']:.2f}ì´ˆ")
                logger.info(f"   â€¢ í´ëŸ¬ìŠ¤í„° ID: {result['results']['cluster_id']}")
                logger.info(f"   â€¢ ìœ ì‚¬íŒ€ ìˆ˜: {result['results']['similar_teams_count']}")
                logger.info(f"   â€¢ ì¢…í•© ë‹¬ì„±ë¥ : {result['results']['overall_rate']}%")
                logger.info(f"   â€¢ ì½”ë©˜íŠ¸ ê¸¸ì´: {result['results']['comment_length']}ì")
                logger.info(f"   â€¢ KPI ë¹„êµ ìˆ˜: {result['results']['kpi_comparisons']}ê°œ")
                logger.info(f"   â€¢ ì—…ë°ì´íŠ¸ëœ team_evaluation_id: {result['results']['updated_team_evaluation_id']}")
            else:
                logger.error(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
                logger.error(f"   â€¢ ì˜¤ë¥˜: {result.get('error_message', 'Unknown error')}")
                logger.error(f"   â€¢ ì˜¤ë¥˜ ìœ í˜•: {result.get('error_type', 'Unknown')}")
            
        except Exception as e:
            logger.error(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ ëª¨ë“ˆ8 í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    logger.info(f"{'='*60}")